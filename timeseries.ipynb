{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thegallier/timeseries/blob/main/timeseries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "ozPGMJjwveMB",
        "outputId": "7706b11d-82fd-4111-a144-a6d7774f98c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying hyperparameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.001, 'num_epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4034ed44d46f>\u001b[0m in \u001b[0;36m<cell line: 487>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;31m# Start hyperparameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m \u001b[0mhyperparameter_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;31m# Example 1: Combine TransformerModel and LSTMModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-4034ed44d46f>\u001b[0m in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(hyperparams, train_loader, test_loader, device)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mkappa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-4034ed44d46f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, device, writer)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_securities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-4034ed44d46f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0moutputs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0moutputs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-4034ed44d46f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (sequence_length, batch_size, embedding_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Last output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask_for_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_nested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;31m# feed forward block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from itertools import product\n",
        "import time\n",
        "\n",
        "# Parameters\n",
        "num_timesteps = 5000  # Reduced for practical purposes\n",
        "num_securities = 10  # Number of different securities\n",
        "num_features_per_security = 4  # Features per security\n",
        "num_classes = 3  # Number of target classes\n",
        "num_features = num_securities * num_features_per_security  # Total number of features\n",
        "\n",
        "# Generate timestamps\n",
        "timestamps = np.arange(num_timesteps)\n",
        "\n",
        "# Generate random data for the primary dataset (X_data) and labels (y_data)\n",
        "X_data = np.random.rand(num_timesteps, num_features).astype(np.float32)  # Random features\n",
        "y_data = np.random.randint(0, num_classes, size=(num_timesteps, num_securities)).astype(np.int64)  # Random labels\n",
        "\n",
        "# Generate the second dataset with 3 categorical strings and 2 continuous floats per timestamp\n",
        "str_columns = ['str1', 'str2', 'str3']\n",
        "float_columns = ['float1', 'float2']\n",
        "second_dataset = {\n",
        "    'timestamp': timestamps,\n",
        "    'str1': np.random.choice(['A', 'B', 'C'], num_timesteps),\n",
        "    'str2': np.random.choice(['D', 'E', 'F'], num_timesteps),\n",
        "    'str3': np.random.choice(['G', 'H', 'I'], num_timesteps),\n",
        "    'float1': np.random.rand(num_timesteps),\n",
        "    'float2': np.random.rand(num_timesteps),\n",
        "}\n",
        "\n",
        "# Encode categorical string columns using LabelEncoder\n",
        "label_encoders = {}\n",
        "for col in str_columns:\n",
        "    le = LabelEncoder()\n",
        "    second_dataset[col] = le.fit_transform(second_dataset[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Combine all features from the second dataset into a single array\n",
        "second_X_data = np.column_stack([second_dataset[col] for col in str_columns + float_columns]).astype(np.float32)\n",
        "\n",
        "# Apply Min-Max scaling to both datasets\n",
        "scaler_X = MinMaxScaler()\n",
        "X_data = scaler_X.fit_transform(X_data)\n",
        "\n",
        "scaler_second_X = MinMaxScaler()\n",
        "second_X_data = scaler_second_X.fit_transform(second_X_data)\n",
        "\n",
        "def add_positional_encoding(X, timestamps, option='shared'):\n",
        "    \"\"\"\n",
        "    Add positional encoding to the feature matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - X (ndarray): Feature matrix.\n",
        "    - timestamps (ndarray): Array of timestamps.\n",
        "    - option (str): 'shared' or 'per_security'.\n",
        "\n",
        "    Returns:\n",
        "    - X_pe (ndarray): X with positional encoding added.\n",
        "    \"\"\"\n",
        "    if option == 'shared':\n",
        "        # Shared positional encoding across all features\n",
        "        pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(X.shape[1]) / X.shape[1]))\n",
        "        X_pe = X + pe.astype(np.float32)\n",
        "    elif option == 'per_security':\n",
        "        # Separate positional encoding for each security\n",
        "        pe_list = []\n",
        "        for i in range(num_securities):\n",
        "            pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(num_features_per_security) / num_features_per_security))\n",
        "            pe_list.append(pe)\n",
        "        pe_concat = np.hstack(pe_list)\n",
        "        X_pe = X + pe_concat.astype(np.float32)\n",
        "    else:\n",
        "        X_pe = X  # No positional encoding\n",
        "    return X_pe\n",
        "\n",
        "# Apply positional encoding\n",
        "positional_encoding_option = 'shared'  # 'shared' or 'per_security'\n",
        "X_data = add_positional_encoding(X_data, timestamps, positional_encoding_option)\n",
        "\n",
        "def create_windows(X1, X2, y, window_size, horizon):\n",
        "    \"\"\"\n",
        "    Create sliding windows for time series data.\n",
        "\n",
        "    Parameters:\n",
        "    - X1 (ndarray): Primary dataset features.\n",
        "    - X2 (ndarray): Secondary dataset features.\n",
        "    - y (ndarray): Target variable.\n",
        "    - window_size (int): Size of the window.\n",
        "    - horizon (int): Prediction horizon.\n",
        "\n",
        "    Returns:\n",
        "    - Tuple[np.ndarray, np.ndarray, np.ndarray]: Tuples of windows for X1, X2, and y.\n",
        "    \"\"\"\n",
        "    X1_windows = []\n",
        "    X2_windows = []\n",
        "    y_windows = []\n",
        "    for i in range(len(X1) - window_size - horizon + 1):\n",
        "        X1_windows.append(X1[i:i+window_size])\n",
        "        X2_windows.append(X2[i:i+window_size])\n",
        "        y_windows.append(y[i+window_size+horizon-1])\n",
        "    return np.array(X1_windows), np.array(X2_windows), np.array(y_windows)\n",
        "\n",
        "# Define window sizes\n",
        "window_size = 20\n",
        "horizon = 1\n",
        "\n",
        "# Create windows\n",
        "X1_windows, X2_windows, y_windows = create_windows(X_data, second_X_data, y_data, window_size, horizon)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(X1_windows) * train_ratio)\n",
        "\n",
        "X1_train = X1_windows[:train_size]\n",
        "X2_train = X2_windows[:train_size]\n",
        "y_train = y_windows[:train_size]\n",
        "\n",
        "X1_test = X1_windows[train_size:]\n",
        "X2_test = X2_windows[train_size:]\n",
        "y_test = y_windows[train_size:]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X1_train_tensor = torch.tensor(X1_train)\n",
        "X2_train_tensor = torch.tensor(X2_train)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "\n",
        "X1_test_tensor = torch.tensor(X1_test)\n",
        "X2_test_tensor = torch.tensor(X2_test)\n",
        "y_test_tensor = torch.tensor(y_test)\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for time series data with two feature sets.\n",
        "\n",
        "    Parameters:\n",
        "    - X1 (torch.Tensor): Primary dataset features.\n",
        "    - X2 (torch.Tensor): Secondary dataset features.\n",
        "    - y (torch.Tensor): Target variable.\n",
        "    \"\"\"\n",
        "    def __init__(self, X1, X2, y):\n",
        "        self.X1 = X1.float()\n",
        "        self.X2 = X2.float()\n",
        "        self.y = y.long()\n",
        "    def __len__(self):\n",
        "        return len(self.X1)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X1[idx], self.X2[idx], self.y[idx]\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = TimeSeriesDataset(X1_train_tensor, X2_train_tensor, y_train_tensor)\n",
        "test_dataset = TimeSeriesDataset(X1_test_tensor, X2_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class MatrixRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, num_features):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(1, num_securities))\n",
        "        self.B = nn.Parameter(torch.randn(num_features, num_classes))\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten over time\n",
        "        out = self.A @ x @ self.B  # Shape: (batch_size, num_classes)\n",
        "        out = out.view(-1, num_securities, num_classes)\n",
        "        return out\n",
        "\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_securities, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.linear = nn.Linear(input_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.linear(x)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, window_size)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        out = x.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_securities, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures global dependencies.\n",
        "    - Parallel computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Requires large datasets.\n",
        "    - Computationally intensive.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.embedding = nn.Linear(num_features, 128)\n",
        "        self.pos_encoder = PositionalEncoding(128)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=2)\n",
        "        self.decoder = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), x.size(1), -1)  # (batch_size, window_size, num_features)\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # (sequence_length, batch_size, embedding_dim)\n",
        "        output = self.transformer_encoder(x)\n",
        "        output = output[-1, :, :]  # Last output\n",
        "        output = self.decoder(output)\n",
        "        output = output.view(-1, self.num_securities, self.num_classes)\n",
        "        return output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional Encoding for Transformer.\n",
        "\n",
        "    Adds positional information to the embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        if d_model % 2 == 1:\n",
        "            pe[:, 1::2] = torch.sin(position * div_term)\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(1)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return x\n",
        "\n",
        "class SimpleRNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple Recurrent Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures sequential dependencies.\n",
        "    - Simpler than LSTM.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Struggles with long-term dependencies.\n",
        "    - May suffer from vanishing gradients.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_securities, num_classes):\n",
        "        super(SimpleRNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.rnn.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined Model: Merges outputs from two models.\n",
        "\n",
        "    Advantages:\n",
        "    - Leverages multiple data sources.\n",
        "    - Potentially better performance.\n",
        "\n",
        "    Disadvantages:\n",
        "    - More complex.\n",
        "    - Computationally intensive.\n",
        "    \"\"\"\n",
        "    def __init__(self, model1, model2, num_classes, num_securities):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.model1 = model1\n",
        "        self.model2 = model2\n",
        "        self.fc = nn.Linear(num_classes * 2, num_classes)\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "    def forward(self, x1, x2):\n",
        "        outputs1 = self.model1(x1)\n",
        "        outputs2 = self.model2(x2)\n",
        "        outputs = torch.cat((outputs1, outputs2), dim=2)\n",
        "        batch_size = outputs.size(0)\n",
        "        outputs = outputs.view(-1, outputs.size(2))\n",
        "        final_output = self.fc(outputs)\n",
        "        final_output = final_output.view(batch_size, self.num_securities, -1)\n",
        "        return final_output\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs, device, writer):\n",
        "    \"\"\"\n",
        "    Training loop for the model.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to train.\n",
        "    - train_loader (DataLoader): DataLoader for training data.\n",
        "    - criterion (nn.Module): Loss function.\n",
        "    - optimizer (torch.optim.Optimizer): Optimizer.\n",
        "    - num_epochs (int): Number of epochs.\n",
        "    - device (torch.device): Computation device.\n",
        "    - writer (SummaryWriter): TensorBoard SummaryWriter.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    global_step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X1_batch, X2_batch, y_batch in train_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            loss = 0\n",
        "            for i in range(num_securities):\n",
        "                loss += criterion(outputs[:, i, :], y_batch[:, i])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            writer.add_scalar('Training Loss', loss.item(), global_step)\n",
        "            global_step += 1\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "        # Save checkpoint\n",
        "        torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pth')\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test set.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to evaluate.\n",
        "    - test_loader (DataLoader): DataLoader for test data.\n",
        "    - device (torch.device): Computation device.\n",
        "\n",
        "    Returns:\n",
        "    - float: Cohen's kappa score.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for X1_batch, X2_batch, y_batch in test_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            _, predicted = torch.max(outputs.data, 2)\n",
        "            total += y_batch.numel()\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy().flatten())\n",
        "            all_targets.extend(y_batch.cpu().numpy().flatten())\n",
        "    accuracy = 100 * correct / total\n",
        "    kappa = cohen_kappa_score(all_targets, all_preds)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
        "    print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
        "    return kappa\n",
        "\n",
        "def hyperparameter_tuning(hyperparams, train_loader, test_loader, device):\n",
        "    \"\"\"\n",
        "    Perform hyperparameter tuning.\n",
        "\n",
        "    Parameters:\n",
        "    - hyperparams (dict): Dictionary of hyperparameters to try.\n",
        "    - train_loader (DataLoader): DataLoader for training data.\n",
        "    - test_loader (DataLoader): DataLoader for test data.\n",
        "    - device (torch.device): Computation device.\n",
        "    \"\"\"\n",
        "    best_kappa = -1\n",
        "    best_params = None\n",
        "    for params in product(*hyperparams.values()):\n",
        "        param_dict = dict(zip(hyperparams.keys(), params))\n",
        "        print(f\"Trying hyperparameters: {param_dict}\")\n",
        "        model1 = TransformerModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "        model2 = LSTMModel(input_size=second_X_data.shape[1], hidden_size=param_dict['hidden_size'],\n",
        "                           num_layers=param_dict['num_layers'], num_securities=num_securities, num_classes=num_classes)\n",
        "        combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "        optimizer = torch.optim.Adam(combined_model.parameters(), lr=param_dict['learning_rate'])\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        writer = SummaryWriter()\n",
        "        train_model(combined_model, train_loader, criterion, optimizer, param_dict['num_epochs'], device, writer)\n",
        "        kappa = evaluate_model(combined_model, test_loader, device)\n",
        "        writer.close()\n",
        "        if kappa > best_kappa:\n",
        "            best_kappa = kappa\n",
        "            best_params = param_dict\n",
        "    print(f\"Best Cohen's Kappa: {best_kappa:.4f} with parameters: {best_params}\")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters for tuning\n",
        "hyperparams = {\n",
        "    'hidden_size': [64, 128],\n",
        "    'num_layers': [1, 2],\n",
        "    'learning_rate': [0.001, 0.0001],\n",
        "    'num_epochs': [5]\n",
        "}\n",
        "\n",
        "# Start hyperparameter tuning\n",
        "hyperparameter_tuning(hyperparams, train_loader, test_loader, device)\n",
        "\n",
        "# Example 1: Combine TransformerModel and LSTMModel\n",
        "print(\"\\nTraining Combined Model 1: TransformerModel + LSTMModel\")\n",
        "model1 = TransformerModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = LSTMModel(input_size=second_X_data.shape[1], hidden_size=128, num_layers=2, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 2: Combine CNNModel and SimpleRNNModel\n",
        "print(\"\\nTraining Combined Model 2: CNNModel + SimpleRNNModel\")\n",
        "model1 = CNNModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = SimpleRNNModel(input_size=second_X_data.shape[1], hidden_size=64, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 3: Combine LogisticRegressionModel and LSTMModel\n",
        "print(\"\\nTraining Combined Model 3: LogisticRegressionModel + LSTMModel\")\n",
        "model1 = LogisticRegressionModel(input_size=num_features*window_size, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = LSTMModel(input_size=second_X_data.shape[1], hidden_size=128, num_layers=1, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Financial Time Series Forecasting Package\n",
        "---------------------------------------\n",
        "A comprehensive package for financial time series forecasting using various deep learning models.\n",
        "\n",
        "This package includes:\n",
        "- Multiple model architectures (AutoRegressive, LSTM, TCN, ProphetLike)\n",
        "- Data validation and preprocessing\n",
        "- Model checkpointing and logging\n",
        "- Configuration management\n",
        "- Comprehensive testing suite\n",
        "\n",
        "Author: Assistant\n",
        "Date: 2024-10-20\n",
        "Version: 1.0.0\n",
        "\"\"\"\n",
        "\n",
        "import logging\n",
        "import yaml\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List, Dict, Any, Tuple, Union\n",
        "from datetime import datetime, timedelta\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_forecasting import TimeSeriesDataSet\n",
        "from pytorch_forecasting.metrics import RMSE, QuantileLoss\n",
        "from scipy import stats\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    \"\"\"Configuration class for model parameters.\n",
        "\n",
        "    Attributes:\n",
        "        model_name (str): Name of the model to use\n",
        "        max_epochs (int): Maximum number of training epochs\n",
        "        batch_size (int): Batch size for training\n",
        "        learning_rate (float): Learning rate for optimization\n",
        "        hidden_size (int): Number of hidden units in layers\n",
        "        dropout (float): Dropout rate for regularization\n",
        "        max_encoder_length (int): Maximum length of encoder sequence\n",
        "        max_prediction_length (int): Maximum length of prediction sequence\n",
        "    \"\"\"\n",
        "    model_name: str\n",
        "    max_epochs: int = 30\n",
        "    batch_size: int = 64\n",
        "    learning_rate: float = 0.03\n",
        "    hidden_size: int = 16\n",
        "    dropout: float = 0.1\n",
        "    max_encoder_length: int = 30\n",
        "    max_prediction_length: int = 7\n",
        "\n",
        "    @classmethod\n",
        "    def from_yaml(cls, yaml_path: str) -> 'ModelConfig':\n",
        "        \"\"\"Load configuration from YAML file.\n",
        "\n",
        "        Args:\n",
        "            yaml_path: Path to YAML configuration file\n",
        "\n",
        "        Returns:\n",
        "            ModelConfig instance\n",
        "        \"\"\"\n",
        "        with open(yaml_path, 'r') as f:\n",
        "            config_dict = yaml.safe_load(f)\n",
        "        return cls(**config_dict)\n",
        "\n",
        "    def to_yaml(self, yaml_path: str) -> None:\n",
        "        \"\"\"Save configuration to YAML file.\n",
        "\n",
        "        Args:\n",
        "            yaml_path: Path to save configuration\n",
        "        \"\"\"\n",
        "        with open(yaml_path, 'w') as f:\n",
        "            yaml.dump(self.__dict__, f)\n",
        "\n",
        "class DataValidator:\n",
        "    \"\"\"Data validation utilities.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def validate_dataframe(df: pd.DataFrame, required_columns: List[str]) -> bool:\n",
        "        \"\"\"Validate DataFrame structure and content.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            required_columns: List of required column names\n",
        "\n",
        "        Returns:\n",
        "            bool: True if validation passes\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If validation fails\n",
        "        \"\"\"\n",
        "        # Check for required columns\n",
        "        missing_cols = set(required_columns) - set(df.columns)\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Check for null values\n",
        "        null_cols = df.columns[df.isnull().any()].tolist()\n",
        "        if null_cols:\n",
        "            raise ValueError(f\"Null values found in columns: {null_cols}\")\n",
        "\n",
        "        # Check for infinite values\n",
        "        inf_cols = df.columns[np.isinf(df.select_dtypes(include=np.number)).any()].tolist()\n",
        "        if inf_cols:\n",
        "            raise ValueError(f\"Infinite values found in columns: {inf_cols}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "class ModelCheckpointer:\n",
        "    \"\"\"Model checkpointing utilities.\"\"\"\n",
        "\n",
        "    def __init__(self, checkpoint_dir: str):\n",
        "        \"\"\"Initialize checkpointer.\n",
        "\n",
        "        Args:\n",
        "            checkpoint_dir: Directory to store checkpoints\n",
        "        \"\"\"\n",
        "        self.checkpoint_dir = Path(checkpoint_dir)\n",
        "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def save_checkpoint(self, model: torch.nn.Module, epoch: int,\n",
        "                       optimizer: torch.optim.Optimizer, loss: float) -> str:\n",
        "        \"\"\"Save model checkpoint.\n",
        "\n",
        "        Args:\n",
        "            model: PyTorch model\n",
        "            epoch: Current epoch number\n",
        "            optimizer: PyTorch optimizer\n",
        "            loss: Current loss value\n",
        "\n",
        "        Returns:\n",
        "            str: Path to saved checkpoint\n",
        "        \"\"\"\n",
        "        checkpoint_path = self.checkpoint_dir / f\"checkpoint_epoch_{epoch}.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "        }, checkpoint_path)\n",
        "        return str(checkpoint_path)\n",
        "\n",
        "    def load_checkpoint(self, model: torch.nn.Module,\n",
        "                       optimizer: torch.optim.Optimizer,\n",
        "                       checkpoint_path: str) -> Tuple[int, float]:\n",
        "        \"\"\"Load model checkpoint.\n",
        "\n",
        "        Args:\n",
        "            model: PyTorch model\n",
        "            optimizer: PyTorch optimizer\n",
        "            checkpoint_path: Path to checkpoint file\n",
        "\n",
        "        Returns:\n",
        "            Tuple containing (epoch_number, loss_value)\n",
        "        \"\"\"\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        return checkpoint['epoch'], checkpoint['loss']\n",
        "\n",
        "class AutoRegressiveModel(pl.LightningModule):\n",
        "    \"\"\"Simple Autoregressive model using a Linear layer.\"\"\"\n",
        "\n",
        "    def __init__(self, input_size: int, output_size: int = 1, **kwargs):\n",
        "        \"\"\"Initialize AR model.\n",
        "\n",
        "        Args:\n",
        "            input_size: Number of input features\n",
        "            output_size: Number of output features\n",
        "            **kwargs: Additional arguments\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(input_size, output_size)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x: Dictionary containing input tensors\n",
        "\n",
        "        Returns:\n",
        "            Model predictions\n",
        "        \"\"\"\n",
        "        encoder_output = x[\"encoder_cont\"][:, -1, :]  # Use last time step\n",
        "        prediction = self.linear(encoder_output)\n",
        "        return prediction\n",
        "\n",
        "class LSTMForecaster(pl.LightningModule):\n",
        "    \"\"\"LSTM-based Forecaster.\"\"\"\n",
        "\n",
        "    def __init__(self, input_size: int, hidden_size: int, num_layers: int,\n",
        "                 dropout: float = 0.0, **kwargs):\n",
        "        \"\"\"Initialize LSTM model.\n",
        "\n",
        "        Args:\n",
        "            input_size: Number of input features\n",
        "            hidden_size: Number of hidden units\n",
        "            num_layers: Number of LSTM layers\n",
        "            dropout: Dropout rate\n",
        "            **kwargs: Additional arguments\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size, hidden_size, num_layers,\n",
        "            batch_first=True, dropout=dropout\n",
        "        )\n",
        "        self.output_layer = torch.nn.Linear(hidden_size, 1)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        encoder_input = x[\"encoder_cont\"]\n",
        "        output, (hidden, _) = self.lstm(encoder_input)\n",
        "        prediction = self.output_layer(hidden[-1])\n",
        "        return prediction\n",
        "\n",
        "class TCNBlock(torch.nn.Module):\n",
        "    \"\"\"Temporal Convolutional Network block.\"\"\"\n",
        "\n",
        "    def __init__(self, n_inputs: int, n_outputs: int, kernel_size: int,\n",
        "                 stride: int, dilation: int, padding: int, dropout: float = 0.2):\n",
        "        \"\"\"Initialize TCN block.\"\"\"\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(\n",
        "            n_inputs, n_outputs, kernel_size,\n",
        "            stride=stride, padding=padding, dilation=dilation\n",
        "        )\n",
        "        self.chomp1 = torch.nn.functional.pad  # Remove future timesteps\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.dropout1 = torch.nn.Dropout(dropout)\n",
        "\n",
        "        self.net = torch.nn.Sequential(\n",
        "            self.conv1,\n",
        "            self.relu1,\n",
        "            self.dropout1\n",
        "        )\n",
        "\n",
        "        self.downsample = torch.nn.Conv1d(n_inputs, n_outputs, 1) \\\n",
        "            if n_inputs != n_outputs else None\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\"Initialize network weights.\"\"\"\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "class TCNForecaster(pl.LightningModule):\n",
        "    \"\"\"Temporal Convolutional Network Forecaster.\"\"\"\n",
        "\n",
        "    def __init__(self, input_size: int, num_channels: List[int],\n",
        "                 kernel_size: int = 2, dropout: float = 0.2, **kwargs):\n",
        "        \"\"\"Initialize TCN model.\"\"\"\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = input_size if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TCNBlock(\n",
        "                in_channels, out_channels, kernel_size, stride=1,\n",
        "                dilation=dilation_size,\n",
        "                padding=(kernel_size-1) * dilation_size,\n",
        "                dropout=dropout\n",
        "            )]\n",
        "\n",
        "        self.network = torch.nn.Sequential(*layers)\n",
        "        self.output_layer = torch.nn.Linear(num_channels[-1], 1)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        encoder_input = x[\"encoder_cont\"].permute(0, 2, 1)\n",
        "        output = self.network(encoder_input)\n",
        "        output = output[:, :, -1]  # Take last time step\n",
        "        prediction = self.output_layer(output)\n",
        "        return prediction\n",
        "\n",
        "class ProphetLikeModel(pl.LightningModule):\n",
        "    \"\"\"Prophet-like model capturing trend and seasonality.\"\"\"\n",
        "\n",
        "    def __init__(self, seasonality: int, **kwargs):\n",
        "        \"\"\"Initialize Prophet-like model.\"\"\"\n",
        "        super().__init__()\n",
        "        self.trend = torch.nn.Linear(1, 1)\n",
        "        self.seasonality = torch.nn.Linear(seasonality, 1)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        time = x[\"encoder_cont\"][:, :, 0].unsqueeze(-1)\n",
        "        trend = self.trend(time)\n",
        "\n",
        "        seasonal_features = x[\"encoder_cont\"][:, :, 1:self.hparams.seasonality+1]\n",
        "        seasonality = self.seasonality(seasonal_features)\n",
        "\n",
        "        prediction = trend + seasonality\n",
        "        return prediction[:, -1, :]\n",
        "\n",
        "class BaseWrapper:\n",
        "    \"\"\"Base wrapper for all models.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        \"\"\"Initialize wrapper.\"\"\"\n",
        "        self.config = config\n",
        "        self.logger = logging.getLogger(f\"{self.__class__.__name__}\")\n",
        "        self.validator = DataValidator()\n",
        "        self.checkpointer = ModelCheckpointer(\"checkpoints\")\n",
        "        self.model = None\n",
        "        self.training_metrics = []\n",
        "\n",
        "    def prepare_data(self, df: pd.DataFrame, time_idx: str,\n",
        "                    target: str, group_ids: List[str]) -> None:\n",
        "        \"\"\"Prepare data for training.\"\"\"\n",
        "        # Validate data\n",
        "        self.validator.validate_dataframe(df, [time_idx, target] + group_ids)\n",
        "\n",
        "        # Create TimeSeriesDataSet\n",
        "        self.training = TimeSeriesDataSet(\n",
        "            df[df[time_idx] <= df[time_idx].max() - self.config.max_prediction_length],\n",
        "            time_idx=time_idx,\n",
        "            target=target,\n",
        "            group_ids=group_ids,\n",
        "            max_encoder_length=self.config.max_encoder_length,\n",
        "            max_prediction_length=self.config.max_prediction_length,\n",
        "            static_categoricals=group_ids,\n",
        "            time_varying_known_reals=[time_idx],\n",
        "            time_varying_unknown_reals=[target],\n",
        "            target_normalizer=None,\n",
        "            allow_missings=True,\n",
        "        )\n",
        "\n",
        "        self.validation = TimeSeriesDataSet.from_dataset(\n",
        "            self.training,\n",
        "            df[df[time_idx] > df[time_idx].max() - self.config.max_prediction_length],\n",
        "            min_prediction_idx=df[time_idx].max() - self.config.max_prediction_length + 1\n",
        "        )\n",
        "\n",
        "        self.train_dataloader = DataLoader(\n",
        "            self.training, batch_size=self.config.batch_size, shuffle=True\n",
        "        )\n",
        "        self.val_dataloader = DataLoader(\n",
        "            self.validation, batch_size=self.config.batch_size\n",
        "        )\n",
        "\n",
        "    def fit(self) -> None:\n",
        "        \"\"\"Train the model.\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not initialized\")\n",
        "\n",
        "        trainer = pl.Trainer(\n",
        "            max_epochs=self.config.max_epochs,\n",
        "            callbacks=[\n",
        "                EarlyStopping(\n",
        "                    monitor=\"val_loss\",\n",
        "                    min_delta=1e-4,\n",
        "                    patience=5,\n",
        "                    verbose=False,\n",
        "                    mode=\"min\"\n",
        "                )\n",
        "            ],\n",
        "            gradient_clip_val=0.1,\n",
        "        )\n",
        "\n",
        "        trainer.fit(\n",
        "            self.model,\n",
        "            train_dataloaders=self.train_dataloader,\n",
        "            val_dataloaders=self.val_dataloader\n",
        "        )\n",
        "\n",
        "    def predict(self, df: pd.DataFrame) -> np.ndarray:\n",
        "        \"\"\"Make predictions.\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained\")\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(\n",
        "                self.validation.to_dataloader(df, batch_size=self.config.batch_size)\n",
        "            )\n",
        "        return predictions.numpy()\n",
        "\n",
        "def generate_sample_data(n_assets: int = 5, n_days: int = 100,\n",
        "                        seed: int = 42) -> pd.DataFrame:\n",
        "    \"\"\"Generate sample financial data for testing.\n",
        "\n",
        "    Args:\n",
        "        n_assets: Number of assets\n",
        "        n_days: Number of days\n",
        "        seed: Random seed\n",
        "\n",
        "    Returns:\n",
        "        DataFrame containing sample data\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    dates = [datetime.today() - timedelta(days=x) for x in range(n_days)]\n",
        "    dates.reverse()\n",
        "\n",
        "    data = {\n",
        "        'time': dates * n_assets,\n",
        "        'group_id': np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "6PcbYe1rbdgl",
        "outputId": "d96997b0-a652-4037-d926-5b5fe535f618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-2-92dd88ec71fe>, line 423)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-92dd88ec71fe>\"\u001b[0;36m, line \u001b[0;32m423\u001b[0m\n\u001b[0;31m    'group_id': np\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO-t4USs2aJt",
        "outputId": "97e42d1c-edcd-4401-b534-6832093c0199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Combined Model 1: GNNModel + TransformerModel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Loss: 11.0505\n",
            "Epoch [2/5], Loss: 11.0070\n",
            "Epoch [3/5], Loss: 11.0030\n",
            "Epoch [4/5], Loss: 10.9930\n",
            "Epoch [5/5], Loss: 10.9843\n",
            "Accuracy on test set: 33.00%\n",
            "Cohen's Kappa: -0.0043\n",
            "\n",
            "Training Combined Model 2: MambaModel + LSTMModel\n",
            "Epoch [1/5], Loss: 11.0014\n",
            "Epoch [2/5], Loss: 10.9867\n",
            "Epoch [3/5], Loss: 10.9818\n",
            "Epoch [4/5], Loss: 10.9776\n",
            "Epoch [5/5], Loss: 10.9677\n",
            "Accuracy on test set: 33.00%\n",
            "Cohen's Kappa: -0.0045\n",
            "\n",
            "Training Combined Model 3: LiquidNetModel + CNNModel\n",
            "Epoch [1/5], Loss: 10.9973\n",
            "Epoch [2/5], Loss: 10.9749\n",
            "Epoch [3/5], Loss: 10.9603\n",
            "Epoch [4/5], Loss: 10.9382\n",
            "Epoch [5/5], Loss: 10.9085\n",
            "Accuracy on test set: 33.32%\n",
            "Cohen's Kappa: -0.0008\n",
            "\n",
            "Training Combined Model 4: HiddenMarkovModel + LogisticRegressionModel\n",
            "Epoch [1/5], Loss: 11.0670\n",
            "Epoch [2/5], Loss: 10.9946\n",
            "Epoch [3/5], Loss: 10.9829\n",
            "Epoch [4/5], Loss: 10.9717\n",
            "Epoch [5/5], Loss: 10.9646\n",
            "Accuracy on test set: 33.44%\n",
            "Cohen's Kappa: 0.0014\n",
            "\n",
            "Training Combined Model 5: GNNModel + MambaModel\n",
            "Epoch [1/5], Loss: 11.0025\n",
            "Epoch [2/5], Loss: 10.9864\n",
            "Epoch [3/5], Loss: 10.9820\n",
            "Epoch [4/5], Loss: 10.9792\n",
            "Epoch [5/5], Loss: 10.9707\n",
            "Accuracy on test set: 33.76%\n",
            "Cohen's Kappa: 0.0050\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from itertools import product\n",
        "import time\n",
        "\n",
        "# Parameters\n",
        "num_timesteps = 5000  # Total number of time steps\n",
        "num_securities = 10  # Number of different securities\n",
        "num_features_per_security = 4  # Features per security\n",
        "num_classes = 3  # Number of target classes\n",
        "num_features = num_securities * num_features_per_security  # Total number of features\n",
        "\n",
        "# Generate timestamps\n",
        "timestamps = np.arange(num_timesteps)\n",
        "\n",
        "# Generate random data for the primary dataset (X_data) and labels (y_data)\n",
        "X_data = np.random.rand(num_timesteps, num_features).astype(np.float32)  # Random features\n",
        "y_data = np.random.randint(0, num_classes, size=(num_timesteps, num_securities)).astype(np.int64)  # Random labels\n",
        "\n",
        "# Generate the second dataset with 3 categorical strings and 2 continuous floats per timestamp\n",
        "str_columns = ['str1', 'str2', 'str3']\n",
        "float_columns = ['float1', 'float2']\n",
        "second_dataset = {\n",
        "    'timestamp': timestamps,\n",
        "    'str1': np.random.choice(['A', 'B', 'C'], num_timesteps),\n",
        "    'str2': np.random.choice(['D', 'E', 'F'], num_timesteps),\n",
        "    'str3': np.random.choice(['G', 'H', 'I'], num_timesteps),\n",
        "    'float1': np.random.rand(num_timesteps),\n",
        "    'float2': np.random.rand(num_timesteps),\n",
        "}\n",
        "\n",
        "# Encode categorical string columns using LabelEncoder\n",
        "label_encoders = {}\n",
        "for col in str_columns:\n",
        "    le = LabelEncoder()\n",
        "    second_dataset[col] = le.fit_transform(second_dataset[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Combine all features from the second dataset into a single array\n",
        "second_X_data = np.column_stack([second_dataset[col] for col in str_columns + float_columns]).astype(np.float32)\n",
        "\n",
        "# Apply Min-Max scaling to both datasets\n",
        "scaler_X = MinMaxScaler()\n",
        "X_data = scaler_X.fit_transform(X_data)\n",
        "\n",
        "scaler_second_X = MinMaxScaler()\n",
        "second_X_data = scaler_second_X.fit_transform(second_X_data)\n",
        "\n",
        "def add_positional_encoding(X, timestamps, option='shared'):\n",
        "    \"\"\"\n",
        "    Add positional encoding to the feature matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - X (ndarray): Feature matrix.\n",
        "    - timestamps (ndarray): Array of timestamps.\n",
        "    - option (str): 'shared' or 'per_security'.\n",
        "\n",
        "    Returns:\n",
        "    - X_pe (ndarray): X with positional encoding added.\n",
        "    \"\"\"\n",
        "    if option == 'shared':\n",
        "        # Shared positional encoding across all features\n",
        "        pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(X.shape[1]) / X.shape[1]))\n",
        "        X_pe = X + pe.astype(np.float32)\n",
        "    elif option == 'per_security':\n",
        "        # Separate positional encoding for each security\n",
        "        pe_list = []\n",
        "        for i in range(num_securities):\n",
        "            pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(num_features_per_security) / num_features_per_security))\n",
        "            pe_list.append(pe)\n",
        "        pe_concat = np.hstack(pe_list)\n",
        "        X_pe = X + pe_concat.astype(np.float32)\n",
        "    else:\n",
        "        X_pe = X  # No positional encoding\n",
        "    return X_pe\n",
        "\n",
        "# Apply positional encoding\n",
        "positional_encoding_option = 'shared'  # 'shared' or 'per_security'\n",
        "X_data = add_positional_encoding(X_data, timestamps, positional_encoding_option)\n",
        "\n",
        "def create_windows(X1, X2, y, window_size, horizon):\n",
        "    \"\"\"\n",
        "    Create sliding windows for time series data.\n",
        "\n",
        "    Parameters:\n",
        "    - X1 (ndarray): Primary dataset features.\n",
        "    - X2 (ndarray): Secondary dataset features.\n",
        "    - y (ndarray): Target variable.\n",
        "    - window_size (int): Size of the window.\n",
        "    - horizon (int): Prediction horizon.\n",
        "\n",
        "    Returns:\n",
        "    - Tuple[np.ndarray, np.ndarray, np.ndarray]: Tuples of windows for X1, X2, and y.\n",
        "    \"\"\"\n",
        "    X1_windows = []\n",
        "    X2_windows = []\n",
        "    y_windows = []\n",
        "    for i in range(len(X1) - window_size - horizon + 1):\n",
        "        X1_windows.append(X1[i:i+window_size])\n",
        "        X2_windows.append(X2[i:i+window_size])\n",
        "        y_windows.append(y[i+window_size+horizon-1])\n",
        "    return np.array(X1_windows), np.array(X2_windows), np.array(y_windows)\n",
        "\n",
        "# Define window sizes\n",
        "window_size = 20\n",
        "horizon = 1\n",
        "\n",
        "# Create windows\n",
        "X1_windows, X2_windows, y_windows = create_windows(X_data, second_X_data, y_data, window_size, horizon)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(X1_windows) * train_ratio)\n",
        "\n",
        "X1_train = X1_windows[:train_size]\n",
        "X2_train = X2_windows[:train_size]\n",
        "y_train = y_windows[:train_size]\n",
        "\n",
        "X1_test = X1_windows[train_size:]\n",
        "X2_test = X2_windows[train_size:]\n",
        "y_test = y_windows[train_size:]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X1_train_tensor = torch.tensor(X1_train)\n",
        "X2_train_tensor = torch.tensor(X2_train)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "\n",
        "X1_test_tensor = torch.tensor(X1_test)\n",
        "X2_test_tensor = torch.tensor(X2_test)\n",
        "y_test_tensor = torch.tensor(y_test)\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for time series data with two feature sets.\n",
        "\n",
        "    Parameters:\n",
        "    - X1 (torch.Tensor): Primary dataset features.\n",
        "    - X2 (torch.Tensor): Secondary dataset features.\n",
        "    - y (torch.Tensor): Target variable.\n",
        "    \"\"\"\n",
        "    def __init__(self, X1, X2, y):\n",
        "        self.X1 = X1.float()\n",
        "        self.X2 = X2.float()\n",
        "        self.y = y.long()\n",
        "    def __len__(self):\n",
        "        return len(self.X1)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X1[idx], self.X2[idx], self.y[idx]\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = TimeSeriesDataset(X1_train_tensor, X2_train_tensor, y_train_tensor)\n",
        "test_dataset = TimeSeriesDataset(X1_test_tensor, X2_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class MatrixRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "\n",
        "    Parameters:\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, num_features, num_classes):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(1, num_securities))\n",
        "        self.B = nn.Parameter(torch.randn(num_features, num_classes))\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten over time\n",
        "        out = self.A @ x @ self.B  # Shape: (batch_size, num_classes)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_securities, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.linear = nn.Linear(input_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.linear(x)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "\n",
        "    Parameters:\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, window_size)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        out = x.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - hidden_size (int): Size of hidden state.\n",
        "    - num_layers (int): Number of LSTM layers.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_securities, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures global dependencies.\n",
        "    - Parallel computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Requires large datasets.\n",
        "    - Computationally intensive.\n",
        "\n",
        "    Parameters:\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.embedding = nn.Linear(num_features, 128)\n",
        "        self.pos_encoder = PositionalEncoding(128)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=2)\n",
        "        self.decoder = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), x.size(1), -1)  # (batch_size, window_size, num_features)\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # (sequence_length, batch_size, embedding_dim)\n",
        "        output = self.transformer_encoder(x)\n",
        "        output = output[-1, :, :]  # Last output\n",
        "        output = self.decoder(output)\n",
        "        output = output.view(-1, self.num_securities, self.num_classes)\n",
        "        return output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional Encoding for Transformer.\n",
        "\n",
        "    Adds positional information to the embeddings.\n",
        "\n",
        "    Parameters:\n",
        "    - d_model (int): Embedding dimension.\n",
        "    - max_len (int): Maximum sequence length.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        if d_model % 2 == 1:\n",
        "            pe[:, 1::2] = torch.sin(position * div_term)\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(1)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return x\n",
        "\n",
        "class SimpleRNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple Recurrent Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures sequential dependencies.\n",
        "    - Simpler than LSTM.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Struggles with long-term dependencies.\n",
        "    - May suffer from vanishing gradients.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - hidden_size (int): Size of hidden state.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_securities, num_classes):\n",
        "        super(SimpleRNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "# Missing Models with Docstrings and Comments\n",
        "\n",
        "class GNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures relationships between securities.\n",
        "    - Utilizes attention mechanisms.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Requires graph structure.\n",
        "\n",
        "    Parameters:\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_features_per_security (int): Features per security.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, num_features_per_security, num_classes):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        # Create a linear layer for each security\n",
        "        self.gcn_layers = nn.ModuleList([nn.Linear(num_features_per_security, 64) for _ in range(num_securities)])\n",
        "        # Multi-head attention mechanism\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=64, num_heads=4, batch_first=True)\n",
        "        # Fully connected layer for classification\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, window_size, num_features)\n",
        "        batch_size = x.size(0)\n",
        "        x = x[:, -1, :]  # Use the last time step\n",
        "        x = x.view(batch_size, self.num_securities, -1)  # (batch_size, num_securities, num_features_per_security)\n",
        "        node_embeddings = []\n",
        "        for i in range(self.num_securities):\n",
        "            h = self.gcn_layers[i](x[:, i, :])  # (batch_size, 64)\n",
        "            node_embeddings.append(h)\n",
        "        h = torch.stack(node_embeddings, dim=1)  # (batch_size, num_securities, 64)\n",
        "        # Apply attention mechanism\n",
        "        attn_output, _ = self.attention(h, h, h)\n",
        "        out = self.fc(attn_output)  # (batch_size, num_securities, num_classes)\n",
        "        return out\n",
        "\n",
        "class MambaModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Mamba Model: Combines CNN and LSTM architectures.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures both local and long-term dependencies.\n",
        "    - Utilizes CNN for feature extraction and LSTM for temporal patterns.\n",
        "\n",
        "    Disadvantages:\n",
        "    - More complex and computationally intensive.\n",
        "\n",
        "    Parameters:\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(MambaModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        # Convolutional layer\n",
        "        self.cnn = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, batch_first=True)\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, window_size, num_features)\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, window_size)\n",
        "        x = F.relu(self.cnn(x))  # Apply CNN\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, new_window_size, channels)\n",
        "        h0 = torch.zeros(2, x.size(0), 128).to(x.device)  # Initial hidden state\n",
        "        c0 = torch.zeros(2, x.size(0), 128).to(x.device)  # Initial cell state\n",
        "        out, _ = self.lstm(x, (h0, c0))  # Apply LSTM\n",
        "        out = out[:, -1, :]  # Get the last output\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LiquidNetModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Liquid Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Dynamic adaptation to inputs.\n",
        "    - Good for time-series data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Relatively new, less tested.\n",
        "    - May be complex to tune.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - hidden_size (int): Size of hidden state.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_securities, num_classes):\n",
        "        super(LiquidNetModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        # RNN Cell with ReLU activation\n",
        "        self.rnn_cell = nn.RNNCell(input_size, hidden_size, nonlinearity='relu')\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h_t = torch.zeros(x.size(0), self.rnn_cell.hidden_size).to(x.device)  # Initial hidden state\n",
        "        for t in range(x.size(1)):\n",
        "            h_t = self.rnn_cell(x[:, t, :], h_t)  # Update hidden state\n",
        "        out = self.fc(h_t)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class HiddenMarkovModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Hidden Markov Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Probabilistic approach.\n",
        "    - Good for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Simplified version here.\n",
        "    - May not capture complex patterns.\n",
        "\n",
        "    Parameters:\n",
        "    - num_states (int): Number of hidden states.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_states, num_securities, num_classes):\n",
        "        super(HiddenMarkovModel, self).__init__()\n",
        "        self.num_states = num_states\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        # Start probabilities\n",
        "        self.start_prob = nn.Parameter(torch.randn(num_states))\n",
        "        # Transition probabilities\n",
        "        self.transition_prob = nn.Parameter(torch.randn(num_states, num_states))\n",
        "        # Emission probabilities\n",
        "        self.emission_prob = nn.Parameter(torch.randn(num_states, num_classes))\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        # Simplified; in practice, you'd implement the forward algorithm\n",
        "        out = torch.softmax(self.emission_prob, dim=1)\n",
        "        # Corrected repeat dimensions to match tensor dimensions\n",
        "        out = out.unsqueeze(0).unsqueeze(0).repeat(batch_size, self.num_securities, 1, 1)\n",
        "        # Since the model expects output shape (batch_size, num_securities, num_classes)\n",
        "        # We need to aggregate over the hidden states (num_states)\n",
        "        out = torch.mean(out, dim=2)  # Average over hidden states\n",
        "        return out\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined Model: Merges outputs from two models.\n",
        "\n",
        "    Advantages:\n",
        "    - Leverages multiple data sources.\n",
        "    - Potentially better performance.\n",
        "\n",
        "    Disadvantages:\n",
        "    - More complex.\n",
        "    - Computationally intensive.\n",
        "\n",
        "    Parameters:\n",
        "    - model1 (nn.Module): First model.\n",
        "    - model2 (nn.Module): Second model.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    - num_securities (int): Number of securities.\n",
        "    \"\"\"\n",
        "    def __init__(self, model1, model2, num_classes, num_securities):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.model1 = model1\n",
        "        self.model2 = model2\n",
        "        self.fc = nn.Linear(num_classes * 2, num_classes)\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "    def forward(self, x1, x2):\n",
        "        outputs1 = self.model1(x1)\n",
        "        outputs2 = self.model2(x2)\n",
        "        outputs = torch.cat((outputs1, outputs2), dim=2)\n",
        "        batch_size = outputs.size(0)\n",
        "        outputs = outputs.view(-1, outputs.size(2))\n",
        "        final_output = self.fc(outputs)\n",
        "        final_output = final_output.view(batch_size, self.num_securities, -1)\n",
        "        return final_output\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs, device, writer):\n",
        "    \"\"\"\n",
        "    Training loop for the model.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to train.\n",
        "    - train_loader (DataLoader): DataLoader for training data.\n",
        "    - criterion (nn.Module): Loss function.\n",
        "    - optimizer (torch.optim.Optimizer): Optimizer.\n",
        "    - num_epochs (int): Number of epochs.\n",
        "    - device (torch.device): Computation device.\n",
        "    - writer (SummaryWriter): TensorBoard SummaryWriter.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    global_step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X1_batch, X2_batch, y_batch in train_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            loss = 0\n",
        "            for i in range(num_securities):\n",
        "                loss += criterion(outputs[:, i, :], y_batch[:, i])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            writer.add_scalar('Training Loss', loss.item(), global_step)\n",
        "            global_step += 1\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "        # Save checkpoint\n",
        "        torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pth')\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test set.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to evaluate.\n",
        "    - test_loader (DataLoader): DataLoader for test data.\n",
        "    - device (torch.device): Computation device.\n",
        "\n",
        "    Returns:\n",
        "    - float: Cohen's kappa score.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for X1_batch, X2_batch, y_batch in test_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            _, predicted = torch.max(outputs.data, 2)\n",
        "            total += y_batch.numel()\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy().flatten())\n",
        "            all_targets.extend(y_batch.cpu().numpy().flatten())\n",
        "    accuracy = 100 * correct / total\n",
        "    kappa = cohen_kappa_score(all_targets, all_preds)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
        "    print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
        "    return kappa\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Examples of combination models using the new models\n",
        "\n",
        "# Example 1: Combine GNNModel and TransformerModel\n",
        "print(\"\\nTraining Combined Model 1: GNNModel + TransformerModel\")\n",
        "model1 = GNNModel(num_securities=num_securities, num_features_per_security=num_features_per_security, num_classes=num_classes)\n",
        "model2 = TransformerModel(num_features=second_X_data.shape[1], num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 2: Combine MambaModel and LSTMModel\n",
        "print(\"\\nTraining Combined Model 2: MambaModel + LSTMModel\")\n",
        "model1 = MambaModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = LSTMModel(input_size=second_X_data.shape[1], hidden_size=64, num_layers=1, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 3: Combine LiquidNetModel and CNNModel\n",
        "print(\"\\nTraining Combined Model 3: LiquidNetModel + CNNModel\")\n",
        "model1 = LiquidNetModel(input_size=num_features, hidden_size=128, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = CNNModel(num_features=second_X_data.shape[1], num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 4: Combine HiddenMarkovModel and LogisticRegressionModel\n",
        "print(\"\\nTraining Combined Model 4: HiddenMarkovModel + LogisticRegressionModel\")\n",
        "model1 = HiddenMarkovModel(num_states=5, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = LogisticRegressionModel(input_size=second_X_data.shape[1]*window_size, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 5: Combine GNNModel and MambaModel\n",
        "print(\"\\nTraining Combined Model 5: GNNModel + MambaModel\")\n",
        "model1 = GNNModel(num_securities=num_securities, num_features_per_security=num_features_per_security, num_classes=num_classes)\n",
        "model2 = MambaModel(num_features=second_X_data.shape[1], num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_ZCKOPo0MRM",
        "outputId": "2c2878d8-a5ca-4030-feca-75735a27c6df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Combined Model with Transformer and LSTM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Loss: 11.0751\n",
            "Epoch [2/5], Loss: 11.0117\n",
            "Epoch [3/5], Loss: 11.0131\n",
            "Epoch [4/5], Loss: 11.0011\n",
            "Epoch [5/5], Loss: 10.9982\n",
            "Accuracy on test set: 32.97%\n"
          ]
        }
      ],
      "source": [
        "# ... [Previous code remains the same up to model definitions]\n",
        "\n",
        "# Instantiate models for primary and second datasets\n",
        "print(\"Training Combined Model with Transformer and LSTM...\")\n",
        "\n",
        "# Primary model\n",
        "primary_model = TransformerModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "# Secondary model\n",
        "secondary_model = LSTMModel(input_size=second_input_size, hidden_size=128, num_layers=2, num_securities=num_securities, num_classes=num_classes)\n",
        "\n",
        "# Define final linear layer\n",
        "class FinalModel(nn.Module):\n",
        "    def __init__(self, num_classes, num_securities):\n",
        "        super(FinalModel, self).__init__()\n",
        "        self.fc = nn.Linear(num_classes * 2, num_classes)\n",
        "        self.num_securities = num_securities\n",
        "    def forward(self, outputs1, outputs2):\n",
        "        # Concatenate over class dimension\n",
        "        outputs = torch.cat((outputs1, outputs2), dim=2)\n",
        "        # Pass through linear layer\n",
        "        batch_size = outputs.size(0)\n",
        "        outputs = outputs.view(-1, outputs.size(2))\n",
        "        final_output = self.fc(outputs)\n",
        "        final_output = final_output.view(batch_size, self.num_securities, -1)\n",
        "        return final_output\n",
        "\n",
        "final_model = FinalModel(num_classes=num_classes, num_securities=num_securities)\n",
        "\n",
        "# Combine the parameters of all models\n",
        "params = list(primary_model.parameters()) + list(secondary_model.parameters()) + list(final_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
        "\n",
        "# Updated training function\n",
        "def train_model(model1, model2, final_model, train_loader, criterion, optimizer, num_epochs, device):\n",
        "    model1 = model1.to(device)\n",
        "    model2 = model2.to(device)\n",
        "    final_model = final_model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model1.train()\n",
        "        model2.train()\n",
        "        final_model.train()\n",
        "        total_loss = 0\n",
        "        for X1_batch, X2_batch, y_batch in train_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs1 = model1(X1_batch)\n",
        "            outputs2 = model2(X2_batch)\n",
        "            final_output = final_model(outputs1, outputs2)\n",
        "            loss = 0\n",
        "            for i in range(num_securities):\n",
        "                loss += criterion(final_output[:, i, :], y_batch[:, i])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "# Updated evaluation function\n",
        "def evaluate_model(model1, model2, final_model, test_loader, device):\n",
        "    model1 = model1.to(device)\n",
        "    model2 = model2.to(device)\n",
        "    final_model = final_model.to(device)\n",
        "    model1.eval()\n",
        "    model2.eval()\n",
        "    final_model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for X1_batch, X2_batch, y_batch in test_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs1 = model1(X1_batch)\n",
        "            outputs2 = model2(X2_batch)\n",
        "            final_output = final_model(outputs1, outputs2)\n",
        "            _, predicted = torch.max(final_output.data, 2)\n",
        "            total += y_batch.numel()\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
        "\n",
        "# Start training\n",
        "train_model(primary_model, secondary_model, final_model, train_loader, criterion, optimizer, num_epochs, device)\n",
        "evaluate_model(primary_model, secondary_model, final_model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6sf3SVposU0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Time2Vec implementation\n",
        "class Time2Vec(nn.Module):\n",
        "    def __init__(self, seq_len, d_model):\n",
        "        super(Time2Vec, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.d_model = d_model\n",
        "        self.w0 = nn.Parameter(torch.randn(1))\n",
        "        self.b0 = nn.Parameter(torch.randn(1))\n",
        "        self.w = nn.Parameter(torch.randn(d_model - 1))\n",
        "        self.b = nn.Parameter(torch.randn(d_model - 1))\n",
        "\n",
        "    def forward(self, batch_size):\n",
        "        # Create time indices\n",
        "        t = torch.arange(self.seq_len).unsqueeze(-1).float().to(self.w0.device)  # Shape: (seq_len, 1)\n",
        "        # Linear component\n",
        "        v = self.w0 * t + self.b0  # Shape: (seq_len, 1)\n",
        "        # Periodic component\n",
        "        vp = torch.sin(self.w * t + self.b)  # Broadcasting over (seq_len, d_model - 1)\n",
        "        # Concatenate components\n",
        "        time_emb = torch.cat([v, vp], dim=-1)  # Shape: (seq_len, d_model)\n",
        "        # Expand to match batch size\n",
        "        time_emb = time_emb.unsqueeze(0).expand(batch_size, -1, -1)  # Shape: (batch_size, seq_len, d_model)\n",
        "        return time_emb\n",
        "\n",
        "# Corrected Multi-Head Attention Mechanism\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.out_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        batch_size = q.size(0)\n",
        "\n",
        "        # Perform linear projections and split into heads\n",
        "        q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1,2)\n",
        "        k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1,2)\n",
        "        v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1,2)\n",
        "\n",
        "        # Calculate attention scores\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # Concatenate heads\n",
        "        context = context.transpose(1,2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
        "        output = self.out_linear(context)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Corrected Gated Residual Network\n",
        "class GatedResidualNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GatedResidualNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.elu = nn.ELU()\n",
        "        self.fc2 = nn.Linear(hidden_size, 2 * input_size)  # Output size doubled for GLU\n",
        "        self.glu = nn.GLU(dim=-1)  # Splits last dimension into two halves\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.fc1(x)\n",
        "        x = self.elu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.glu(x)\n",
        "        return residual + x\n",
        "\n",
        "# Corrected Transformer Encoder Block\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, hidden_size):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.grn = GatedResidualNetwork(d_model, hidden_size)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attn_output = self.attention(x, x, x, mask)\n",
        "        x = self.norm1(x + attn_output)\n",
        "        grn_output = self.grn(x)\n",
        "        x = self.norm2(x + grn_output)\n",
        "        return x\n",
        "\n",
        "# Corrected Transformer Decoder Block\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, hidden_size):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.grn = GatedResidualNetwork(d_model, hidden_size)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
        "        # Self-attention with masking\n",
        "        attn_output = self.self_attention(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + attn_output)\n",
        "\n",
        "        # Cross-attention with encoder outputs\n",
        "        attn_output = self.cross_attention(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + attn_output)\n",
        "\n",
        "        # Apply GRN and residual connection\n",
        "        grn_output = self.grn(x)\n",
        "        x = self.norm3(x + grn_output)\n",
        "        return x\n",
        "\n",
        "# Corrected Portfolio Transformer Model\n",
        "class PortfolioTransformer(nn.Module):\n",
        "    def __init__(self, num_assets, d_model, num_heads, hidden_size, num_layers, seq_len):\n",
        "        super(PortfolioTransformer, self).__init__()\n",
        "        self.num_assets = num_assets\n",
        "        self.d_model = d_model\n",
        "        self.seq_len = seq_len\n",
        "        self.input_proj = nn.Linear(num_assets, d_model)\n",
        "        self.time2vec = Time2Vec(seq_len, d_model)\n",
        "        self.encoder_layers = nn.ModuleList(\n",
        "            [TransformerEncoder(d_model, num_heads, hidden_size) for _ in range(num_layers)]\n",
        "        )\n",
        "        self.decoder_layers = nn.ModuleList(\n",
        "            [TransformerDecoder(d_model, num_heads, hidden_size) for _ in range(num_layers)]\n",
        "        )\n",
        "        self.fc_out = nn.Linear(d_model, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, num_assets)\n",
        "        batch_size = x.size(0)\n",
        "        # Project input features to d_model\n",
        "        x_proj = self.input_proj(x)  # Shape: (batch_size, seq_len, d_model)\n",
        "        # Get time embeddings\n",
        "        time_emb = self.time2vec(batch_size)  # Shape: (batch_size, seq_len, d_model)\n",
        "        # Combine input embeddings and time embeddings\n",
        "        x = x_proj + time_emb  # Element-wise addition\n",
        "        # Encoder\n",
        "        for encoder in self.encoder_layers:\n",
        "            x = encoder(x)\n",
        "        # Decoder\n",
        "        dec_input = x\n",
        "        for decoder in self.decoder_layers:\n",
        "            x = decoder(dec_input, x)\n",
        "        s_i_t = self.fc_out(x)  # Output shape: (batch_size, seq_len, num_assets)\n",
        "        # Compute weights using the compound function\n",
        "        weights = torch.sign(s_i_t) * torch.softmax(torch.abs(s_i_t), dim=-1)\n",
        "        return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrPdsSy0o3YJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Generate random returns data: 100 securities over 1000 time steps\n",
        "num_securities = 100\n",
        "num_time_steps = 1000\n",
        "np.random.seed(42)  # For reproducibility\n",
        "\n",
        "# Simulate random returns\n",
        "returns_data = np.random.randn(num_time_steps, num_securities) * 0.01  # Small random returns\n",
        "prices = 100 + np.cumsum(returns_data, axis=0)  # Simulate price paths\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "prices = torch.tensor(prices, dtype=torch.float32)\n",
        "returns = torch.tensor(returns_data, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTj0mZgqo5xO",
        "outputId": "819e1e54-1d45-4619-f621-f2dd92818dec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.0227\n",
            "Epoch 2/10, Loss: -0.1482\n",
            "Epoch 3/10, Loss: -0.1936\n",
            "Epoch 4/10, Loss: -0.2280\n",
            "Epoch 5/10, Loss: -0.2235\n",
            "Epoch 6/10, Loss: -0.2329\n",
            "Epoch 7/10, Loss: -0.2364\n",
            "Epoch 8/10, Loss: -0.2379\n",
            "Epoch 9/10, Loss: -0.2571\n",
            "Epoch 10/10, Loss: -0.2559\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Prepare the dataset\n",
        "sequence_length = 20  # Use last 20 days for prediction\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(len(prices) - sequence_length):\n",
        "    X.append(returns[i:i+sequence_length])\n",
        "    y.append(returns[i+sequence_length])\n",
        "\n",
        "X = torch.stack(X)  # Shape: (num_samples, seq_len, num_assets)\n",
        "y = torch.stack(y)  # Shape: (num_samples, num_assets)\n",
        "\n",
        "dataset = TensorDataset(X, y)\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Initialize the model\n",
        "num_assets = num_securities\n",
        "model = PortfolioTransformer(\n",
        "    num_assets=num_assets, d_model=64, num_heads=8, hidden_size=128, num_layers=4, seq_len=sequence_length\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "def train(model, optimizer, data_loader, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            portfolio_weights = model(batch_X)  # Output shape: (batch_size, seq_len, num_assets)\n",
        "            # Use the last time step's weights\n",
        "            portfolio_weights = portfolio_weights[:, -1, :]  # Shape: (batch_size, num_assets)\n",
        "            # Compute portfolio returns\n",
        "            portfolio_returns = torch.sum(portfolio_weights * batch_y, dim=1)\n",
        "            loss = sharpe_loss(portfolio_returns)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(data_loader):.4f}\")\n",
        "\n",
        "# Loss function (Negative Sharpe Ratio)\n",
        "def sharpe_loss(portfolio_returns, risk_free_rate=0.0):\n",
        "    # Assuming daily returns, annualize by multiplying by sqrt(252)\n",
        "    mean_return = torch.mean(portfolio_returns)\n",
        "    std_return = torch.std(portfolio_returns)\n",
        "    sharpe_ratio = (mean_return - risk_free_rate) / (std_return + 1e-6)\n",
        "    return -sharpe_ratio  # Negative for minimization\n",
        "\n",
        "# Train the model\n",
        "train(model, optimizer, data_loader, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lzRyXdVtM2g"
      },
      "outputs": [],
      "source": [
        "## version 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udFpzIeosoq6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Advanced Time Encoding: Learnable Positional Encoding\n",
        "class LearnablePositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements learnable positional encoding for sequences.\n",
        "\n",
        "    Args:\n",
        "        seq_len (int): The maximum length of the input sequences.\n",
        "        d_model (int): The dimension of the model.\n",
        "    \"\"\"\n",
        "    def __init__(self, seq_len, d_model):\n",
        "        super(LearnablePositionalEncoding, self).__init__()\n",
        "        self.position_embeddings = nn.Embedding(seq_len, d_model)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass for positional encoding.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor of shape (batch_size, seq_len, d_model).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Positionally encoded tensor.\n",
        "        \"\"\"\n",
        "        positions = torch.arange(0, self.seq_len, device=x.device).unsqueeze(0)\n",
        "        pos_embed = self.position_embeddings(positions)\n",
        "        x = x + pos_embed\n",
        "        return x\n",
        "\n",
        "# PortfolioTransformer using PyTorch's nn.Transformer\n",
        "class PortfolioTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Portfolio Transformer model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets in the portfolio.\n",
        "        d_model (int): Dimension of the model.\n",
        "        nhead (int): Number of attention heads.\n",
        "        num_layers (int): Number of transformer encoder layers.\n",
        "        seq_len (int): Length of the input sequences.\n",
        "        dropout (float): Dropout probability.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, num_assets, d_model, nhead, num_layers, seq_len, dropout=0.1\n",
        "    ):\n",
        "        super(PortfolioTransformer, self).__init__()\n",
        "        self.num_assets = num_assets\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Input projection layer to map asset returns to model dimension\n",
        "        self.input_proj = nn.Linear(num_assets, d_model)\n",
        "\n",
        "        # Learnable positional encoding\n",
        "        self.pos_encoder = LearnablePositionalEncoding(seq_len, d_model)\n",
        "\n",
        "        # Transformer encoder layers\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layers, num_layers=num_layers\n",
        "        )\n",
        "\n",
        "        # Output layer to map back to asset space\n",
        "        self.fc_out = nn.Linear(d_model, num_assets)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"\n",
        "        Initializes weights for better convergence.\n",
        "        \"\"\"\n",
        "        initrange = 0.1\n",
        "        self.input_proj.weight.data.uniform_(-initrange, initrange)\n",
        "        self.input_proj.bias.data.zero_()\n",
        "        self.fc_out.bias.data.zero_()\n",
        "        self.fc_out.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor of shape (batch_size, seq_len, num_assets).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Portfolio weights of shape (batch_size, seq_len, num_assets).\n",
        "        \"\"\"\n",
        "        # Project input to model dimension and scale\n",
        "        x = self.input_proj(x) * np.sqrt(self.d_model)\n",
        "        # Add positional encoding\n",
        "        x = self.pos_encoder(x)\n",
        "        # Pass through transformer encoder\n",
        "        x = self.transformer_encoder(x)\n",
        "        # Map back to asset space\n",
        "        s_i_t = self.fc_out(x)  # Shape: (batch_size, seq_len, num_assets)\n",
        "        # Apply activation and normalize weights\n",
        "        weights = torch.tanh(s_i_t)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=-1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "def sharpe_loss(\n",
        "    portfolio_returns, portfolio_weights, prev_weights, transaction_cost=0.0002\n",
        "):\n",
        "    \"\"\"\n",
        "    Computes the negative Sharpe ratio as the loss function, including transaction costs.\n",
        "\n",
        "    Args:\n",
        "        portfolio_returns (Tensor): Portfolio returns of shape (batch_size,).\n",
        "        portfolio_weights (Tensor): Current portfolio weights of shape (batch_size, num_assets).\n",
        "        prev_weights (Tensor): Previous portfolio weights of shape (batch_size, num_assets).\n",
        "        transaction_cost (float): Transaction cost rate per unit weight change.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Loss value (negative Sharpe ratio).\n",
        "    \"\"\"\n",
        "    # Compute transaction costs based on weight changes\n",
        "    tc = transaction_cost * torch.sum(torch.abs(portfolio_weights - prev_weights), dim=1)\n",
        "    # Net returns after subtracting transaction costs\n",
        "    net_returns = portfolio_returns - tc\n",
        "    # Compute mean and standard deviation of returns\n",
        "    mean_return = torch.mean(net_returns)\n",
        "    std_return = torch.std(net_returns)\n",
        "    # Compute Sharpe ratio\n",
        "    sharpe_ratio = mean_return / (std_return + 1e-6)\n",
        "    # Return negative Sharpe ratio for minimization\n",
        "    return -sharpe_ratio\n",
        "\n",
        "def compute_expected_time_to_target(portfolio_returns, target_sharpe, window=20):\n",
        "    \"\"\"\n",
        "    Estimates the expected time to reach the target Sharpe ratio.\n",
        "\n",
        "    Args:\n",
        "        portfolio_returns (list): List of past portfolio returns.\n",
        "        target_sharpe (float): Target Sharpe ratio.\n",
        "        window (int): Window size for rolling calculation.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Estimated time to reach the target Sharpe ratio.\n",
        "    \"\"\"\n",
        "    # If insufficient data, return zero\n",
        "    if len(portfolio_returns) < window:\n",
        "        return torch.tensor(0.0)\n",
        "    # Compute rolling mean and std\n",
        "    recent_returns = torch.tensor(portfolio_returns[-window:])\n",
        "    rolling_returns = torch.mean(recent_returns)\n",
        "    rolling_std = torch.std(recent_returns)\n",
        "    rolling_sharpe = rolling_returns / (rolling_std + 1e-6)\n",
        "    # Estimate time to target\n",
        "    if rolling_sharpe >= target_sharpe:\n",
        "        time_to_target = torch.tensor(0.0)\n",
        "    else:\n",
        "        # Simplified estimation\n",
        "        time_to_target = (target_sharpe - rolling_sharpe) * window\n",
        "    return time_to_target\n",
        "\n",
        "def adjust_position_scaling(portfolio_weights, time_to_target, scaling_factor=0.1):\n",
        "    \"\"\"\n",
        "    Adjusts position scaling based on the estimated time to target Sharpe ratio.\n",
        "\n",
        "    Args:\n",
        "        portfolio_weights (Tensor): Current portfolio weights.\n",
        "        time_to_target (Tensor): Estimated time to reach target Sharpe ratio.\n",
        "        scaling_factor (float): Factor to control scaling sensitivity.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Adjusted portfolio weights.\n",
        "    \"\"\"\n",
        "    # Compute scaling coefficient\n",
        "    scaling = 1.0 - scaling_factor * torch.sigmoid(time_to_target)\n",
        "    # Adjust portfolio weights\n",
        "    adjusted_weights = portfolio_weights * scaling\n",
        "    return adjusted_weights\n",
        "\n",
        "def train(model, optimizer, data_loader, num_epochs, target_sharpe=1.0):\n",
        "    \"\"\"\n",
        "    Trains the PortfolioTransformer model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PortfolioTransformer model.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer.\n",
        "        data_loader (DataLoader): DataLoader for training data.\n",
        "        num_epochs (int): Number of training epochs.\n",
        "        target_sharpe (float): Target Sharpe ratio for scaling positions.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    portfolio_returns_history = []\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass to get portfolio weights\n",
        "            portfolio_weights = model(batch_X)\n",
        "            # Use the last time step's weights\n",
        "            portfolio_weights = portfolio_weights[:, -1, :]\n",
        "            # Initialize prev_weights with zeros matching portfolio_weights\n",
        "            prev_weights = torch.zeros_like(portfolio_weights)\n",
        "            # Compute portfolio returns\n",
        "            portfolio_returns = torch.sum(portfolio_weights * batch_y, dim=1)\n",
        "            # Adjust positions based on expected time to target\n",
        "            time_to_target = compute_expected_time_to_target(\n",
        "                portfolio_returns_history, target_sharpe\n",
        "            )\n",
        "            portfolio_weights = adjust_position_scaling(\n",
        "                portfolio_weights, time_to_target\n",
        "            )\n",
        "            # Update returns history\n",
        "            portfolio_returns_history.extend(portfolio_returns.tolist())\n",
        "            # Compute loss with transaction costs\n",
        "            loss = sharpe_loss(portfolio_returns, portfolio_weights, prev_weights)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            # Update prev_weights for the next batch\n",
        "            prev_weights = portfolio_weights.detach()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(data_loader):.4f}\")\n",
        "\n",
        "def backtest(model, data, train_size, test_size, sequence_length, target_sharpe=1.0):\n",
        "    \"\"\"\n",
        "    Performs backtesting by training on a subset of data and testing on future data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PortfolioTransformer model.\n",
        "        data (Tensor): Asset returns data.\n",
        "        train_size (int): Number of samples for training.\n",
        "        test_size (int): Number of samples for testing.\n",
        "        sequence_length (int): Length of input sequences.\n",
        "        target_sharpe (float): Target Sharpe ratio for scaling positions.\n",
        "    \"\"\"\n",
        "    num_samples = len(data) - sequence_length\n",
        "    train_indices = range(train_size)\n",
        "    test_indices = range(train_size, train_size + test_size)\n",
        "\n",
        "    # Prepare training data\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for i in train_indices:\n",
        "        X_train.append(data[i:i+sequence_length])\n",
        "        y_train.append(data[i+sequence_length])\n",
        "    X_train = torch.stack(X_train)\n",
        "    y_train = torch.stack(y_train)\n",
        "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Prepare test data\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    for i in test_indices:\n",
        "        X_test.append(data[i:i+sequence_length])\n",
        "        y_test.append(data[i+sequence_length])\n",
        "    X_test = torch.stack(X_test)\n",
        "    y_test = torch.stack(y_test)\n",
        "\n",
        "    # Train the model\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "    train(model, optimizer, train_loader, num_epochs=10, target_sharpe=target_sharpe)\n",
        "\n",
        "    # Backtest on test data\n",
        "    model.eval()\n",
        "    prev_weights = torch.zeros(y_test.size(1))\n",
        "    portfolio_returns_history = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(X_test)):\n",
        "            batch_X = X_test[i:i+1]  # Shape: (1, seq_len, num_assets)\n",
        "            batch_y = y_test[i:i+1]  # Shape: (1, num_assets)\n",
        "            # Get portfolio weights\n",
        "            portfolio_weights = model(batch_X)\n",
        "            portfolio_weights = portfolio_weights[:, -1, :]\n",
        "            # Compute portfolio returns\n",
        "            portfolio_returns = torch.sum(portfolio_weights * batch_y, dim=1)\n",
        "            # Adjust positions based on expected time to target\n",
        "            time_to_target = compute_expected_time_to_target(\n",
        "                portfolio_returns_history, target_sharpe=target_sharpe\n",
        "            )\n",
        "            portfolio_weights = adjust_position_scaling(\n",
        "                portfolio_weights, time_to_target\n",
        "            )\n",
        "            # Update returns history\n",
        "            portfolio_returns_history.extend(portfolio_returns.tolist())\n",
        "            # Update prev_weights\n",
        "            prev_weights = portfolio_weights.detach()\n",
        "        # Compute cumulative returns and Sharpe ratio\n",
        "        portfolio_returns = np.array(portfolio_returns_history)\n",
        "        cumulative_returns = np.cumprod(1 + portfolio_returns) - 1\n",
        "        mean_return = np.mean(portfolio_returns)\n",
        "        std_return = np.std(portfolio_returns)\n",
        "        sharpe_ratio = mean_return / (std_return + 1e-6) * np.sqrt(252)\n",
        "        print(f\"Cumulative Return: {cumulative_returns[-1]:.4f}\")\n",
        "        print(f\"Annualized Sharpe Ratio: {sharpe_ratio:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qmk8tSvSswV7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Generate random returns data: 100 securities over 1000 time steps\n",
        "num_securities = 100\n",
        "num_time_steps = 1000\n",
        "\n",
        "# Simulate random returns (e.g., normally distributed with small mean and std)\n",
        "returns_data = np.random.normal(loc=0.001, scale=0.01, size=(num_time_steps, num_securities))\n",
        "returns = torch.tensor(returns_data, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRQEHmx-s2Lt",
        "outputId": "968a8d84-fb43-4a7a-cec6-66b7d2efa499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: -0.4861\n",
            "Epoch 2/10, Loss: -0.7983\n",
            "Epoch 3/10, Loss: -0.8931\n",
            "Epoch 4/10, Loss: -0.9067\n",
            "Epoch 5/10, Loss: -0.9006\n",
            "Epoch 6/10, Loss: -0.9224\n",
            "Epoch 7/10, Loss: -0.9115\n",
            "Epoch 8/10, Loss: -0.9196\n",
            "Epoch 9/10, Loss: -0.9191\n",
            "Epoch 10/10, Loss: -0.9201\n",
            "Cumulative Return: 0.2299\n",
            "Annualized Sharpe Ratio: 12.6064\n"
          ]
        }
      ],
      "source": [
        "# Define parameters\n",
        "sequence_length = 20\n",
        "train_size = 700\n",
        "test_size = 200\n",
        "num_assets = num_securities\n",
        "\n",
        "# Initialize the model\n",
        "model = PortfolioTransformer(\n",
        "    num_assets=num_assets,\n",
        "    d_model=64,\n",
        "    nhead=8,\n",
        "    num_layers=4,\n",
        "    seq_len=sequence_length,\n",
        "    dropout=0.1\n",
        ")\n",
        "\n",
        "# Run backtest\n",
        "backtest(model, returns, train_size, test_size, sequence_length, target_sharpe=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7bsziDwk4_nQ",
        "outputId": "f6e16500-03a3-4970-d2b5-f8cd5b9382ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Logistic Regression Model\n",
            "Epoch [1/5], Loss: 0.009969\n",
            "Epoch [2/5], Loss: -0.013706\n",
            "Epoch [3/5], Loss: -0.030145\n",
            "Epoch [4/5], Loss: -0.055203\n",
            "Epoch [5/5], Loss: -0.082532\n",
            "Cumulative Return: -0.071690\n",
            "Annualized Sharpe Ratio: -0.277367\n",
            "\n",
            "Training LSTM Model\n",
            "Epoch [1/5], Loss: 0.015314\n",
            "Epoch [2/5], Loss: -0.019160\n",
            "Epoch [3/5], Loss: -0.023031\n",
            "Epoch [4/5], Loss: -0.035522\n",
            "Epoch [5/5], Loss: -0.023104\n",
            "Cumulative Return: -0.001735\n",
            "Annualized Sharpe Ratio: 0.024882\n",
            "\n",
            "Training CNN Model\n",
            "Epoch [1/5], Loss: 0.008797\n",
            "Epoch [2/5], Loss: -0.006740\n",
            "Epoch [3/5], Loss: -0.012274\n",
            "Epoch [4/5], Loss: -0.018750\n",
            "Epoch [5/5], Loss: -0.021238\n",
            "Cumulative Return: 0.168103\n",
            "Annualized Sharpe Ratio: 0.680245\n",
            "\n",
            "Training Transformer Model\n",
            "Epoch [1/5], Loss: 0.055456\n",
            "Epoch [2/5], Loss: 0.000523\n",
            "Epoch [3/5], Loss: -0.012663\n",
            "Epoch [4/5], Loss: -0.023768\n",
            "Epoch [5/5], Loss: -0.035341\n",
            "Cumulative Return: -0.019282\n",
            "Annualized Sharpe Ratio: -0.069464\n",
            "\n",
            "Training Portfolio Transformer Model\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (20) must match the size of tensor b (64) at non-singleton dimension 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0a32d9d195ad>\u001b[0m in \u001b[0;36m<cell line: 342>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPortfolioTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_assets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_assets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharpe_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0mbacktest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-0a32d9d195ad>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mportfolio_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;31m# Compute portfolio returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mportfolio_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mportfolio_weights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mportfolio_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mportfolio_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mportfolio_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (20) must match the size of tensor b (64) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "# Parameters\n",
        "num_timesteps = 5000  # Total number of time steps\n",
        "num_assets = 10       # Number of assets in the portfolio\n",
        "seq_len = 20          # Length of input sequences\n",
        "d_model = 64          # Model dimension for Transformer\n",
        "batch_size = 64       # Batch size for training\n",
        "num_epochs = 5        # Number of training epochs\n",
        "\n",
        "# Generate synthetic returns data\n",
        "np.random.seed(42)\n",
        "returns_data = np.random.normal(0, 0.01, size=(num_timesteps, num_assets)).astype(np.float32)\n",
        "returns_data = torch.tensor(returns_data)\n",
        "\n",
        "# Dataset and DataLoader for training\n",
        "class ReturnsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for asset returns.\n",
        "\n",
        "    Args:\n",
        "        data (Tensor): Asset returns data of shape (num_timesteps, num_assets).\n",
        "        seq_len (int): Length of input sequences.\n",
        "    \"\"\"\n",
        "    def __init__(self, data, seq_len):\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.data[idx:idx + self.seq_len]\n",
        "        y = self.data[idx + self.seq_len]\n",
        "        return X, y\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(returns_data) * train_ratio)\n",
        "train_data = returns_data[:train_size]\n",
        "test_data = returns_data[train_size:]\n",
        "\n",
        "train_dataset = ReturnsDataset(train_data, seq_len)\n",
        "test_dataset = ReturnsDataset(test_data, seq_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Loss function: Negative Sharpe Ratio\n",
        "def sharpe_loss(portfolio_returns, portfolio_weights, prev_weights, transaction_cost=0.0002):\n",
        "    \"\"\"\n",
        "    Computes the negative Sharpe ratio as the loss function, including transaction costs.\n",
        "\n",
        "    Args:\n",
        "        portfolio_returns (Tensor): Portfolio returns of shape (batch_size,).\n",
        "        portfolio_weights (Tensor): Current portfolio weights of shape (batch_size, num_assets).\n",
        "        prev_weights (Tensor): Previous portfolio weights of shape (batch_size, num_assets).\n",
        "        transaction_cost (float): Transaction cost rate per unit weight change.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Loss value (negative Sharpe ratio).\n",
        "    \"\"\"\n",
        "    # Compute transaction costs based on weight changes\n",
        "    tc = transaction_cost * torch.sum(torch.abs(portfolio_weights - prev_weights), dim=1)\n",
        "    # Net returns after subtracting transaction costs\n",
        "    net_returns = portfolio_returns - tc\n",
        "    # Compute mean and standard deviation of returns\n",
        "    mean_return = torch.mean(net_returns)\n",
        "    std_return = torch.std(net_returns)\n",
        "    # Compute Sharpe ratio\n",
        "    sharpe_ratio = mean_return / (std_return + 1e-6)\n",
        "    # Return negative Sharpe ratio for minimization\n",
        "    return -sharpe_ratio\n",
        "\n",
        "# Base class for models\n",
        "class BaseModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Base class for asset allocation models.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets in the portfolio.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.num_assets = num_assets\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor of shape (batch_size, seq_len, num_assets).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Portfolio weights of shape (batch_size, num_assets).\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Logistic Regression Model\n",
        "class LogisticRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of input features (seq_len * num_assets).\n",
        "        num_assets (int): Number of assets.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_assets):\n",
        "        super(LogisticRegressionModel, self).__init__(num_assets)\n",
        "        self.linear = nn.Linear(input_size, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        out = self.linear(x)\n",
        "        weights = torch.tanh(out)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# LSTM Model\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"\n",
        "    LSTM Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets.\n",
        "        hidden_size (int): Size of hidden state.\n",
        "        num_layers (int): Number of LSTM layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets, hidden_size=64, num_layers=2):\n",
        "        super(LSTMModel, self).__init__(num_assets)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size=num_assets, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        weights = torch.tanh(out)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# CNN Model\n",
        "class CNNModel(BaseModel):\n",
        "    \"\"\"\n",
        "    CNN Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets):\n",
        "        super(CNNModel, self).__init__(num_assets)\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_assets, out_channels=32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.fc = nn.Linear(64, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_assets, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        weights = torch.tanh(x)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Transformer Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets.\n",
        "        d_model (int): Dimension of the model.\n",
        "        nhead (int): Number of attention heads.\n",
        "        num_layers (int): Number of transformer encoder layers.\n",
        "        seq_len (int): Length of the input sequences.\n",
        "        dropout (float): Dropout probability.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets, d_model=64, nhead=4, num_layers=2, seq_len=20, dropout=0.1):\n",
        "        super(TransformerModel, self).__init__(num_assets)\n",
        "        self.d_model = d_model\n",
        "        self.input_proj = nn.Linear(num_assets, d_model)\n",
        "        self.pos_encoder = LearnablePositionalEncoding(seq_len, d_model)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, num_assets)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.input_proj.weight.data.uniform_(-initrange, initrange)\n",
        "        self.input_proj.bias.data.zero_()\n",
        "        self.fc_out.bias.data.zero_()\n",
        "        self.fc_out.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x) * np.sqrt(self.d_model)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x[:, -1, :]  # Last time step\n",
        "        x = self.fc_out(x)\n",
        "        weights = torch.tanh(x)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# Learnable Positional Encoding\n",
        "class LearnablePositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements learnable positional encoding for sequences.\n",
        "\n",
        "    Args:\n",
        "        seq_len (int): The maximum length of the input sequences.\n",
        "        d_model (int): The dimension of the model.\n",
        "    \"\"\"\n",
        "    def __init__(self, seq_len, d_model):\n",
        "        super(LearnablePositionalEncoding, self).__init__()\n",
        "        self.position_embeddings = nn.Embedding(seq_len, d_model)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        positions = torch.arange(0, self.seq_len, device=x.device).unsqueeze(0)\n",
        "        pos_embed = self.position_embeddings(positions)\n",
        "        x = x + pos_embed\n",
        "        return x\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
        "    \"\"\"\n",
        "    Training loop for the model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to train.\n",
        "        train_loader (DataLoader): DataLoader for training data.\n",
        "        criterion (function): Loss function.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer.\n",
        "        num_epochs (int): Number of epochs.\n",
        "        device (torch.device): Computation device.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    prev_weights = torch.zeros((batch_size, model.num_assets)).to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            portfolio_weights = model(X_batch)\n",
        "            # Compute portfolio returns\n",
        "            portfolio_returns = torch.sum(portfolio_weights * y_batch, dim=1)\n",
        "            # Compute loss\n",
        "            loss = criterion(portfolio_returns, portfolio_weights, prev_weights[:portfolio_weights.size(0)])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            # Update prev_weights\n",
        "            prev_weights[:portfolio_weights.size(0)] = portfolio_weights.detach()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}')\n",
        "\n",
        "# Backtesting function\n",
        "def backtest_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Backtesting the model on test data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model.\n",
        "        test_loader (DataLoader): DataLoader for test data.\n",
        "        device (torch.device): Computation device.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    portfolio_returns_history = []\n",
        "    prev_weights = torch.zeros((1, model.num_assets)).to(device)\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            portfolio_weights = model(X_batch)\n",
        "            portfolio_returns = torch.sum(portfolio_weights * y_batch, dim=1)\n",
        "            portfolio_returns_history.extend(portfolio_returns.cpu().numpy())\n",
        "            # Update prev_weights\n",
        "            prev_weights = portfolio_weights.detach()\n",
        "    portfolio_returns = np.array(portfolio_returns_history)\n",
        "    cumulative_returns = np.cumprod(1 + portfolio_returns) - 1\n",
        "    mean_return = np.mean(portfolio_returns)\n",
        "    std_return = np.std(portfolio_returns)\n",
        "    sharpe_ratio = mean_return / (std_return + 1e-6) * np.sqrt(252)\n",
        "    print(f\"Cumulative Return: {cumulative_returns[-1]:.6f}\")\n",
        "    print(f\"Annualized Sharpe Ratio: {sharpe_ratio:.6f}\")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Example usage with Logistic Regression Model\n",
        "print(\"\\nTraining Logistic Regression Model\")\n",
        "model = LogisticRegressionModel(input_size=seq_len * num_assets, num_assets=num_assets)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# Example usage with LSTM Model\n",
        "print(\"\\nTraining LSTM Model\")\n",
        "model = LSTMModel(num_assets=num_assets)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# Example usage with CNN Model\n",
        "print(\"\\nTraining CNN Model\")\n",
        "model = CNNModel(num_assets=num_assets)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# Example usage with Transformer Model\n",
        "print(\"\\nTraining Transformer Model\")\n",
        "model = TransformerModel(num_assets=num_assets, d_model=d_model, seq_len=seq_len)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# New Model provided by the user\n",
        "print(\"\\nTraining Portfolio Transformer Model\")\n",
        "model = PortfolioTransformer(num_assets=num_assets, d_model=d_model, nhead=4, num_layers=2, seq_len=seq_len)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "LsrS2ceu6OaZ",
        "outputId": "96b975e4-5899-429c-8428-b1ec68b78589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression Model\n",
            "Epoch [1/5], Loss: 0.011724\n",
            "Epoch [2/5], Loss: -0.026207\n",
            "Epoch [3/5], Loss: -0.050812\n",
            "Epoch [4/5], Loss: -0.090326\n",
            "Epoch [5/5], Loss: -0.241300\n",
            "Cumulative Return: 0.009765\n",
            "Annualized Sharpe Ratio: 0.071672\n",
            "\n",
            "Training LSTM Model\n",
            "Epoch [1/5], Loss: 0.033284\n",
            "Epoch [2/5], Loss: 0.007168\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-942e74977694>\u001b[0m in \u001b[0;36m<cell line: 401>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_assets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_assets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharpe_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0mbacktest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-942e74977694>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mportfolio_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mportfolio_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mportfolio_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "# Parameters\n",
        "num_timesteps = 5000  # Total number of time steps\n",
        "num_assets = 10       # Number of assets in the portfolio\n",
        "seq_len = 20          # Length of input sequences\n",
        "d_model = 64          # Model dimension for Transformer\n",
        "batch_size = 64       # Batch size for training\n",
        "num_epochs = 5        # Number of training epochs\n",
        "\n",
        "# Generate synthetic returns data\n",
        "np.random.seed(42)\n",
        "returns_data = np.random.normal(0, 0.01, size=(num_timesteps, num_assets)).astype(np.float32)\n",
        "returns_data = torch.tensor(returns_data)\n",
        "\n",
        "# Dataset and DataLoader for training\n",
        "class ReturnsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for asset returns.\n",
        "\n",
        "    Args:\n",
        "        data (Tensor): Asset returns data of shape (num_timesteps, num_assets).\n",
        "        seq_len (int): Length of input sequences.\n",
        "    \"\"\"\n",
        "    def __init__(self, data, seq_len):\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.data[idx:idx + self.seq_len]\n",
        "        y = self.data[idx + self.seq_len]\n",
        "        return X, y\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(returns_data) * train_ratio)\n",
        "train_data = returns_data[:train_size]\n",
        "test_data = returns_data[train_size:]\n",
        "\n",
        "train_dataset = ReturnsDataset(train_data, seq_len)\n",
        "test_dataset = ReturnsDataset(test_data, seq_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # Use batch_size=1 for backtesting\n",
        "\n",
        "# Loss function: Negative Sharpe Ratio\n",
        "def sharpe_loss(portfolio_returns, portfolio_weights, prev_weights, transaction_cost=0.0002):\n",
        "    \"\"\"\n",
        "    Computes the negative Sharpe ratio as the loss function, including transaction costs.\n",
        "\n",
        "    Args:\n",
        "        portfolio_returns (Tensor): Portfolio returns of shape (batch_size,).\n",
        "        portfolio_weights (Tensor): Current portfolio weights of shape (batch_size, num_assets).\n",
        "        prev_weights (Tensor): Previous portfolio weights of shape (batch_size, num_assets).\n",
        "        transaction_cost (float): Transaction cost rate per unit weight change.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Loss value (negative Sharpe ratio).\n",
        "    \"\"\"\n",
        "    # Compute transaction costs based on weight changes\n",
        "    tc = transaction_cost * torch.sum(torch.abs(portfolio_weights - prev_weights), dim=1)\n",
        "    # Net returns after subtracting transaction costs\n",
        "    net_returns = portfolio_returns - tc\n",
        "    # Compute mean and standard deviation of returns\n",
        "    mean_return = torch.mean(net_returns)\n",
        "    std_return = torch.std(net_returns)\n",
        "    # Compute Sharpe ratio\n",
        "    sharpe_ratio = mean_return / (std_return + 1e-6)\n",
        "    # Return negative Sharpe ratio for minimization\n",
        "    return -sharpe_ratio\n",
        "\n",
        "# Base class for models\n",
        "class BaseModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Base class for asset allocation models.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets in the portfolio.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.num_assets = num_assets\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor of shape (batch_size, seq_len, num_assets).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Portfolio weights of shape (batch_size, num_assets).\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Logistic Regression Model\n",
        "class LogisticRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of input features (seq_len * num_assets).\n",
        "        num_assets (int): Number of assets.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_assets):\n",
        "        super(LogisticRegressionModel, self).__init__(num_assets)\n",
        "        self.linear = nn.Linear(input_size, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        out = self.linear(x)\n",
        "        weights = torch.tanh(out)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# LSTM Model\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"\n",
        "    LSTM Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets.\n",
        "        hidden_size (int): Size of hidden state.\n",
        "        num_layers (int): Number of LSTM layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets, hidden_size=64, num_layers=2):\n",
        "        super(LSTMModel, self).__init__(num_assets)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size=num_assets, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        weights = torch.tanh(out)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# CNN Model\n",
        "class CNNModel(BaseModel):\n",
        "    \"\"\"\n",
        "    CNN Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets):\n",
        "        super(CNNModel, self).__init__(num_assets)\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_assets, out_channels=32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.fc = nn.Linear(64, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_assets, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        weights = torch.tanh(x)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Transformer Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets.\n",
        "        d_model (int): Dimension of the model.\n",
        "        nhead (int): Number of attention heads.\n",
        "        num_layers (int): Number of transformer encoder layers.\n",
        "        seq_len (int): Length of the input sequences.\n",
        "        dropout (float): Dropout probability.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets, d_model=64, nhead=4, num_layers=2, seq_len=20, dropout=0.1):\n",
        "        super(TransformerModel, self).__init__(num_assets)\n",
        "        self.d_model = d_model\n",
        "        self.input_proj = nn.Linear(num_assets, d_model)\n",
        "        self.pos_encoder = LearnablePositionalEncoding(seq_len, d_model)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, num_assets)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.input_proj.weight.data.uniform_(-initrange, initrange)\n",
        "        self.input_proj.bias.data.zero_()\n",
        "        self.fc_out.bias.data.zero_()\n",
        "        self.fc_out.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x) * np.sqrt(self.d_model)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # (batch_size, seq_len, d_model)\n",
        "        x = x[:, -1, :]  # Last time step\n",
        "        x = self.fc_out(x)\n",
        "        weights = torch.tanh(x)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# Learnable Positional Encoding\n",
        "class LearnablePositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements learnable positional encoding for sequences.\n",
        "\n",
        "    Args:\n",
        "        seq_len (int): The maximum length of the input sequences.\n",
        "        d_model (int): The dimension of the model.\n",
        "    \"\"\"\n",
        "    def __init__(self, seq_len, d_model):\n",
        "        super(LearnablePositionalEncoding, self).__init__()\n",
        "        self.position_embeddings = nn.Embedding(seq_len, d_model)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0).long()\n",
        "        pos_embed = self.position_embeddings(positions)\n",
        "        x = x + pos_embed\n",
        "        return x\n",
        "\n",
        "# Portfolio Transformer Model\n",
        "class PortfolioTransformer(BaseModel):\n",
        "    \"\"\"\n",
        "    Portfolio Transformer model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets in the portfolio.\n",
        "        d_model (int): Dimension of the model.\n",
        "        nhead (int): Number of attention heads.\n",
        "        num_layers (int): Number of transformer encoder layers.\n",
        "        seq_len (int): Length of the input sequences.\n",
        "        dropout (float): Dropout probability.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, num_assets, d_model, nhead, num_layers, seq_len, dropout=0.1\n",
        "    ):\n",
        "        super(PortfolioTransformer, self).__init__(num_assets)\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Input projection layer to map asset returns to model dimension\n",
        "        self.input_proj = nn.Linear(num_assets, d_model)\n",
        "\n",
        "        # Learnable positional encoding\n",
        "        self.pos_encoder = LearnablePositionalEncoding(seq_len, d_model)\n",
        "\n",
        "        # Transformer encoder layers\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead, dropout=dropout\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layers, num_layers=num_layers\n",
        "        )\n",
        "\n",
        "        # Output layer to map back to asset space\n",
        "        self.fc_out = nn.Linear(d_model, num_assets)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"\n",
        "        Initializes weights for better convergence.\n",
        "        \"\"\"\n",
        "        initrange = 0.1\n",
        "        self.input_proj.weight.data.uniform_(-initrange, initrange)\n",
        "        self.input_proj.bias.data.zero_()\n",
        "        self.fc_out.bias.data.zero_()\n",
        "        self.fc_out.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor of shape (batch_size, seq_len, num_assets).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Portfolio weights of shape (batch_size, num_assets).\n",
        "        \"\"\"\n",
        "        # Project input to model dimension and scale\n",
        "        x = self.input_proj(x) * np.sqrt(self.d_model)\n",
        "        # Add positional encoding\n",
        "        x = self.pos_encoder(x)\n",
        "        # Permute dimensions to match expected input of TransformerEncoder\n",
        "        x = x.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
        "        # Pass through transformer encoder\n",
        "        x = self.transformer_encoder(x)\n",
        "        # Permute back to (batch_size, seq_len, d_model)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        # Get the last time step\n",
        "        x = x[:, -1, :]  # (batch_size, d_model)\n",
        "        # Map back to asset space\n",
        "        s_i_t = self.fc_out(x)  # Shape: (batch_size, num_assets)\n",
        "        # Apply activation and normalize weights\n",
        "        weights = torch.tanh(s_i_t)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
        "    \"\"\"\n",
        "    Training loop for the model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to train.\n",
        "        train_loader (DataLoader): DataLoader for training data.\n",
        "        criterion (function): Loss function.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer.\n",
        "        num_epochs (int): Number of epochs.\n",
        "        device (torch.device): Computation device.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    prev_weights = torch.zeros((batch_size, model.num_assets)).to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            portfolio_weights = model(X_batch)\n",
        "            # Compute portfolio returns\n",
        "            portfolio_returns = torch.sum(portfolio_weights * y_batch, dim=1)\n",
        "            # Compute loss\n",
        "            loss = criterion(portfolio_returns, portfolio_weights, prev_weights[:portfolio_weights.size(0)])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            # Update prev_weights\n",
        "            prev_weights[:portfolio_weights.size(0)] = portfolio_weights.detach()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}')\n",
        "\n",
        "# Backtesting function\n",
        "def backtest_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Backtesting the model on test data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model.\n",
        "        test_loader (DataLoader): DataLoader for test data.\n",
        "        device (torch.device): Computation device.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    portfolio_returns_history = []\n",
        "    prev_weights = torch.zeros((1, model.num_assets)).to(device)\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            portfolio_weights = model(X_batch)\n",
        "            portfolio_returns = torch.sum(portfolio_weights * y_batch, dim=1)\n",
        "            portfolio_returns_history.extend(portfolio_returns.cpu().numpy())\n",
        "            # Update prev_weights\n",
        "            prev_weights = portfolio_weights.detach()\n",
        "    portfolio_returns = np.array(portfolio_returns_history)\n",
        "    cumulative_returns = np.cumprod(1 + portfolio_returns) - 1\n",
        "    mean_return = np.mean(portfolio_returns)\n",
        "    std_return = np.std(portfolio_returns)\n",
        "    sharpe_ratio = mean_return / (std_return + 1e-6) * np.sqrt(252)\n",
        "    print(f\"Cumulative Return: {cumulative_returns[-1]:.6f}\")\n",
        "    print(f\"Annualized Sharpe Ratio: {sharpe_ratio:.6f}\")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Example usage with Logistic Regression Model\n",
        "print(\"\\nTraining Logistic Regression Model\")\n",
        "model = LogisticRegressionModel(input_size=seq_len * num_assets, num_assets=num_assets)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# Example usage with LSTM Model\n",
        "print(\"\\nTraining LSTM Model\")\n",
        "model = LSTMModel(num_assets=num_assets)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# Example usage with CNN Model\n",
        "print(\"\\nTraining CNN Model\")\n",
        "model = CNNModel(num_assets=num_assets)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# Example usage with Transformer Model\n",
        "print(\"\\nTraining Transformer Model\")\n",
        "model = TransformerModel(num_assets=num_assets, d_model=d_model, seq_len=seq_len)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# New Model provided by the user\n",
        "print(\"\\nTraining Portfolio Transformer Model\")\n",
        "model = PortfolioTransformer(num_assets=num_assets, d_model=d_model, nhead=4, num_layers=2, seq_len=seq_len)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61KwcCfCcewe",
        "outputId": "5a1ab79c-9275-4adf-82d7-830d2a52a3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                            Version\n",
            "---------------------------------- --------------------\n",
            "absl-py                            1.4.0\n",
            "accelerate                         0.34.2\n",
            "aiohappyeyeballs                   2.4.3\n",
            "aiohttp                            3.10.10\n",
            "aiosignal                          1.3.1\n",
            "alabaster                          0.7.16\n",
            "albucore                           0.0.16\n",
            "albumentations                     1.4.15\n",
            "altair                             4.2.2\n",
            "annotated-types                    0.7.0\n",
            "anyio                              3.7.1\n",
            "argon2-cffi                        23.1.0\n",
            "argon2-cffi-bindings               21.2.0\n",
            "array_record                       0.5.1\n",
            "arviz                              0.19.0\n",
            "astropy                            6.1.4\n",
            "astropy-iers-data                  0.2024.10.14.0.32.55\n",
            "astunparse                         1.6.3\n",
            "async-timeout                      4.0.3\n",
            "atpublic                           4.1.0\n",
            "attrs                              24.2.0\n",
            "audioread                          3.0.1\n",
            "autograd                           1.7.0\n",
            "babel                              2.16.0\n",
            "backcall                           0.2.0\n",
            "beautifulsoup4                     4.12.3\n",
            "bigframes                          1.22.0\n",
            "bigquery-magics                    0.4.0\n",
            "bleach                             6.1.0\n",
            "blinker                            1.4\n",
            "blis                               0.7.11\n",
            "blosc2                             2.0.0\n",
            "bokeh                              3.4.3\n",
            "Bottleneck                         1.4.1\n",
            "bqplot                             0.12.43\n",
            "branca                             0.8.0\n",
            "CacheControl                       0.14.0\n",
            "cachetools                         5.5.0\n",
            "catalogue                          2.0.10\n",
            "certifi                            2024.8.30\n",
            "cffi                               1.17.1\n",
            "chardet                            5.2.0\n",
            "charset-normalizer                 3.4.0\n",
            "chex                               0.1.87\n",
            "clarabel                           0.9.0\n",
            "click                              8.1.7\n",
            "cloudpathlib                       0.19.0\n",
            "cloudpickle                        3.1.0\n",
            "cmake                              3.30.4\n",
            "cmdstanpy                          1.2.4\n",
            "colorcet                           3.1.0\n",
            "colorlover                         0.3.0\n",
            "colour                             0.1.5\n",
            "community                          1.0.0b1\n",
            "confection                         0.1.5\n",
            "cons                               0.4.6\n",
            "contourpy                          1.3.0\n",
            "cryptography                       43.0.1\n",
            "cuda-python                        12.2.1\n",
            "cudf-cu12                          24.10.1\n",
            "cufflinks                          0.17.3\n",
            "cupy-cuda12x                       12.2.0\n",
            "cvxopt                             1.3.2\n",
            "cvxpy                              1.5.3\n",
            "cycler                             0.12.1\n",
            "cymem                              2.0.8\n",
            "Cython                             3.0.11\n",
            "dask                               2024.8.2\n",
            "datascience                        0.17.6\n",
            "db-dtypes                          1.3.0\n",
            "dbus-python                        1.2.18\n",
            "debugpy                            1.6.6\n",
            "decorator                          4.4.2\n",
            "defusedxml                         0.7.1\n",
            "Deprecated                         1.2.14\n",
            "diffusers                          0.30.3\n",
            "distro                             1.7.0\n",
            "dlib                               19.24.2\n",
            "dm-tree                            0.1.8\n",
            "docker-pycreds                     0.4.0\n",
            "docstring_parser                   0.16\n",
            "docutils                           0.18.1\n",
            "dopamine_rl                        4.0.9\n",
            "duckdb                             1.1.2\n",
            "earthengine-api                    1.0.0\n",
            "easydict                           1.13\n",
            "ecos                               2.0.14\n",
            "editdistance                       0.8.1\n",
            "eerepr                             0.0.4\n",
            "einops                             0.8.0\n",
            "en-core-web-sm                     3.7.1\n",
            "entrypoints                        0.4\n",
            "et-xmlfile                         1.1.0\n",
            "etils                              1.9.4\n",
            "etuples                            0.3.9\n",
            "eval_type_backport                 0.2.0\n",
            "exceptiongroup                     1.2.2\n",
            "fastai                             2.7.17\n",
            "fastcore                           1.7.16\n",
            "fastdownload                       0.0.7\n",
            "fastjsonschema                     2.20.0\n",
            "fastprogress                       1.0.3\n",
            "fastrlock                          0.8.2\n",
            "filelock                           3.16.1\n",
            "firebase-admin                     6.5.0\n",
            "Flask                              2.2.5\n",
            "flatbuffers                        24.3.25\n",
            "flax                               0.8.5\n",
            "folium                             0.17.0\n",
            "fonttools                          4.54.1\n",
            "frozendict                         2.4.6\n",
            "frozenlist                         1.4.1\n",
            "fsspec                             2024.6.1\n",
            "future                             1.0.0\n",
            "gast                               0.6.0\n",
            "gcsfs                              2024.6.1\n",
            "GDAL                               3.6.4\n",
            "gdown                              5.2.0\n",
            "geemap                             0.34.5\n",
            "gensim                             4.3.3\n",
            "geocoder                           1.38.1\n",
            "geographiclib                      2.0\n",
            "geopandas                          1.0.1\n",
            "geopy                              2.4.1\n",
            "gin-config                         0.5.0\n",
            "gitdb                              4.0.11\n",
            "GitPython                          3.1.43\n",
            "glob2                              0.7\n",
            "google                             2.0.3\n",
            "google-ai-generativelanguage       0.6.6\n",
            "google-api-core                    2.19.2\n",
            "google-api-python-client           2.137.0\n",
            "google-auth                        2.27.0\n",
            "google-auth-httplib2               0.2.0\n",
            "google-auth-oauthlib               1.2.1\n",
            "google-cloud-aiplatform            1.70.0\n",
            "google-cloud-bigquery              3.25.0\n",
            "google-cloud-bigquery-connection   1.15.5\n",
            "google-cloud-bigquery-storage      2.27.0\n",
            "google-cloud-bigtable              2.26.0\n",
            "google-cloud-core                  2.4.1\n",
            "google-cloud-datastore             2.19.0\n",
            "google-cloud-firestore             2.16.1\n",
            "google-cloud-functions             1.16.5\n",
            "google-cloud-iam                   2.15.2\n",
            "google-cloud-language              2.13.4\n",
            "google-cloud-pubsub                2.25.0\n",
            "google-cloud-resource-manager      1.12.5\n",
            "google-cloud-storage               2.8.0\n",
            "google-cloud-translate             3.15.5\n",
            "google-colab                       1.0.0\n",
            "google-crc32c                      1.6.0\n",
            "google-generativeai                0.7.2\n",
            "google-pasta                       0.2.0\n",
            "google-resumable-media             2.7.2\n",
            "googleapis-common-protos           1.65.0\n",
            "googledrivedownloader              0.4\n",
            "graphviz                           0.20.3\n",
            "greenlet                           3.1.1\n",
            "grpc-google-iam-v1                 0.13.1\n",
            "grpcio                             1.64.1\n",
            "grpcio-status                      1.48.2\n",
            "gspread                            6.0.2\n",
            "gspread-dataframe                  3.3.1\n",
            "gym                                0.25.2\n",
            "gym-notices                        0.0.8\n",
            "h5netcdf                           1.4.0\n",
            "h5py                               3.11.0\n",
            "holidays                           0.58\n",
            "holoviews                          1.19.1\n",
            "html5lib                           1.1\n",
            "httpimport                         1.4.0\n",
            "httplib2                           0.22.0\n",
            "huggingface-hub                    0.24.7\n",
            "humanize                           4.10.0\n",
            "hyperopt                           0.2.7\n",
            "ibis-framework                     9.2.0\n",
            "idna                               3.10\n",
            "imageio                            2.35.1\n",
            "imageio-ffmpeg                     0.5.1\n",
            "imagesize                          1.4.1\n",
            "imbalanced-learn                   0.12.4\n",
            "imgaug                             0.4.0\n",
            "immutabledict                      4.2.0\n",
            "importlib_metadata                 8.5.0\n",
            "importlib_resources                6.4.5\n",
            "imutils                            0.5.4\n",
            "inflect                            7.4.0\n",
            "iniconfig                          2.0.0\n",
            "intel-cmplr-lib-ur                 2024.2.1\n",
            "intel-openmp                       2024.2.1\n",
            "ipyevents                          2.0.2\n",
            "ipyfilechooser                     0.6.0\n",
            "ipykernel                          5.5.6\n",
            "ipyleaflet                         0.19.2\n",
            "ipyparallel                        8.8.0\n",
            "ipython                            7.34.0\n",
            "ipython-genutils                   0.2.0\n",
            "ipython-sql                        0.5.0\n",
            "ipytree                            0.2.2\n",
            "ipywidgets                         7.7.1\n",
            "itsdangerous                       2.2.0\n",
            "jax                                0.4.33\n",
            "jax-cuda12-pjrt                    0.4.33\n",
            "jax-cuda12-plugin                  0.4.33\n",
            "jaxlib                             0.4.33\n",
            "jeepney                            0.7.1\n",
            "jellyfish                          1.1.0\n",
            "jieba                              0.42.1\n",
            "Jinja2                             3.1.4\n",
            "joblib                             1.4.2\n",
            "jsonpickle                         3.3.0\n",
            "jsonschema                         4.23.0\n",
            "jsonschema-specifications          2024.10.1\n",
            "jupyter-client                     6.1.12\n",
            "jupyter-console                    6.1.0\n",
            "jupyter_core                       5.7.2\n",
            "jupyter-leaflet                    0.19.2\n",
            "jupyter-server                     1.24.0\n",
            "jupyterlab_pygments                0.3.0\n",
            "jupyterlab_widgets                 3.0.13\n",
            "kaggle                             1.6.17\n",
            "kagglehub                          0.3.2\n",
            "keras                              3.4.1\n",
            "keyring                            23.5.0\n",
            "kiwisolver                         1.4.7\n",
            "langcodes                          3.4.1\n",
            "language_data                      1.2.0\n",
            "launchpadlib                       1.10.16\n",
            "lazr.restfulclient                 0.14.4\n",
            "lazr.uri                           1.0.6\n",
            "lazy_loader                        0.4\n",
            "libclang                           18.1.1\n",
            "libcudf-cu12                       24.10.1\n",
            "librosa                            0.10.2.post1\n",
            "lightgbm                           4.5.0\n",
            "lightning                          2.4.0\n",
            "lightning-utilities                0.11.8\n",
            "linkify-it-py                      2.0.3\n",
            "llvmlite                           0.43.0\n",
            "locket                             1.0.0\n",
            "logical-unification                0.4.6\n",
            "lxml                               4.9.4\n",
            "marisa-trie                        1.2.1\n",
            "Markdown                           3.7\n",
            "markdown-it-py                     3.0.0\n",
            "MarkupSafe                         3.0.1\n",
            "matplotlib                         3.7.1\n",
            "matplotlib-inline                  0.1.7\n",
            "matplotlib-venn                    1.1.1\n",
            "mdit-py-plugins                    0.4.2\n",
            "mdurl                              0.1.2\n",
            "miniKanren                         1.0.3\n",
            "missingno                          0.5.2\n",
            "mistune                            0.8.4\n",
            "mizani                             0.11.4\n",
            "mkl                                2024.2.2\n",
            "ml-dtypes                          0.4.1\n",
            "mlxtend                            0.23.1\n",
            "more-itertools                     10.5.0\n",
            "moviepy                            1.0.3\n",
            "mpmath                             1.3.0\n",
            "msgpack                            1.1.0\n",
            "multidict                          6.1.0\n",
            "multipledispatch                   1.0.0\n",
            "multitasking                       0.0.11\n",
            "murmurhash                         1.0.10\n",
            "music21                            9.1.0\n",
            "namex                              0.0.8\n",
            "natsort                            8.4.0\n",
            "nbclassic                          1.1.0\n",
            "nbclient                           0.10.0\n",
            "nbconvert                          6.5.4\n",
            "nbformat                           5.10.4\n",
            "nest-asyncio                       1.6.0\n",
            "networkx                           3.4.1\n",
            "nibabel                            5.2.1\n",
            "nltk                               3.8.1\n",
            "notebook                           6.5.5\n",
            "notebook_shim                      0.2.4\n",
            "numba                              0.60.0\n",
            "numexpr                            2.10.1\n",
            "numpy                              1.26.4\n",
            "nvidia-cublas-cu12                 12.6.3.3\n",
            "nvidia-cuda-cupti-cu12             12.6.80\n",
            "nvidia-cuda-nvcc-cu12              12.6.77\n",
            "nvidia-cuda-runtime-cu12           12.6.77\n",
            "nvidia-cudnn-cu12                  9.5.0.50\n",
            "nvidia-cufft-cu12                  11.3.0.4\n",
            "nvidia-curand-cu12                 10.3.7.77\n",
            "nvidia-cusolver-cu12               11.7.1.2\n",
            "nvidia-cusparse-cu12               12.5.4.2\n",
            "nvidia-nccl-cu12                   2.23.4\n",
            "nvidia-nvjitlink-cu12              12.6.77\n",
            "nvtx                               0.2.10\n",
            "nx-cugraph-cu12                    24.10.0\n",
            "oauth2client                       4.1.3\n",
            "oauthlib                           3.2.2\n",
            "opencv-contrib-python              4.10.0.84\n",
            "opencv-python                      4.10.0.84\n",
            "opencv-python-headless             4.10.0.84\n",
            "openpyxl                           3.1.5\n",
            "opentelemetry-api                  1.16.0\n",
            "opentelemetry-sdk                  1.16.0\n",
            "opentelemetry-semantic-conventions 0.37b0\n",
            "opt_einsum                         3.4.0\n",
            "optax                              0.2.3\n",
            "optree                             0.13.0\n",
            "orbax-checkpoint                   0.6.4\n",
            "osqp                               0.6.7.post3\n",
            "packaging                          24.1\n",
            "pandas                             2.2.2\n",
            "pandas-datareader                  0.10.0\n",
            "pandas-gbq                         0.23.2\n",
            "pandas-stubs                       2.2.2.240909\n",
            "pandocfilters                      1.5.1\n",
            "panel                              1.4.5\n",
            "param                              2.1.1\n",
            "parso                              0.8.4\n",
            "parsy                              2.1\n",
            "partd                              1.4.2\n",
            "pathlib                            1.0.1\n",
            "patsy                              0.5.6\n",
            "peewee                             3.17.7\n",
            "pexpect                            4.9.0\n",
            "pickleshare                        0.7.5\n",
            "pillow                             10.4.0\n",
            "pip                                24.1.2\n",
            "platformdirs                       4.3.6\n",
            "plotly                             5.24.1\n",
            "plotnine                           0.13.6\n",
            "pluggy                             1.5.0\n",
            "polars                             1.7.1\n",
            "pooch                              1.8.2\n",
            "portpicker                         1.5.2\n",
            "preshed                            3.0.9\n",
            "prettytable                        3.11.0\n",
            "proglog                            0.1.10\n",
            "progressbar2                       4.5.0\n",
            "prometheus_client                  0.21.0\n",
            "promise                            2.3\n",
            "prompt_toolkit                     3.0.48\n",
            "propcache                          0.2.0\n",
            "prophet                            1.1.6\n",
            "proto-plus                         1.24.0\n",
            "protobuf                           3.20.3\n",
            "psutil                             5.9.5\n",
            "psycopg2                           2.9.9\n",
            "ptyprocess                         0.7.0\n",
            "py-cpuinfo                         9.0.0\n",
            "py4j                               0.10.9.7\n",
            "pyarrow                            16.1.0\n",
            "pyarrow-hotfix                     0.6\n",
            "pyasn1                             0.6.1\n",
            "pyasn1_modules                     0.4.1\n",
            "pycocotools                        2.0.8\n",
            "pycparser                          2.22\n",
            "pydantic                           2.9.2\n",
            "pydantic_core                      2.23.4\n",
            "pydata-google-auth                 1.8.2\n",
            "pydot                              3.0.2\n",
            "pydotplus                          2.0.2\n",
            "PyDrive                            1.3.1\n",
            "PyDrive2                           1.20.0\n",
            "pyerfa                             2.0.1.4\n",
            "pygame                             2.6.1\n",
            "pygit2                             1.15.1\n",
            "Pygments                           2.18.0\n",
            "PyGObject                          3.42.1\n",
            "PyJWT                              2.9.0\n",
            "pylibcudf-cu12                     24.10.1\n",
            "pylibcugraph-cu12                  24.10.0\n",
            "pylibraft-cu12                     24.10.0\n",
            "pymc                               5.16.2\n",
            "pymystem3                          0.2.0\n",
            "pynvjitlink-cu12                   0.3.0\n",
            "pyogrio                            0.10.0\n",
            "PyOpenGL                           3.1.7\n",
            "pyOpenSSL                          24.2.1\n",
            "pyparsing                          3.2.0\n",
            "pyperclip                          1.9.0\n",
            "pyproj                             3.7.0\n",
            "pyshp                              2.3.1\n",
            "PySocks                            1.7.1\n",
            "pyspark                            3.5.3\n",
            "pytensor                           2.25.5\n",
            "pytest                             7.4.4\n",
            "python-apt                         0.0.0\n",
            "python-box                         7.2.0\n",
            "python-dateutil                    2.8.2\n",
            "python-louvain                     0.16\n",
            "python-slugify                     8.0.4\n",
            "python-utils                       3.9.0\n",
            "pytorch-forecasting                1.1.1\n",
            "pytorch-lightning                  2.4.0\n",
            "pytz                               2024.2\n",
            "pyviz_comms                        3.0.3\n",
            "PyYAML                             6.0.2\n",
            "pyzmq                              24.0.1\n",
            "qdldl                              0.1.7.post4\n",
            "ratelim                            0.1.6\n",
            "referencing                        0.35.1\n",
            "regex                              2024.9.11\n",
            "requests                           2.32.3\n",
            "requests-oauthlib                  1.3.1\n",
            "requirements-parser                0.9.0\n",
            "rich                               13.9.2\n",
            "rmm-cu12                           24.10.0\n",
            "rpds-py                            0.20.0\n",
            "rpy2                               3.4.2\n",
            "rsa                                4.9\n",
            "safetensors                        0.4.5\n",
            "scikit-image                       0.24.0\n",
            "scikit-learn                       1.5.2\n",
            "scipy                              1.13.1\n",
            "scooby                             0.10.0\n",
            "scs                                3.2.7\n",
            "seaborn                            0.13.2\n",
            "SecretStorage                      3.3.1\n",
            "Send2Trash                         1.8.3\n",
            "sentencepiece                      0.2.0\n",
            "sentry-sdk                         2.16.0\n",
            "setproctitle                       1.3.3\n",
            "setuptools                         75.1.0\n",
            "shap                               0.46.0\n",
            "shapely                            2.0.6\n",
            "shellingham                        1.5.4\n",
            "simple-parsing                     0.1.6\n",
            "six                                1.16.0\n",
            "sklearn-pandas                     2.2.0\n",
            "slicer                             0.0.8\n",
            "smart-open                         7.0.5\n",
            "smmap                              5.0.1\n",
            "sniffio                            1.3.1\n",
            "snowballstemmer                    2.2.0\n",
            "soundfile                          0.12.1\n",
            "soupsieve                          2.6\n",
            "soxr                               0.5.0.post1\n",
            "spacy                              3.7.5\n",
            "spacy-legacy                       3.0.12\n",
            "spacy-loggers                      1.0.5\n",
            "Sphinx                             5.0.2\n",
            "sphinxcontrib-applehelp            2.0.0\n",
            "sphinxcontrib-devhelp              2.0.0\n",
            "sphinxcontrib-htmlhelp             2.1.0\n",
            "sphinxcontrib-jsmath               1.0.1\n",
            "sphinxcontrib-qthelp               2.0.0\n",
            "sphinxcontrib-serializinghtml      2.0.0\n",
            "SQLAlchemy                         2.0.35\n",
            "sqlglot                            25.1.0\n",
            "sqlparse                           0.5.1\n",
            "srsly                              2.4.8\n",
            "stanio                             0.5.1\n",
            "statsmodels                        0.14.4\n",
            "StrEnum                            0.4.15\n",
            "sympy                              1.13.3\n",
            "tables                             3.8.0\n",
            "tabulate                           0.9.0\n",
            "tbb                                2021.13.1\n",
            "tenacity                           9.0.0\n",
            "tensorboard                        2.17.0\n",
            "tensorboard-data-server            0.7.2\n",
            "tensorflow                         2.17.0\n",
            "tensorflow-datasets                4.9.6\n",
            "tensorflow-hub                     0.16.1\n",
            "tensorflow-io-gcs-filesystem       0.37.1\n",
            "tensorflow-metadata                1.16.1\n",
            "tensorflow-probability             0.24.0\n",
            "tensorstore                        0.1.66\n",
            "termcolor                          2.5.0\n",
            "terminado                          0.18.1\n",
            "text-unidecode                     1.3\n",
            "textblob                           0.17.1\n",
            "tf_keras                           2.17.0\n",
            "tf-slim                            1.1.0\n",
            "thinc                              8.2.5\n",
            "threadpoolctl                      3.5.0\n",
            "tifffile                           2024.9.20\n",
            "timm                               1.0.10\n",
            "tinycss2                           1.3.0\n",
            "tokenizers                         0.19.1\n",
            "toml                               0.10.2\n",
            "tomli                              2.0.2\n",
            "toolz                              0.12.1\n",
            "torch                              2.4.1+cu121\n",
            "torchaudio                         2.4.1+cu121\n",
            "torchcde                           0.2.5\n",
            "torchdiffeq                        0.2.4\n",
            "torchmetrics                       1.5.0\n",
            "torchsde                           0.2.6\n",
            "torchsummary                       1.5.1\n",
            "torchvision                        0.19.1+cu121\n",
            "tornado                            6.3.3\n",
            "tqdm                               4.66.5\n",
            "traitlets                          5.7.1\n",
            "traittypes                         0.2.1\n",
            "trampoline                         0.1.2\n",
            "transformers                       4.44.2\n",
            "tweepy                             4.14.0\n",
            "typeguard                          4.3.0\n",
            "typer                              0.12.5\n",
            "types-pytz                         2024.2.0.20241003\n",
            "types-setuptools                   75.1.0.20241014\n",
            "typing_extensions                  4.12.2\n",
            "tzdata                             2024.2\n",
            "tzlocal                            5.2\n",
            "uc-micro-py                        1.0.3\n",
            "uritemplate                        4.1.1\n",
            "urllib3                            2.2.3\n",
            "vega-datasets                      0.9.0\n",
            "wadllib                            1.3.6\n",
            "wandb                              0.18.3\n",
            "wasabi                             1.1.3\n",
            "wcwidth                            0.2.13\n",
            "weasel                             0.4.1\n",
            "webcolors                          24.8.0\n",
            "webencodings                       0.5.1\n",
            "websocket-client                   1.8.0\n",
            "Werkzeug                           3.0.4\n",
            "wheel                              0.44.0\n",
            "widgetsnbextension                 3.6.9\n",
            "wordcloud                          1.9.3\n",
            "wrapt                              1.16.0\n",
            "xarray                             2024.9.0\n",
            "xarray-einstats                    0.8.0\n",
            "xgboost                            2.1.1\n",
            "xlrd                               2.0.1\n",
            "xyzservices                        2024.9.0\n",
            "yarl                               1.15.2\n",
            "yellowbrick                        1.5\n",
            "yfinance                           0.2.44\n",
            "zipp                               3.20.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch_timeseriues"
      ],
      "metadata": {
        "id": "fCNbWBmJv51t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHuqO_iLcS3i",
        "outputId": "226cd546-0f03-48bc-dfd5-3adb6c318291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "accelerate==0.34.2\n",
            "aiohappyeyeballs==2.4.3\n",
            "aiohttp==3.10.10\n",
            "aiosignal==1.3.1\n",
            "alabaster==0.7.16\n",
            "albucore==0.0.16\n",
            "albumentations==1.4.15\n",
            "altair==4.2.2\n",
            "annotated-types==0.7.0\n",
            "anyio==3.7.1\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array_record==0.5.1\n",
            "arviz==0.19.0\n",
            "astropy==6.1.4\n",
            "astropy-iers-data==0.2024.10.14.0.32.55\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.3\n",
            "atpublic==4.1.0\n",
            "attrs==24.2.0\n",
            "audioread==3.0.1\n",
            "autograd==1.7.0\n",
            "babel==2.16.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.12.3\n",
            "bigframes==1.22.0\n",
            "bigquery-magics==0.4.0\n",
            "bleach==6.1.0\n",
            "blinker==1.4\n",
            "blis==0.7.11\n",
            "blosc2==2.0.0\n",
            "bokeh==3.4.3\n",
            "Bottleneck==1.4.1\n",
            "bqplot==0.12.43\n",
            "branca==0.8.0\n",
            "CacheControl==0.14.0\n",
            "cachetools==5.5.0\n",
            "catalogue==2.0.10\n",
            "certifi==2024.8.30\n",
            "cffi==1.17.1\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.4.0\n",
            "chex==0.1.87\n",
            "clarabel==0.9.0\n",
            "click==8.1.7\n",
            "cloudpathlib==0.19.0\n",
            "cloudpickle==3.1.0\n",
            "cmake==3.30.4\n",
            "cmdstanpy==1.2.4\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.6\n",
            "contourpy==1.3.0\n",
            "cryptography==43.0.1\n",
            "cuda-python==12.2.1\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.10.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda12x==12.2.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.5.3\n",
            "cycler==0.12.1\n",
            "cymem==2.0.8\n",
            "Cython==3.0.11\n",
            "dask==2024.8.2\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.3.0\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.6.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "Deprecated==1.2.14\n",
            "diffusers==0.30.3\n",
            "distro==1.7.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.8\n",
            "docker-pycreds==0.4.0\n",
            "docstring_parser==0.16\n",
            "docutils==0.18.1\n",
            "dopamine_rl==4.0.9\n",
            "duckdb==1.1.2\n",
            "earthengine-api==1.0.0\n",
            "easydict==1.13\n",
            "ecos==2.0.14\n",
            "editdistance==0.8.1\n",
            "eerepr==0.0.4\n",
            "einops==0.8.0\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
            "entrypoints==0.4\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.9.4\n",
            "etuples==0.3.9\n",
            "eval_type_backport==0.2.0\n",
            "exceptiongroup==1.2.2\n",
            "fastai==2.7.17\n",
            "fastcore==1.7.16\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.20.0\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.2\n",
            "filelock==3.16.1\n",
            "firebase-admin==6.5.0\n",
            "Flask==2.2.5\n",
            "flatbuffers==24.3.25\n",
            "flax==0.8.5\n",
            "folium==0.17.0\n",
            "fonttools==4.54.1\n",
            "frozendict==2.4.6\n",
            "frozenlist==1.4.1\n",
            "fsspec==2024.6.1\n",
            "future==1.0.0\n",
            "gast==0.6.0\n",
            "gcsfs==2024.6.1\n",
            "GDAL==3.6.4\n",
            "gdown==5.2.0\n",
            "geemap==0.34.5\n",
            "gensim==4.3.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==1.0.1\n",
            "geopy==2.4.1\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.11\n",
            "GitPython==3.1.43\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.6.6\n",
            "google-api-core==2.19.2\n",
            "google-api-python-client==2.137.0\n",
            "google-auth==2.27.0\n",
            "google-auth-httplib2==0.2.0\n",
            "google-auth-oauthlib==1.2.1\n",
            "google-cloud-aiplatform==1.70.0\n",
            "google-cloud-bigquery==3.25.0\n",
            "google-cloud-bigquery-connection==1.15.5\n",
            "google-cloud-bigquery-storage==2.27.0\n",
            "google-cloud-bigtable==2.26.0\n",
            "google-cloud-core==2.4.1\n",
            "google-cloud-datastore==2.19.0\n",
            "google-cloud-firestore==2.16.1\n",
            "google-cloud-functions==1.16.5\n",
            "google-cloud-iam==2.15.2\n",
            "google-cloud-language==2.13.4\n",
            "google-cloud-pubsub==2.25.0\n",
            "google-cloud-resource-manager==1.12.5\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.15.5\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
            "google-crc32c==1.6.0\n",
            "google-generativeai==0.7.2\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.2\n",
            "googleapis-common-protos==1.65.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.3\n",
            "greenlet==3.1.1\n",
            "grpc-google-iam-v1==0.13.1\n",
            "grpcio==1.64.1\n",
            "grpcio-status==1.48.2\n",
            "gspread==6.0.2\n",
            "gspread-dataframe==3.3.1\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h5netcdf==1.4.0\n",
            "h5py==3.11.0\n",
            "holidays==0.58\n",
            "holoviews==1.19.1\n",
            "html5lib==1.1\n",
            "httpimport==1.4.0\n",
            "httplib2==0.22.0\n",
            "huggingface-hub==0.24.7\n",
            "humanize==4.10.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==9.2.0\n",
            "idna==3.10\n",
            "imageio==2.35.1\n",
            "imageio-ffmpeg==0.5.1\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.12.4\n",
            "imgaug==0.4.0\n",
            "immutabledict==4.2.0\n",
            "importlib_metadata==8.5.0\n",
            "importlib_resources==6.4.5\n",
            "imutils==0.5.4\n",
            "inflect==7.4.0\n",
            "iniconfig==2.0.0\n",
            "intel-cmplr-lib-ur==2024.2.1\n",
            "intel-openmp==2024.2.1\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==5.5.6\n",
            "ipyleaflet==0.19.2\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.2.0\n",
            "jax==0.4.33\n",
            "jax-cuda12-pjrt==0.4.33\n",
            "jax-cuda12-plugin==0.4.33\n",
            "jaxlib==0.4.33\n",
            "jeepney==0.7.1\n",
            "jellyfish==1.1.0\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.4\n",
            "joblib==1.4.2\n",
            "jsonpickle==3.3.0\n",
            "jsonschema==4.23.0\n",
            "jsonschema-specifications==2024.10.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-leaflet==0.19.2\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.7.2\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.13\n",
            "kaggle==1.6.17\n",
            "kagglehub==0.3.2\n",
            "keras==3.4.1\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.7\n",
            "langcodes==3.4.1\n",
            "language_data==1.2.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "libcudf-cu12 @ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-24.10.1-py3-none-manylinux_2_28_x86_64.whl\n",
            "librosa==0.10.2.post1\n",
            "lightgbm==4.5.0\n",
            "lightning==2.4.0\n",
            "lightning-utilities==0.11.8\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.43.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==4.9.4\n",
            "marisa-trie==1.2.1\n",
            "Markdown==3.7\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==3.0.1\n",
            "matplotlib==3.7.1\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==1.1.1\n",
            "mdit-py-plugins==0.4.2\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.11.4\n",
            "mkl==2024.2.2\n",
            "ml-dtypes==0.4.1\n",
            "mlxtend==0.23.1\n",
            "more-itertools==10.5.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.1.0\n",
            "multidict==6.1.0\n",
            "multipledispatch==1.0.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.10\n",
            "music21==9.1.0\n",
            "namex==0.0.8\n",
            "natsort==8.4.0\n",
            "nbclassic==1.1.0\n",
            "nbclient==0.10.0\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.10.4\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.4.1\n",
            "nibabel==5.2.1\n",
            "nltk==3.8.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.4\n",
            "numba==0.60.0\n",
            "numexpr==2.10.1\n",
            "numpy==1.26.4\n",
            "nvidia-cublas-cu12==12.6.3.3\n",
            "nvidia-cuda-cupti-cu12==12.6.80\n",
            "nvidia-cuda-nvcc-cu12==12.6.77\n",
            "nvidia-cuda-runtime-cu12==12.6.77\n",
            "nvidia-cudnn-cu12==9.5.0.50\n",
            "nvidia-cufft-cu12==11.3.0.4\n",
            "nvidia-curand-cu12==10.3.7.77\n",
            "nvidia-cusolver-cu12==11.7.1.2\n",
            "nvidia-cusparse-cu12==12.5.4.2\n",
            "nvidia-nccl-cu12==2.23.4\n",
            "nvidia-nvjitlink-cu12==12.6.77\n",
            "nvtx==0.2.10\n",
            "nx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-24.10.0-py3-none-any.whl\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "opencv-contrib-python==4.10.0.84\n",
            "opencv-python==4.10.0.84\n",
            "opencv-python-headless==4.10.0.84\n",
            "openpyxl==3.1.5\n",
            "opentelemetry-api==1.16.0\n",
            "opentelemetry-sdk==1.16.0\n",
            "opentelemetry-semantic-conventions==0.37b0\n",
            "opt_einsum==3.4.0\n",
            "optax==0.2.3\n",
            "optree==0.13.0\n",
            "orbax-checkpoint==0.6.4\n",
            "osqp==0.6.7.post3\n",
            "packaging==24.1\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.23.2\n",
            "pandas-stubs==2.2.2.240909\n",
            "pandocfilters==1.5.1\n",
            "panel==1.4.5\n",
            "param==2.1.1\n",
            "parso==0.8.4\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.6\n",
            "peewee==3.17.7\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==10.4.0\n",
            "platformdirs==4.3.6\n",
            "plotly==5.24.1\n",
            "plotnine==0.13.6\n",
            "pluggy==1.5.0\n",
            "polars==1.7.1\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "preshed==3.0.9\n",
            "prettytable==3.11.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.21.0\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.48\n",
            "propcache==0.2.0\n",
            "prophet==1.1.6\n",
            "proto-plus==1.24.0\n",
            "protobuf==3.20.3\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.9\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==16.1.0\n",
            "pyarrow-hotfix==0.6\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.1\n",
            "pycocotools==2.0.8\n",
            "pycparser==2.22\n",
            "pydantic==2.9.2\n",
            "pydantic_core==2.23.4\n",
            "pydata-google-auth==1.8.2\n",
            "pydot==3.0.2\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.20.0\n",
            "pyerfa==2.0.1.4\n",
            "pygame==2.6.1\n",
            "pygit2==1.15.1\n",
            "Pygments==2.18.0\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.9.0\n",
            "pylibcudf-cu12 @ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-24.10.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "pylibcugraph-cu12==24.10.0\n",
            "pylibraft-cu12==24.10.0\n",
            "pymc==5.16.2\n",
            "pymystem3==0.2.0\n",
            "pynvjitlink-cu12==0.3.0\n",
            "pyogrio==0.10.0\n",
            "PyOpenGL==3.1.7\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.2.0\n",
            "pyperclip==1.9.0\n",
            "pyproj==3.7.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pyspark==3.5.3\n",
            "pytensor==2.25.5\n",
            "pytest==7.4.4\n",
            "python-apt==0.0.0\n",
            "python-box==7.2.0\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-utils==3.9.0\n",
            "pytorch-forecasting==1.1.1\n",
            "pytorch-lightning==2.4.0\n",
            "pytz==2024.2\n",
            "pyviz_comms==3.0.3\n",
            "PyYAML==6.0.2\n",
            "pyzmq==24.0.1\n",
            "qdldl==0.1.7.post4\n",
            "ratelim==0.1.6\n",
            "referencing==0.35.1\n",
            "regex==2024.9.11\n",
            "requests==2.32.3\n",
            "requests-oauthlib==1.3.1\n",
            "requirements-parser==0.9.0\n",
            "rich==13.9.2\n",
            "rmm-cu12==24.10.0\n",
            "rpds-py==0.20.0\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.4.5\n",
            "scikit-image==0.24.0\n",
            "scikit-learn==1.5.2\n",
            "scipy==1.13.1\n",
            "scooby==0.10.0\n",
            "scs==3.2.7\n",
            "seaborn==0.13.2\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.3\n",
            "sentencepiece==0.2.0\n",
            "sentry-sdk==2.16.0\n",
            "setproctitle==1.3.3\n",
            "shap==0.46.0\n",
            "shapely==2.0.6\n",
            "shellingham==1.5.4\n",
            "simple-parsing==0.1.6\n",
            "six==1.16.0\n",
            "sklearn-pandas==2.2.0\n",
            "slicer==0.0.8\n",
            "smart-open==7.0.5\n",
            "smmap==5.0.1\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==2.2.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.6\n",
            "soxr==0.5.0.post1\n",
            "spacy==3.7.5\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "Sphinx==5.0.2\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "SQLAlchemy==2.0.35\n",
            "sqlglot==25.1.0\n",
            "sqlparse==0.5.1\n",
            "srsly==2.4.8\n",
            "stanio==0.5.1\n",
            "statsmodels==0.14.4\n",
            "StrEnum==0.4.15\n",
            "sympy==1.13.3\n",
            "tables==3.8.0\n",
            "tabulate==0.9.0\n",
            "tbb==2021.13.1\n",
            "tenacity==9.0.0\n",
            "tensorboard==2.17.0\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.17.0\n",
            "tensorflow-datasets==4.9.6\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.37.1\n",
            "tensorflow-metadata==1.16.1\n",
            "tensorflow-probability==0.24.0\n",
            "tensorstore==0.1.66\n",
            "termcolor==2.5.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.17.0\n",
            "thinc==8.2.5\n",
            "threadpoolctl==3.5.0\n",
            "tifffile==2024.9.20\n",
            "timm==1.0.10\n",
            "tinycss2==1.3.0\n",
            "tokenizers==0.19.1\n",
            "toml==0.10.2\n",
            "tomli==2.0.2\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu121_full/torch-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
            "torchaudio @ https://download.pytorch.org/whl/cu121_full/torchaudio-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
            "torchcde==0.2.5\n",
            "torchdiffeq==0.2.4\n",
            "torchmetrics==1.5.0\n",
            "torchsde==0.2.6\n",
            "torchsummary==1.5.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu121_full/torchvision-0.19.1%2Bcu121-cp310-cp310-linux_x86_64.whl\n",
            "tornado==6.3.3\n",
            "tqdm==4.66.5\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "trampoline==0.1.2\n",
            "transformers==4.44.2\n",
            "tweepy==4.14.0\n",
            "typeguard==4.3.0\n",
            "typer==0.12.5\n",
            "types-pytz==2024.2.0.20241003\n",
            "types-setuptools==75.1.0.20241014\n",
            "typing_extensions==4.12.2\n",
            "tzdata==2024.2\n",
            "tzlocal==5.2\n",
            "uc-micro-py==1.0.3\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.2.3\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.18.3\n",
            "wasabi==1.1.3\n",
            "wcwidth==0.2.13\n",
            "weasel==0.4.1\n",
            "webcolors==24.8.0\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "Werkzeug==3.0.4\n",
            "widgetsnbextension==3.6.9\n",
            "wordcloud==1.9.3\n",
            "wrapt==1.16.0\n",
            "xarray==2024.9.0\n",
            "xarray-einstats==0.8.0\n",
            "xgboost==2.1.1\n",
            "xlrd==2.0.1\n",
            "xyzservices==2024.9.0\n",
            "yarl==1.15.2\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.44\n",
            "zipp==3.20.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tQzgBks3wD9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_forecasting pytorch_lightning torchcde"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnu9Vg19wfqu",
        "outputId": "f6564278-35d2-459a-8519-380e77db0626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_forecasting\n",
            "  Downloading pytorch_forecasting-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchcde\n",
            "  Downloading torchcde-0.2.5-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_forecasting) (1.26.4)\n",
            "Requirement already satisfied: torch!=2.0.1,<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_forecasting) (2.4.1+cu121)\n",
            "Collecting lightning<3.0.0,>=2.0.0 (from pytorch_forecasting)\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from pytorch_forecasting) (1.13.1)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_forecasting) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_forecasting) (1.5.2)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.6.1)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.5.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting torchdiffeq>=0.2.0 (from torchcde)\n",
            "  Downloading torchdiffeq-0.2.4-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting torchsde>=0.2.5 (from torchcde)\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.10.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0,>=1.2->pytorch_forecasting) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0,>=1.2->pytorch_forecasting) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.1.4)\n",
            "Collecting trampoline>=0.1.2 (from torchsde>=0.2.5->torchcde)\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch_forecasting) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.2.0)\n",
            "Downloading pytorch_forecasting-1.1.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchcde-0.2.5-py3-none-any.whl (28 kB)\n",
            "Downloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Downloading torchdiffeq-0.2.4-py3-none-any.whl (32 kB)\n",
            "Downloading torchmetrics-1.5.0-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.5/890.5 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: trampoline, lightning-utilities, torchsde, torchmetrics, torchdiffeq, torchcde, pytorch_lightning, lightning, pytorch_forecasting\n",
            "Successfully installed lightning-2.4.0 lightning-utilities-0.11.8 pytorch_forecasting-1.1.1 pytorch_lightning-2.4.0 torchcde-0.2.5 torchdiffeq-0.2.4 torchmetrics-1.5.0 torchsde-0.2.6 trampoline-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pytorch_forecasting.models.base_model import BaseModel\n",
        "from pytorch_forecasting.metrics import RMSE\n",
        "\n",
        "class AutoRegressiveModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Simple Autoregressive model using a Linear layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size: int, output_size: int = 1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.linear = torch.nn.Linear(input_size, output_size)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x[\"encoder_cont\"] shape: (batch_size, encoder_length, input_size)\n",
        "        encoder_output = x[\"encoder_cont\"][:, -1, :]  # Use last time step\n",
        "        prediction = self.linear(encoder_output)\n",
        "        return self.to_network_output(prediction=prediction)\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataset(cls, dataset, **kwargs):\n",
        "        new_kwargs = {\n",
        "            \"input_size\": len(dataset.reals),\n",
        "            \"loss\": RMSE(),\n",
        "        }\n",
        "        new_kwargs.update(kwargs)\n",
        "        return super().from_dataset(dataset, **new_kwargs)"
      ],
      "metadata": {
        "id": "crYe-1JHwgrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pytorch_forecasting.models.base_model import BaseModelWithCovariates\n",
        "from pytorch_forecasting.metrics import RMSE\n",
        "\n",
        "class LSTMForecaster(BaseModelWithCovariates):\n",
        "    \"\"\"\n",
        "    LSTM-based Forecaster.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size: int, hidden_size: int, num_layers: int, dropout: float = 0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.output_layer = torch.nn.Linear(hidden_size, 1)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Concatenate continuous and categorical variables\n",
        "        encoder_input = x[\"encoder_cont\"]  # Shape: (batch_size, seq_len, input_size)\n",
        "        output, (hidden, cell) = self.lstm(encoder_input)\n",
        "        # Use the last hidden state\n",
        "        hidden_last = hidden[-1]\n",
        "        prediction = self.output_layer(hidden_last)\n",
        "        return self.to_network_output(prediction=prediction)\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataset(cls, dataset, **kwargs):\n",
        "        new_kwargs = {\n",
        "            \"input_size\": len(dataset.reals),\n",
        "            \"loss\": RMSE(),\n",
        "        }\n",
        "        new_kwargs.update(kwargs)\n",
        "        return super().from_dataset(dataset, **new_kwargs)"
      ],
      "metadata": {
        "id": "Bwbo4x5JweTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pytorch_forecasting.models.base_model import BaseModelWithCovariates\n",
        "from pytorch_forecasting.metrics import RMSE\n",
        "from torch.nn.utils import weight_norm\n",
        "\n",
        "class Chomp1d(torch.nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "class TemporalBlock(torch.nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        self.conv1 = weight_norm(torch.nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                                                 stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.dropout1 = torch.nn.Dropout(dropout)\n",
        "\n",
        "        self.net = torch.nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1)\n",
        "        self.downsample = torch.nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "class TemporalConvNet(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super(TemporalConvNet, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
        "        self.network = torch.nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class TCNForecaster(BaseModelWithCovariates):\n",
        "    \"\"\"\n",
        "    Temporal Convolutional Network Forecaster.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size: int, num_channels: list, kernel_size: int = 2, dropout: float = 0.2, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
        "        self.output_layer = torch.nn.Linear(num_channels[-1], 1)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x[\"encoder_cont\"] shape: (batch_size, seq_len, input_size)\n",
        "        encoder_input = x[\"encoder_cont\"].permute(0, 2, 1)  # Reshape to (batch_size, input_size, seq_len)\n",
        "        tcn_output = self.tcn(encoder_input)\n",
        "        # Use the last time step\n",
        "        last_output = tcn_output[:, :, -1]\n",
        "        prediction = self.output_layer(last_output)\n",
        "        return self.to_network_output(prediction=prediction)\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataset(cls, dataset, **kwargs):\n",
        "        new_kwargs = {\n",
        "            \"input_size\": len(dataset.reals),\n",
        "            \"loss\": RMSE(),\n",
        "        }\n",
        "        new_kwargs.update(kwargs)\n",
        "        return super().from_dataset(dataset, **new_kwargs)"
      ],
      "metadata": {
        "id": "ogy2N-DkwdUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pytorch_forecasting.models.base_model import BaseModel\n",
        "from pytorch_forecasting.metrics import RMSE\n",
        "\n",
        "class ProphetLikeModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Simplified Prophet-like model capturing trend and seasonality.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, seasonality: int, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.trend = torch.nn.Linear(1, 1)\n",
        "        self.seasonality = torch.nn.Linear(seasonality, 1)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        time = x[\"encoder_cont\"][:, :, 0]  # Assuming the first real variable is time\n",
        "        time = time.unsqueeze(-1)\n",
        "        trend = self.trend(time)\n",
        "\n",
        "        seasonal_features = x[\"encoder_cont\"][:, :, 1:self.hparams.seasonality+1]\n",
        "        seasonality = self.seasonality(seasonal_features)\n",
        "\n",
        "        prediction = trend + seasonality\n",
        "        # Use the last time step\n",
        "        prediction = prediction[:, -1, :]\n",
        "        return self.to_network_output(prediction=prediction)\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataset(cls, dataset, **kwargs):\n",
        "        new_kwargs = {\n",
        "            \"loss\": RMSE(),\n",
        "            \"seasonality\": 10,  # Example value, adjust as needed\n",
        "        }\n",
        "        new_kwargs.update(kwargs)\n",
        "        return super().from_dataset(dataset, **new_kwargs)"
      ],
      "metadata": {
        "id": "740wkaCawauX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AssetAllocationWrapper:\n",
        "    \"\"\"\n",
        "    Wrapper to train models for asset allocation based on returns.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name, max_epochs=30):\n",
        "        \"\"\"\n",
        "        Initialize the wrapper.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Name of the model to use ('TFT', 'RNN', 'DeepAR', 'NBeats', 'NHiTS', 'Baseline', 'AutoRegressive', 'LSTM', 'TCN', 'ProphetLike').\n",
        "            max_epochs (int): Maximum number of training epochs.\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.max_epochs = max_epochs\n",
        "        self.model = None\n",
        "\n",
        "    def prepare_data(self, df, time_idx, target, group_ids):\n",
        "        \"\"\"\n",
        "        Prepare dataset for asset allocation.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): Dataset containing returns.\n",
        "            time_idx (str): Name of the time index column.\n",
        "            target (str): Name of the target column (e.g., returns).\n",
        "            group_ids (list): List of group identifier column names (e.g., securities).\n",
        "        \"\"\"\n",
        "        # Ensure time_idx is integer and sort data\n",
        "        df[time_idx] = pd.to_datetime(df[time_idx])\n",
        "        df.sort_values(by=[group_ids[0], time_idx], inplace=True)\n",
        "        df[time_idx] = df[time_idx].dt.strftime('%Y%m%d').astype(int)\n",
        "\n",
        "        # Create TimeSeriesDataSet\n",
        "        max_encoder_length = 30\n",
        "        max_prediction_length = 7\n",
        "\n",
        "        self.training_cutoff = df[time_idx].max() - max_prediction_length\n",
        "\n",
        "        self.training = TimeSeriesDataSet(\n",
        "            df[df[time_idx] <= self.training_cutoff],\n",
        "            time_idx=time_idx,\n",
        "            target=target,\n",
        "            group_ids=group_ids,\n",
        "            max_encoder_length=max_encoder_length,\n",
        "            max_prediction_length=max_prediction_length,\n",
        "            static_categoricals=group_ids,\n",
        "            time_varying_known_reals=[time_idx],\n",
        "            time_varying_unknown_reals=[target],\n",
        "            target_normalizer=GroupNormalizer(groups=group_ids),\n",
        "            allow_missings=True,\n",
        "        )\n",
        "\n",
        "        self.validation = TimeSeriesDataSet.from_dataset(\n",
        "            self.training, df[df[time_idx] > self.training_cutoff], min_prediction_idx=self.training_cutoff + 1\n",
        "        )\n",
        "\n",
        "        self.batch_size = 64\n",
        "        self.train_dataloader = DataLoader(self.training, batch_size=self.batch_size, shuffle=True)\n",
        "        self.val_dataloader = DataLoader(self.validation, batch_size=self.batch_size)\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"\n",
        "        Fit the selected model.\n",
        "        \"\"\"\n",
        "        # Choose the model\n",
        "        if self.model_name == 'TFT':\n",
        "            self.model = TemporalFusionTransformer.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=16,\n",
        "                attention_head_size=1,\n",
        "                dropout=0.1,\n",
        "                hidden_continuous_size=8,\n",
        "                loss=QuantileLoss(),\n",
        "                log_interval=10,\n",
        "                reduce_on_plateau_patience=4,\n",
        "            )\n",
        "        elif self.model_name == 'RNN':\n",
        "            self.model = RecurrentNetwork.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=16,\n",
        "                rnn_layers=2,\n",
        "                dropout=0.1,\n",
        "                loss=RMSE(),\n",
        "            )\n",
        "        elif self.model_name == 'DeepAR':\n",
        "            self.model = DeepAR.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                rnn_layers=2,\n",
        "                hidden_size=16,\n",
        "                dropout=0.1,\n",
        "            )\n",
        "        elif self.model_name == 'NBeats':\n",
        "            self.model = NBeats.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "            )\n",
        "        elif self.model_name == 'NHiTS':\n",
        "            self.model = NHiTS.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "            )\n",
        "        elif self.model_name == 'Baseline':\n",
        "            self.model = Baseline()\n",
        "        elif self.model_name == 'AutoRegressive':\n",
        "            self.model = AutoRegressiveModel.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "            )\n",
        "        elif self.model_name == 'LSTM':\n",
        "            self.model = LSTMForecaster.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=16,\n",
        "                num_layers=2,\n",
        "                dropout=0.1,\n",
        "            )\n",
        "        elif self.model_name == 'TCN':\n",
        "            self.model = TCNForecaster.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                num_channels=[16]*3,\n",
        "                kernel_size=2,\n",
        "                dropout=0.1,\n",
        "            )\n",
        "        elif self.model_name == 'ProphetLike':\n",
        "            self.model = ProphetLikeModel.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                seasonality=10,\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Model {self.model_name} is not supported.\")\n",
        "\n",
        "        # Trainer\n",
        "        early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=False, mode=\"min\")\n",
        "        trainer = pl.Trainer(\n",
        "            max_epochs=self.max_epochs,\n",
        "            callbacks=[early_stop_callback],\n",
        "            gradient_clip_val=0.1,\n",
        "        )\n",
        "\n",
        "        # Fit the model\n",
        "        trainer.fit(self.model, train_dataloaders=self.train_dataloader, val_dataloaders=self.val_dataloader)\n",
        "\n",
        "    # The predict and backtest methods remain the same."
      ],
      "metadata": {
        "id": "YGfyD5N3wXGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Include all the necessary imports and classes from previous code blocks\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Generate synthetic data for demonstration\n",
        "def generate_synthetic_data(num_securities=10, num_days=500):\n",
        "    dates = pd.date_range(start='2020-01-01', periods=num_days, freq='D')\n",
        "    data = []\n",
        "    for security_id in range(num_securities):\n",
        "        price = 100 + np.cumsum(np.random.randn(num_days) * 0.5)\n",
        "        returns = np.diff(price) / price[:-1]\n",
        "        returns = np.insert(returns, 0, 0)  # Insert zero return for the first day\n",
        "        df = pd.DataFrame({\n",
        "            'date': dates,\n",
        "            'security_id': f'sec_{security_id}',\n",
        "            'price': price,\n",
        "            'returns': returns,\n",
        "        })\n",
        "        data.append(df)\n",
        "    df = pd.concat(data)\n",
        "    return df\n",
        "\n",
        "# Generate data\n",
        "df = generate_synthetic_data()\n",
        "\n",
        "# Initialize the wrapper\n",
        "wrapper = AssetAllocationWrapper(model_name='Signature', max_epochs=10) # add , max_leverage=2.0)\n",
        "wrapper.prepare_data(df, time_idx='date', target='returns', group_ids=['security_id'])\n",
        "wrapper.fit()\n",
        "backtest_results = wrapper.backtest()\n",
        "print(backtest_results.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "UeoipSntxbOP",
        "outputId": "bba0a7d5-bd51-438d-dc99-df43b6752dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TimeSeriesDataSet' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d890adf1a2db>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Initialize the wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAssetAllocationWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Signature'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add , max_leverage=2.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'returns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'security_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mbacktest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbacktest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a72de70aa823>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self, df, time_idx, target, group_ids)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_prediction_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         self.training = TimeSeriesDataSet(\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mtime_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TimeSeriesDataSet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df is your dataset with columns: 'time', 'group_id', 'returns'\n",
        "wrapper = AssetAllocationWrapper(model_name='LSTM', max_epochs=20)\n",
        "wrapper.prepare_data(df, time_idx='time', target='returns', group_ids=['group_id'])\n",
        "wrapper.fit()\n",
        "backtest_results = wrapper.backtest()\n",
        "print(backtest_results.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "SstxPxNjwT2n",
        "outputId": "918d5ef3-1f2a-4f2d-8429-2e85e3972726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-3df1c3f648a5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming df is your dataset with columns: 'time', 'group_id', 'returns'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAssetAllocationWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'returns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'group_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbacktest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbacktest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## pytorch_forecdasting"
      ],
      "metadata": {
        "id": "DwECxFDux-LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchcde\n",
        "from pytorch_forecasting.models.base_model import BaseModelWithCovariates\n",
        "from pytorch_forecasting.metrics import RMSE\n",
        "\n",
        "class SignatureModel(BaseModelWithCovariates):\n",
        "    \"\"\"\n",
        "    Signature-based model using Neural Controlled Differential Equations (Neural CDEs).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size: int, hidden_size: int, output_size: int = 1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden_size = hidden_size\n",
        "        # Define the vector field for the CDE\n",
        "        self.func = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_size, hidden_size),\n",
        "            torch.nn.Tanh(),\n",
        "            torch.nn.Linear(hidden_size, hidden_size * input_size)\n",
        "        )\n",
        "        self.initial_linear = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.readout = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (Dict[str, Tensor]): Input dictionary from TimeSeriesDataSet.\n",
        "\n",
        "        Returns:\n",
        "            Prediction output.\n",
        "        \"\"\"\n",
        "        # x[\"encoder_cont\"] shape: (batch_size, seq_len, input_size)\n",
        "        batch_size, seq_len, input_size = x[\"encoder_cont\"].shape\n",
        "        # Create continuous path using cubic splines\n",
        "        coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(x[\"encoder_cont\"])\n",
        "        X = torchcde.CubicSpline(coeffs)\n",
        "        # Initial hidden state\n",
        "        z0 = self.initial_linear(X.evaluate(X.interval[0]))\n",
        "        # Solve the CDE\n",
        "        z_T = torchcde.cdeint(X=X, func=self.func, z0=z0, t=X.interval)\n",
        "        # z_T shape: (batch_size, 2, hidden_size)\n",
        "        # We take the last time point\n",
        "        z_T = z_T[:, -1, :]\n",
        "        prediction = self.readout(z_T)\n",
        "        return self.to_network_output(prediction=prediction)\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataset(cls, dataset, **kwargs):\n",
        "        \"\"\"\n",
        "        Create the model from a TimeSeriesDataSet.\n",
        "\n",
        "        Args:\n",
        "            dataset (TimeSeriesDataSet): The dataset used for training.\n",
        "            **kwargs: Additional arguments.\n",
        "\n",
        "        Returns:\n",
        "            SignatureModel instance.\n",
        "        \"\"\"\n",
        "        new_kwargs = {\n",
        "            \"input_size\": len(dataset.reals),\n",
        "            \"loss\": RMSE(),\n",
        "        }\n",
        "        new_kwargs.update(kwargs)\n",
        "        return super().from_dataset(dataset, **new_kwargs)"
      ],
      "metadata": {
        "id": "QAYMB5x0wQfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_forecasting import (\n",
        "    TimeSeriesDataSet,\n",
        "    Baseline,\n",
        "    TemporalFusionTransformer,\n",
        "    RecurrentNetwork,\n",
        "    DeepAR,\n",
        "    NBeats,\n",
        "    NHiTS,\n",
        ")\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import RMSE, QuantileLoss\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Include the SignatureModel class code here (from previous code block)\n",
        "\n",
        "class AssetAllocationWrapper:\n",
        "    \"\"\"\n",
        "    Wrapper to train models for asset allocation based on returns.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name, max_epochs=30, max_leverage=2.0):\n",
        "        \"\"\"\n",
        "        Initialize the wrapper.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Name of the model to use.\n",
        "            max_epochs (int): Maximum number of training epochs.\n",
        "            max_leverage (float): Maximum leverage allowed.\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.max_epochs = max_epochs\n",
        "        self.max_leverage = max_leverage\n",
        "        self.model = None\n",
        "\n",
        "    def prepare_data(self, df, time_idx, target, group_ids):\n",
        "        \"\"\"\n",
        "        Prepare dataset for asset allocation.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): Dataset containing returns.\n",
        "            time_idx (str): Name of the time index column.\n",
        "            target (str): Name of the target column (e.g., returns).\n",
        "            group_ids (list): List of group identifier column names (e.g., securities).\n",
        "        \"\"\"\n",
        "        # Ensure time_idx is integer and sort data\n",
        "        df[time_idx] = pd.to_datetime(df[time_idx])\n",
        "        df.sort_values(by=[group_ids[0], time_idx], inplace=True)\n",
        "        df[time_idx] = df[time_idx].dt.strftime('%Y%m%d').astype(int)\n",
        "\n",
        "        # Create TimeSeriesDataSet\n",
        "        max_encoder_length = 30\n",
        "        max_prediction_length = 7\n",
        "\n",
        "        self.training_cutoff = df[time_idx].max() - max_prediction_length\n",
        "\n",
        "        self.training = TimeSeriesDataSet(\n",
        "            df[df[time_idx] <= self.training_cutoff],\n",
        "            time_idx=time_idx,\n",
        "            target=target,\n",
        "            group_ids=group_ids,\n",
        "            max_encoder_length=max_encoder_length,\n",
        "            max_prediction_length=max_prediction_length,\n",
        "            static_categoricals=group_ids,\n",
        "            time_varying_known_reals=[time_idx],\n",
        "            time_varying_unknown_reals=[target],\n",
        "            target_normalizer=GroupNormalizer(groups=group_ids),\n",
        "            allow_missings=True,\n",
        "        )\n",
        "\n",
        "        self.validation = TimeSeriesDataSet.from_dataset(\n",
        "            self.training, df[df[time_idx] > self.training_cutoff], min_prediction_idx=self.training_cutoff + 1\n",
        "        )\n",
        "\n",
        "        self.batch_size = 64\n",
        "        self.train_dataloader = DataLoader(self.training, batch_size=self.batch_size, shuffle=True)\n",
        "        self.val_dataloader = DataLoader(self.validation, batch_size=self.batch_size)\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"\n",
        "        Fit the selected model.\n",
        "        \"\"\"\n",
        "        # Choose the model\n",
        "        if self.model_name == 'TFT':\n",
        "            self.model = TemporalFusionTransformer.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=16,\n",
        "                attention_head_size=1,\n",
        "                dropout=0.1,\n",
        "                hidden_continuous_size=8,\n",
        "                loss=QuantileLoss(),\n",
        "                log_interval=10,\n",
        "                reduce_on_plateau_patience=4,\n",
        "            )\n",
        "        elif self.model_name == 'RNN':\n",
        "            self.model = RecurrentNetwork.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=16,\n",
        "                rnn_layers=2,\n",
        "                dropout=0.1,\n",
        "                loss=RMSE(),\n",
        "            )\n",
        "        elif self.model_name == 'DeepAR':\n",
        "            self.model = DeepAR.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                rnn_layers=2,\n",
        "                hidden_size=16,\n",
        "                dropout=0.1,\n",
        "            )\n",
        "        elif self.model_name == 'NBeats':\n",
        "            self.model = NBeats.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "            )\n",
        "        elif self.model_name == 'NHiTS':\n",
        "            self.model = NHiTS.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "            )\n",
        "        elif self.model_name == 'Baseline':\n",
        "            self.model = Baseline()\n",
        "        elif self.model_name == 'AutoRegressive':\n",
        "            self.model = AutoRegressiveModel.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "            )\n",
        "        elif self.model_name == 'LSTM':\n",
        "            self.model = LSTMForecaster.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=16,\n",
        "                num_layers=2,\n",
        "                dropout=0.1,\n",
        "            )\n",
        "        elif self.model_name == 'TCN':\n",
        "            self.model = TCNForecaster.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                num_channels=[16]*3,\n",
        "                kernel_size=2,\n",
        "                dropout=0.1,\n",
        "            )\n",
        "        elif self.model_name == 'ProphetLike':\n",
        "            self.model = ProphetLikeModel.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                seasonality=10,\n",
        "            )\n",
        "        elif self.model_name == 'Signature':\n",
        "            self.model = SignatureModel.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=32,\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Model {self.model_name} is not supported.\")\n",
        "\n",
        "        # Trainer\n",
        "        early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=False, mode=\"min\")\n",
        "        trainer = pl.Trainer(\n",
        "            max_epochs=self.max_epochs,\n",
        "            callbacks=[early_stop_callback],\n",
        "            gradient_clip_val=0.1,\n",
        "        )\n",
        "\n",
        "        # Fit the model\n",
        "        trainer.fit(self.model, train_dataloaders=self.train_dataloader, val_dataloaders=self.val_dataloader)\n",
        "\n",
        "    def predict(self, df):\n",
        "        \"\"\"\n",
        "        Make predictions on new data.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): DataFrame containing new data.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame with predictions.\n",
        "        \"\"\"\n",
        "        # Prepare dataset\n",
        "        raw_predictions, x = self.model.predict(df, mode=\"raw\", return_x=True)\n",
        "        predictions = self.model.to_prediction(raw_predictions)\n",
        "\n",
        "        # Combine predictions with input data\n",
        "        df_pred = df.copy()\n",
        "        df_pred['prediction'] = predictions\n",
        "        return df_pred\n",
        "\n",
        "    def backtest(self):\n",
        "        \"\"\"\n",
        "        Perform backtesting using the validation set.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame with backtesting predictions.\n",
        "        \"\"\"\n",
        "        actuals = torch.cat([y[0] for x, y in iter(self.val_dataloader)])\n",
        "        predictions = self.model.predict(self.val_dataloader)\n",
        "        df_backtest = pd.DataFrame({\n",
        "            'actual': actuals.numpy().flatten(),\n",
        "            'prediction': predictions.numpy().flatten(),\n",
        "        })\n",
        "\n",
        "        # Adjust leverage based on confidence\n",
        "        df_backtest['confidence'] = self.calculate_confidence(df_backtest)\n",
        "        df_backtest['leverage'] = df_backtest['confidence'] * self.max_leverage\n",
        "        df_backtest['leverage'] = df_backtest['leverage'].clip(0, self.max_leverage)\n",
        "\n",
        "        # Apply leverage to predictions\n",
        "        df_backtest['adjusted_prediction'] = df_backtest['prediction'] * df_backtest['leverage']\n",
        "        return df_backtest\n",
        "\n",
        "    def calculate_confidence(self, df):\n",
        "        \"\"\"\n",
        "        Calculate confidence level based on prediction errors.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): DataFrame with 'actual' and 'prediction' columns.\n",
        "\n",
        "        Returns:\n",
        "            pd.Series: Confidence levels between 0 and 1.\n",
        "        \"\"\"\n",
        "        errors = np.abs(df['actual'] - df['prediction'])\n",
        "        max_error = errors.max()\n",
        "        confidence = 1 - (errors / (max_error + 1e-6))\n",
        "        return confidence"
      ],
      "metadata": {
        "id": "O_k-vzz6wMm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(self, df, time_idx, target, group_ids):\n",
        "    \"\"\"\n",
        "    Prepare dataset for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Dataset containing returns.\n",
        "        time_idx (str): Name of the time index column.\n",
        "        target (str): Name of the target column (e.g., returns).\n",
        "        group_ids (list): List of group identifier column names (e.g., securities).\n",
        "    \"\"\"\n",
        "    # Ensure time_idx is integer and sort data\n",
        "    df[time_idx] = pd.to_datetime(df[time_idx])\n",
        "    df.sort_values(by=[group_ids[0], time_idx], inplace=True)\n",
        "    df[time_idx] = df[time_idx].dt.strftime('%Y%m%d').astype(int)\n",
        "\n",
        "    # Create TimeSeriesDataSet\n",
        "    max_encoder_length = 30\n",
        "    max_prediction_length = 7\n",
        "\n",
        "    self.training_cutoff = df[time_idx].max() - max_prediction_length\n",
        "\n",
        "    self.training = TimeSeriesDataSet(\n",
        "        df[df[time_idx] <= self.training_cutoff],\n",
        "        time_idx=time_idx,\n",
        "        target=target,\n",
        "        group_ids=group_ids,\n",
        "        max_encoder_length=max_encoder_length,\n",
        "        max_prediction_length=max_prediction_length,\n",
        "        static_categoricals=group_ids,\n",
        "        time_varying_known_reals=[time_idx],\n",
        "        time_varying_unknown_reals=[target],\n",
        "        target_normalizer=GroupNormalizer(groups=group_ids),\n",
        "        allow_missing_timesteps=True,  # Corrected argument name\n",
        "    )\n",
        "\n",
        "    self.validation = TimeSeriesDataSet.from_dataset(\n",
        "        self.training, df[df[time_idx] > self.training_cutoff], min_prediction_idx=self.training_cutoff + 1\n",
        "    )\n",
        "\n",
        "    self.batch_size = 64\n",
        "    self.train_dataloader = DataLoader(self.training, batch_size=self.batch_size, shuffle=True)\n",
        "    self.val_dataloader = DataLoader(self.validation, batch_size=self.batch_size)"
      ],
      "metadata": {
        "id": "jhma5ed_wJtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AssetAllocationWrapper:\n",
        "    \"\"\"\n",
        "    Wrapper to train models for asset allocation based on returns.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    Wrapper to train models for asset allocation based on returns.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name, max_epochs=30, max_leverage=2.0):\n",
        "        \"\"\"\n",
        "        Initialize the wrapper.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Name of the model to use.\n",
        "            max_epochs (int): Maximum number of training epochs.\n",
        "            max_leverage (float): Maximum leverage allowed.\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.max_epochs = max_epochs\n",
        "        self.max_leverage = max_leverage\n",
        "        self.model = None\n",
        "\n",
        "    def prepare_data(self, df, time_idx, target, group_ids):\n",
        "        \"\"\"\n",
        "        Prepare dataset for asset allocation.\n",
        "        \"\"\"\n",
        "        # Ensure time_idx is datetime and sort data\n",
        "        df[time_idx] = pd.to_datetime(df[time_idx])\n",
        "        df.sort_values(by=group_ids + [time_idx], inplace=True)\n",
        "\n",
        "        # Assign a unique sequential integer time index within each group\n",
        "        df['time_idx'] = df.groupby(group_ids).cumcount()\n",
        "\n",
        "        # Reindex each group to fill missing time_idx\n",
        "        df_list = []\n",
        "        grouped = df.groupby(group_ids)\n",
        "        for name, group in grouped:\n",
        "            idx = pd.Index(range(group['time_idx'].min(), group['time_idx'].max() + 1), name='time_idx')\n",
        "            group = group.set_index('time_idx').reindex(idx).reset_index()\n",
        "            if isinstance(name, tuple):\n",
        "                for i, gid in enumerate(group_ids):\n",
        "                    group[gid] = name[i]\n",
        "            else:\n",
        "                group[group_ids[0]] = name\n",
        "            # Fill missing values as needed\n",
        "            group[target] = group[target].fillna(0)  # Or use appropriate method\n",
        "            df_list.append(group)\n",
        "        df = pd.concat(df_list).reset_index(drop=True)\n",
        "\n",
        "        # Now, time_idx should be consecutive within each group\n",
        "        max_encoder_length = 20  # Reduced from 30\n",
        "        max_prediction_length = 5  # Reduced from 7\n",
        "\n",
        "        self.training_cutoff = df['time_idx'].max() - max_prediction_length\n",
        "\n",
        "        self.training = TimeSeriesDataSet(\n",
        "            df[df['time_idx'] <= self.training_cutoff],\n",
        "            time_idx='time_idx',\n",
        "            target=target,\n",
        "            group_ids=group_ids,\n",
        "            max_encoder_length=max_encoder_length,\n",
        "            min_encoder_length=10,\n",
        "            max_prediction_length=max_prediction_length,\n",
        "            min_prediction_length=1,\n",
        "            static_categoricals=group_ids,\n",
        "            time_varying_known_reals=['time_idx'],\n",
        "            time_varying_unknown_reals=[target],\n",
        "            target_normalizer=GroupNormalizer(groups=group_ids),\n",
        "            allow_missing_timesteps=True,\n",
        "        )\n",
        "\n",
        "        self.validation = TimeSeriesDataSet.from_dataset(\n",
        "            self.training, df[df['time_idx'] > self.training_cutoff], min_prediction_idx=self.training_cutoff + 1\n",
        "        )\n",
        "\n",
        "        self.batch_size = 64\n",
        "        self.train_dataloader = DataLoader(self.training, batch_size=self.batch_size, shuffle=True)\n",
        "        self.val_dataloader = DataLoader(self.validation, batch_size=self.batch_size)\n",
        "    def fit(self):\n",
        "        \"\"\"\n",
        "        Fit the selected model.\n",
        "        \"\"\"\n",
        "        # Choose the model\n",
        "        if self.model_name == 'TFT':\n",
        "            self.model = TemporalFusionTransformer.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=16,\n",
        "                attention_head_size=1,\n",
        "                dropout=0.1,\n",
        "                hidden_continuous_size=8,\n",
        "                loss=QuantileLoss(),\n",
        "                log_interval=10,\n",
        "                reduce_on_plateau_patience=4,\n",
        "            )\n",
        "        elif self.model_name == 'RNN':\n",
        "            self.model = RecurrentNetwork.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=16,\n",
        "                rnn_layers=2,\n",
        "                dropout=0.1,\n",
        "                loss=RMSE(),\n",
        "            )\n",
        "        elif self.model_name == 'DeepAR':\n",
        "            self.model = DeepAR.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                rnn_layers=2,\n",
        "                hidden_size=16,\n",
        "                dropout=0.1,\n",
        "            )\n",
        "        elif self.model_name == 'NBeats':\n",
        "            self.model = NBeats.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "            )\n",
        "        elif self.model_name == 'NHiTS':\n",
        "            self.model = NHiTS.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "            )\n",
        "        elif self.model_name == 'Baseline':\n",
        "            self.model = Baseline()\n",
        "        elif self.model_name == 'AutoRegressive':\n",
        "            self.model = AutoRegressiveModel.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "            )\n",
        "        elif self.model_name == 'LSTM':\n",
        "            self.model = LSTMForecaster.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=16,\n",
        "                num_layers=2,\n",
        "                dropout=0.1,\n",
        "            )\n",
        "        elif self.model_name == 'TCN':\n",
        "            self.model = TCNForecaster.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                num_channels=[16]*3,\n",
        "                kernel_size=2,\n",
        "                dropout=0.1,\n",
        "            )\n",
        "        elif self.model_name == 'ProphetLike':\n",
        "            self.model = ProphetLikeModel.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                seasonality=10,\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Model {self.model_name} is not supported.\")\n",
        "\n",
        "        # Trainer\n",
        "        early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=False, mode=\"min\")\n",
        "        trainer = pl.Trainer(\n",
        "            max_epochs=self.max_epochs,\n",
        "            callbacks=[early_stop_callback],\n",
        "            gradient_clip_val=0.1,\n",
        "        )\n",
        "\n",
        "        # Fit the model\n",
        "        trainer.fit(self.model, train_dataloaders=self.train_dataloader, val_dataloaders=self.val_dataloader)\n",
        "\n",
        "    # The predict and backtest methods remain the same."
      ],
      "metadata": {
        "id": "pr9DU_lOzLaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data for demonstration\n",
        "def generate_synthetic_data(num_securities=10, num_days=500):\n",
        "    dates = pd.date_range(start='2020-01-01', periods=num_days, freq='D')\n",
        "    data = []\n",
        "    for security_id in range(num_securities):\n",
        "        price = 100 + np.cumsum(np.random.randn(num_days) * 0.5)\n",
        "        returns = np.diff(price) / price[:-1]\n",
        "        returns = np.insert(returns, 0, 0)  # Insert zero return for the first day\n",
        "        df = pd.DataFrame({\n",
        "            'date': dates,\n",
        "            'security_id': f'sec_{security_id}',\n",
        "            'price': price,\n",
        "            'returns': returns,\n",
        "        })\n",
        "        data.append(df)\n",
        "    df = pd.concat(data)\n",
        "    return df\n",
        "max_encoder_length = 28\n",
        "max_prediction_length = 7\n",
        "# Generate data\n",
        "df = generate_synthetic_data()\n",
        "\n",
        "# Initialize the wrapper\n",
        "wrapper = AssetAllocationWrapper(model_name='Signature', max_epochs=10, max_leverage=2.0)\n",
        "wrapper.prepare_data(df, time_idx='date', target='returns', group_ids=['security_id'])\n",
        "wrapper.fit()\n",
        "backtest_results = wrapper.backtest()\n",
        "print(backtest_results.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "AyJfE1OI1BNR",
        "outputId": "31974f54-b038-4d47-b843-0b858c6b1818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/data/timeseries.py:1282: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 10 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__security_id': 'sec_0'}, {'__group_id__security_id': 'sec_1'}, {'__group_id__security_id': 'sec_2'}, {'__group_id__security_id': 'sec_3'}, {'__group_id__security_id': 'sec_4'}, {'__group_id__security_id': 'sec_5'}, {'__group_id__security_id': 'sec_6'}, {'__group_id__security_id': 'sec_7'}, {'__group_id__security_id': 'sec_8'}, {'__group_id__security_id': 'sec_9'}]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "filters should not remove entries all entries - check encoder/decoder lengths and lags",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-06429bec2e1b>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Initialize the wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAssetAllocationWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Signature'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_leverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'returns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'security_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mbacktest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbacktest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-3fca1145e440>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self, df, time_idx, target, group_ids)\u001b[0m\n\u001b[1;32m     71\u001b[0m         )\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         self.validation = TimeSeriesDataSet.from_dataset(\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_idx'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_prediction_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_cutoff\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36mfrom_dataset\u001b[0;34m(cls, dataset, data, stop_randomization, predict, **update_kwargs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mTimeSeriesDataSet\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \"\"\"\n\u001b[0;32m-> 1155\u001b[0;31m         return cls.from_parameters(\n\u001b[0m\u001b[1;32m   1156\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_randomization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_randomization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mupdate_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36mfrom_parameters\u001b[0;34m(cls, parameters, data, stop_randomization, predict, **update_kwargs)\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# create index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;31m# convert to torch tensor for high performance data loading later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36m_construct_index\u001b[0;34m(self, data, predict_mode)\u001b[0m\n\u001b[1;32m   1289\u001b[0m             )\n\u001b[1;32m   1290\u001b[0m         assert (\n\u001b[0;32m-> 1291\u001b[0;31m             \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m         ), \"filters should not remove entries all entries - check encoder/decoder lengths and lags\"\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: filters should not remove entries all entries - check encoder/decoder lengths and lags"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_forecasting import (\n",
        "    TimeSeriesDataSet,\n",
        "    Baseline,\n",
        "    TemporalFusionTransformer,\n",
        "    RecurrentNetwork,\n",
        "    DeepAR,\n",
        "    NBeats,\n",
        "    NHiTS,\n",
        ")\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import RMSE, QuantileLoss\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Include the SignatureModel class code here (from previous code block)\n",
        "# Ensure that you have installed torchcde\n",
        "# pip install torchcde\n",
        "\n",
        "# The SignatureModel class remains the same...\n",
        "\n",
        "\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_forecasting import (\n",
        "    TimeSeriesDataSet,\n",
        "    Baseline,\n",
        "    TemporalFusionTransformer,\n",
        "    RecurrentNetwork,\n",
        "    DeepAR,\n",
        "    NBeats,\n",
        "    NHiTS,\n",
        ")\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import RMSE, QuantileLoss\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Include the SignatureModel class code here (from previous code block)\n",
        "# Ensure that you have installed torchcde\n",
        "# pip install torchcde\n",
        "\n",
        "# The SignatureModel class remains the same...\n",
        "\n",
        "class AssetAllocationWrapper:\n",
        "    \"\"\"\n",
        "    Wrapper to train models for asset allocation based on returns.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name, max_epochs=30, max_leverage=2.0):\n",
        "        \"\"\"\n",
        "        Initialize the wrapper.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Name of the model to use.\n",
        "            max_epochs (int): Maximum number of training epochs.\n",
        "            max_leverage (float): Maximum leverage allowed.\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.max_epochs = max_epochs\n",
        "        self.max_leverage = max_leverage\n",
        "        self.model = None\n",
        "\n",
        "    def prepare_data(self, df, time_idx, target, group_ids):\n",
        "        \"\"\"\n",
        "        Prepare dataset for asset allocation.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): Dataset containing returns.\n",
        "            time_idx (str): Name of the time index column.\n",
        "            target (str): Name of the target column (e.g., returns).\n",
        "            group_ids (list): List of group identifier column names (e.g., securities).\n",
        "        \"\"\"\n",
        "        # Ensure time_idx is datetime and sort data\n",
        "        df[time_idx] = pd.to_datetime(df[time_idx])\n",
        "        df.sort_values(by=group_ids + [time_idx], inplace=True)\n",
        "\n",
        "        # Assign a unique sequential integer time index within each group\n",
        "        df['time_idx'] = df.groupby(group_ids).cumcount()\n",
        "\n",
        "        # Create TimeSeriesDataSet\n",
        "        max_encoder_length = 30\n",
        "        max_prediction_length = 7\n",
        "\n",
        "        self.training_cutoff = df['time_idx'].max() - max_prediction_length\n",
        "\n",
        "        self.training = TimeSeriesDataSet(\n",
        "            df[df['time_idx'] <= self.training_cutoff],\n",
        "            time_idx='time_idx',\n",
        "            target=target,\n",
        "            group_ids=group_ids,\n",
        "            max_encoder_length=max_encoder_length,\n",
        "            max_prediction_length=max_prediction_length,\n",
        "            static_categoricals=group_ids,\n",
        "            time_varying_known_reals=['time_idx'],\n",
        "            time_varying_unknown_reals=[target],\n",
        "            target_normalizer=GroupNormalizer(groups=group_ids),\n",
        "            allow_missing_timesteps=True,\n",
        "        )\n",
        "\n",
        "        self.validation = TimeSeriesDataSet.from_dataset(\n",
        "            self.training, df[df['time_idx'] > self.training_cutoff], min_prediction_idx=self.training_cutoff + 1\n",
        "        )\n",
        "\n",
        "        self.batch_size = 64\n",
        "        self.train_dataloader = DataLoader(self.training, batch_size=self.batch_size, shuffle=True)\n",
        "        self.val_dataloader = DataLoader(self.validation, batch_size=self.batch_size)\n",
        "\n",
        "    # The rest of the class remains the same...\n",
        "    def fit(self):\n",
        "        \"\"\"\n",
        "        Fit the selected model.\n",
        "        \"\"\"\n",
        "        # Choose the model\n",
        "        if self.model_name == 'TFT':\n",
        "            self.model = TemporalFusionTransformer.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=16,\n",
        "                attention_head_size=1,\n",
        "                dropout=0.1,\n",
        "                hidden_continuous_size=8,\n",
        "                loss=QuantileLoss(),\n",
        "                log_interval=10,\n",
        "                reduce_on_plateau_patience=4,\n",
        "            )\n",
        "        elif self.model_name == 'RNN':\n",
        "            self.model = RecurrentNetwork.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=16,\n",
        "                rnn_layers=2,\n",
        "                dropout=0.1,\n",
        "                loss=RMSE(),\n",
        "            )\n",
        "        elif self.model_name == 'DeepAR':\n",
        "            self.model = DeepAR.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                rnn_layers=2,\n",
        "                hidden_size=16,\n",
        "                dropout=0.1,\n",
        "            )\n",
        "        elif self.model_name == 'NBeats':\n",
        "            self.model = NBeats.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "            )\n",
        "        elif self.model_name == 'NHiTS':\n",
        "            self.model = NHiTS.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "            )\n",
        "        elif self.model_name == 'Baseline':\n",
        "            self.model = Baseline()\n",
        "        elif self.model_name == 'AutoRegressive':\n",
        "            self.model = AutoRegressiveModel.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "            )\n",
        "        elif self.model_name == 'LSTM':\n",
        "            self.model = LSTMForecaster.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=16,\n",
        "                num_layers=2,\n",
        "                dropout=0.1,\n",
        "            )\n",
        "        elif self.model_name == 'TCN':\n",
        "            self.model = TCNForecaster.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                num_channels=[16]*3,\n",
        "                kernel_size=2,\n",
        "                dropout=0.1,\n",
        "            )\n",
        "        elif self.model_name == 'ProphetLike':\n",
        "            self.model = ProphetLikeModel.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                seasonality=10,\n",
        "            )\n",
        "        elif self.model_name == 'Signature':\n",
        "            self.model = SignatureModel.from_dataset(\n",
        "                self.training,\n",
        "                learning_rate=0.03,\n",
        "                hidden_size=32,\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Model {self.model_name} is not supported.\")\n",
        "\n",
        "        # Trainer\n",
        "        early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=False, mode=\"min\")\n",
        "        trainer = pl.Trainer(\n",
        "            max_epochs=self.max_epochs,\n",
        "            callbacks=[early_stop_callback],\n",
        "            gradient_clip_val=0.1,\n",
        "        )\n",
        "\n",
        "        # Fit the model\n",
        "        trainer.fit(self.model, train_dataloaders=self.train_dataloader, val_dataloaders=self.val_dataloader)\n",
        "\n",
        "    def predict(self, df):\n",
        "        \"\"\"\n",
        "        Make predictions on new data.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): DataFrame containing new data.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame with predictions.\n",
        "        \"\"\"\n",
        "        # Prepare dataset\n",
        "        raw_predictions, x = self.model.predict(df, mode=\"raw\", return_x=True)\n",
        "        predictions = self.model.to_prediction(raw_predictions)\n",
        "\n",
        "        # Combine predictions with input data\n",
        "        df_pred = df.copy()\n",
        "        df_pred['prediction'] = predictions\n",
        "        return df_pred\n",
        "\n",
        "    def backtest(self):\n",
        "        \"\"\"\n",
        "        Perform backtesting using the validation set.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame with backtesting predictions.\n",
        "        \"\"\"\n",
        "        actuals = torch.cat([y[0] for x, y in iter(self.val_dataloader)])\n",
        "        predictions = self.model.predict(self.val_dataloader)\n",
        "        df_backtest = pd.DataFrame({\n",
        "            'actual': actuals.numpy().flatten(),\n",
        "            'prediction': predictions.numpy().flatten(),\n",
        "        })\n",
        "\n",
        "        # Adjust leverage based on confidence\n",
        "        df_backtest['confidence'] = self.calculate_confidence(df_backtest)\n",
        "        df_backtest['leverage'] = df_backtest['confidence'] * self.max_leverage\n",
        "        df_backtest['leverage'] = df_backtest['leverage'].clip(0, self.max_leverage)\n",
        "\n",
        "        # Apply leverage to predictions\n",
        "        df_backtest['adjusted_prediction'] = df_backtest['prediction'] * df_backtest['leverage']\n",
        "        return df_backtest\n",
        "\n",
        "    def calculate_confidence(self, df):\n",
        "        \"\"\"\n",
        "        Calculate confidence level based on prediction errors.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): DataFrame with 'actual' and 'prediction' columns.\n",
        "\n",
        "        Returns:\n",
        "            pd.Series: Confidence levels between 0 and 1.\n",
        "        \"\"\"\n",
        "        errors = np.abs(df['actual'] - df['prediction'])\n",
        "        max_error = errors.max()\n",
        "        confidence = 1 - (errors / (max_error + 1e-6))\n",
        "        return confidence\n",
        "\n",
        "# Include the implementations of the other models (AutoRegressiveModel, LSTMForecaster, TCNForecaster, ProphetLikeModel, SignatureModel)\n",
        "\n",
        "# Example usage:\n",
        "# Generate synthetic data for demonstration\n",
        "def generate_synthetic_data(num_securities=10, num_days=500):\n",
        "    dates = pd.date_range(start='2020-01-01', periods=num_days, freq='D')\n",
        "    data = []\n",
        "    for security_id in range(num_securities):\n",
        "        price = 100 + np.cumsum(np.random.randn(num_days) * 0.5)\n",
        "        returns = np.diff(price) / price[:-1]\n",
        "        returns = np.insert(returns, 0, 0)  # Insert zero return for the first day\n",
        "        df = pd.DataFrame({\n",
        "            'date': dates,\n",
        "            'security_id': f'sec_{security_id}',\n",
        "            'price': price,\n",
        "            'returns': returns,\n",
        "        })\n",
        "        data.append(df)\n",
        "    df = pd.concat(data)\n",
        "    return df\n",
        "\n",
        "# Generate data\n",
        "df = generate_synthetic_data()\n",
        "\n",
        "# Initialize the wrapper\n",
        "wrapper = AssetAllocationWrapper(model_name='Signature', max_epochs=10, max_leverage=2.0)\n",
        "wrapper.prepare_data(df, time_idx='date', target='returns', group_ids=['security_id'])\n",
        "wrapper.fit()\n",
        "backtest_results = wrapper.backtest()\n",
        "print(backtest_results.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "MF_G49Irz4os",
        "outputId": "512e7706-34a5-4cde-f401-43138fac0bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "data index has to be unique",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-e86303694dba>\u001b[0m in \u001b[0;36m<cell line: 292>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;31m# Initialize the wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAssetAllocationWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Signature'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_leverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'returns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'security_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0mbacktest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbacktest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-e86303694dba>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self, df, time_idx, target, group_ids)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_prediction_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         self.training = TimeSeriesDataSet(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_idx'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mtime_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time_idx'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data index has to be unique\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;31m# add lags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: data index has to be unique"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "1eC4JHmW0CK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = ['TFT', 'RNN', 'DeepAR', 'NBeats', 'NHiTS', 'Baseline', 'AutoRegressive', 'LSTM', 'TCN', 'ProphetLike', 'Signature']\n",
        "results = {}\n",
        "\n",
        "for model_name in model_names:\n",
        "    print(f\"Training aand backtesting with model: {model_name}\")\n",
        "    wrapper = AssetAllocationWrapper(model_name=model_name, max_epochs=10, max_leverage=2.0)\n",
        "    wrapper.prepare_data(df, time_idx='date', target='returns', group_ids=['security_id'])\n",
        "    wrapper.fit()\n",
        "    backtest_results = wrapper.backtest()\n",
        "    results[model_name] = backtest_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Rj72fdshwFbN",
        "outputId": "cc2d7cbf-688d-45f7-cd9c-7b433db27441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and backtesting with model: TFT\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by StandardScaler.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f9b2ba8f5c7c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training and backtesting with model: {model_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAssetAllocationWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_leverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'returns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'security_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbacktest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbacktest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-d99fb32c04a9>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self, df, time_idx, target, group_ids)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_prediction_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         self.training = TimeSeriesDataSet(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_cutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mtime_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m# preprocess data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Target normalizer is separate and not in scalers.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \"\"\"\n\u001b[1;32m    913\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1088\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by StandardScaler."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2WXLQWozKhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for model_name, df_backtest in results.items():\n",
        "    # Compute strategy returns\n",
        "    df_backtest['strategy_returns'] = df_backtest['adjusted_prediction'] * df_backtest['actual']\n",
        "    # Compute cumulative returns\n",
        "    df_backtest['cumulative_returns'] = (1 + df_backtest['strategy_returns']).cumprod() - 1\n",
        "    plt.plot(df_backtest['cumulative_returns'].values, label=model_name)\n",
        "\n",
        "plt.legend()\n",
        "plt.title('Cumulative Returns Comparison')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Cumulative Returns')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w3imBbHwv9t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##claude"
      ],
      "metadata": {
        "id": "DHgi-pQNsE7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Financial Time Series Forecasting Package\n",
        "---------------------------------------\n",
        "A comprehensive package for financial time series forecasting using various deep learning models.\n",
        "\n",
        "This package includes:\n",
        "- Multiple model architectures (AutoRegressive, LSTM, TCN, ProphetLike)\n",
        "- Data validation and preprocessing\n",
        "- Model checkpointing and logging\n",
        "- Configuration management\n",
        "- Comprehensive testing suite\n",
        "\n",
        "Author: Assistant\n",
        "Date: 2024-10-20\n",
        "Version: 1.0.0\n",
        "\"\"\"\n",
        "\n",
        "import logging\n",
        "import yaml\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List, Dict, Any, Tuple, Union\n",
        "from datetime import datetime, timedelta\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_forecasting import TimeSeriesDataSet\n",
        "from pytorch_forecasting.metrics import RMSE, QuantileLoss\n",
        "from scipy import stats\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    \"\"\"Configuration class for model parameters.\n",
        "\n",
        "    Attributes:\n",
        "        model_name (str): Name of the model to use\n",
        "        max_epochs (int): Maximum number of training epochs\n",
        "        batch_size (int): Batch size for training\n",
        "        learning_rate (float): Learning rate for optimization\n",
        "        hidden_size (int): Number of hidden units in layers\n",
        "        dropout (float): Dropout rate for regularization\n",
        "        max_encoder_length (int): Maximum length of encoder sequence\n",
        "        max_prediction_length (int): Maximum length of prediction sequence\n",
        "    \"\"\"\n",
        "    model_name: str\n",
        "    max_epochs: int = 30\n",
        "    batch_size: int = 64\n",
        "    learning_rate: float = 0.03\n",
        "    hidden_size: int = 16\n",
        "    dropout: float = 0.1\n",
        "    max_encoder_length: int = 30\n",
        "    max_prediction_length: int = 7\n",
        "\n",
        "    @classmethod\n",
        "    def from_yaml(cls, yaml_path: str) -> 'ModelConfig':\n",
        "        \"\"\"Load configuration from YAML file.\n",
        "\n",
        "        Args:\n",
        "            yaml_path: Path to YAML configuration file\n",
        "\n",
        "        Returns:\n",
        "            ModelConfig instance\n",
        "        \"\"\"\n",
        "        with open(yaml_path, 'r') as f:\n",
        "            config_dict = yaml.safe_load(f)\n",
        "        return cls(**config_dict)\n",
        "\n",
        "    def to_yaml(self, yaml_path: str) -> None:\n",
        "        \"\"\"Save configuration to YAML file.\n",
        "\n",
        "        Args:\n",
        "            yaml_path: Path to save configuration\n",
        "        \"\"\"\n",
        "        with open(yaml_path, 'w') as f:\n",
        "            yaml.dump(self.__dict__, f)\n",
        "\n",
        "class DataValidator:\n",
        "    \"\"\"Data validation utilities.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def validate_dataframe(df: pd.DataFrame, required_columns: List[str]) -> bool:\n",
        "        \"\"\"Validate DataFrame structure and content.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            required_columns: List of required column names\n",
        "\n",
        "        Returns:\n",
        "            bool: True if validation passes\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If validation fails\n",
        "        \"\"\"\n",
        "        # Check for required columns\n",
        "        missing_cols = set(required_columns) - set(df.columns)\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Check for null values\n",
        "        null_cols = df.columns[df.isnull().any()].tolist()\n",
        "        if null_cols:\n",
        "            raise ValueError(f\"Null values found in columns: {null_cols}\")\n",
        "\n",
        "        # Check for infinite values\n",
        "        inf_cols = df.columns[np.isinf(df.select_dtypes(include=np.number)).any()].tolist()\n",
        "        if inf_cols:\n",
        "            raise ValueError(f\"Infinite values found in columns: {inf_cols}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "class ModelCheckpointer:\n",
        "    \"\"\"Model checkpointing utilities.\"\"\"\n",
        "\n",
        "    def __init__(self, checkpoint_dir: str):\n",
        "        \"\"\"Initialize checkpointer.\n",
        "\n",
        "        Args:\n",
        "            checkpoint_dir: Directory to store checkpoints\n",
        "        \"\"\"\n",
        "        self.checkpoint_dir = Path(checkpoint_dir)\n",
        "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def save_checkpoint(self, model: torch.nn.Module, epoch: int,\n",
        "                       optimizer: torch.optim.Optimizer, loss: float) -> str:\n",
        "        \"\"\"Save model checkpoint.\n",
        "\n",
        "        Args:\n",
        "            model: PyTorch model\n",
        "            epoch: Current epoch number\n",
        "            optimizer: PyTorch optimizer\n",
        "            loss: Current loss value\n",
        "\n",
        "        Returns:\n",
        "            str: Path to saved checkpoint\n",
        "        \"\"\"\n",
        "        checkpoint_path = self.checkpoint_dir / f\"checkpoint_epoch_{epoch}.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "        }, checkpoint_path)\n",
        "        return str(checkpoint_path)\n",
        "\n",
        "    def load_checkpoint(self, model: torch.nn.Module,\n",
        "                       optimizer: torch.optim.Optimizer,\n",
        "                       checkpoint_path: str) -> Tuple[int, float]:\n",
        "        \"\"\"Load model checkpoint.\n",
        "\n",
        "        Args:\n",
        "            model: PyTorch model\n",
        "            optimizer: PyTorch optimizer\n",
        "            checkpoint_path: Path to checkpoint file\n",
        "\n",
        "        Returns:\n",
        "            Tuple containing (epoch_number, loss_value)\n",
        "        \"\"\"\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        return checkpoint['epoch'], checkpoint['loss']\n",
        "\n",
        "class AutoRegressiveModel(pl.LightningModule):\n",
        "    \"\"\"Simple Autoregressive model using a Linear layer.\"\"\"\n",
        "\n",
        "    def __init__(self, input_size: int, output_size: int = 1, **kwargs):\n",
        "        \"\"\"Initialize AR model.\n",
        "\n",
        "        Args:\n",
        "            input_size: Number of input features\n",
        "            output_size: Number of output features\n",
        "            **kwargs: Additional arguments\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(input_size, output_size)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x: Dictionary containing input tensors\n",
        "\n",
        "        Returns:\n",
        "            Model predictions\n",
        "        \"\"\"\n",
        "        encoder_output = x[\"encoder_cont\"][:, -1, :]  # Use last time step\n",
        "        prediction = self.linear(encoder_output)\n",
        "        return prediction\n",
        "\n",
        "class LSTMForecaster(pl.LightningModule):\n",
        "    \"\"\"LSTM-based Forecaster.\"\"\"\n",
        "\n",
        "    def __init__(self, input_size: int, hidden_size: int, num_layers: int,\n",
        "                 dropout: float = 0.0, **kwargs):\n",
        "        \"\"\"Initialize LSTM model.\n",
        "\n",
        "        Args:\n",
        "            input_size: Number of input features\n",
        "            hidden_size: Number of hidden units\n",
        "            num_layers: Number of LSTM layers\n",
        "            dropout: Dropout rate\n",
        "            **kwargs: Additional arguments\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size, hidden_size, num_layers,\n",
        "            batch_first=True, dropout=dropout\n",
        "        )\n",
        "        self.output_layer = torch.nn.Linear(hidden_size, 1)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        encoder_input = x[\"encoder_cont\"]\n",
        "        output, (hidden, _) = self.lstm(encoder_input)\n",
        "        prediction = self.output_layer(hidden[-1])\n",
        "        return prediction\n",
        "\n",
        "class TCNBlock(torch.nn.Module):\n",
        "    \"\"\"Temporal Convolutional Network block.\"\"\"\n",
        "\n",
        "    def __init__(self, n_inputs: int, n_outputs: int, kernel_size: int,\n",
        "                 stride: int, dilation: int, padding: int, dropout: float = 0.2):\n",
        "        \"\"\"Initialize TCN block.\"\"\"\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(\n",
        "            n_inputs, n_outputs, kernel_size,\n",
        "            stride=stride, padding=padding, dilation=dilation\n",
        "        )\n",
        "        self.chomp1 = torch.nn.functional.pad  # Remove future timesteps\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.dropout1 = torch.nn.Dropout(dropout)\n",
        "\n",
        "        self.net = torch.nn.Sequential(\n",
        "            self.conv1,\n",
        "            self.relu1,\n",
        "            self.dropout1\n",
        "        )\n",
        "\n",
        "        self.downsample = torch.nn.Conv1d(n_inputs, n_outputs, 1) \\\n",
        "            if n_inputs != n_outputs else None\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\"Initialize network weights.\"\"\"\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "class TCNForecaster(pl.LightningModule):\n",
        "    \"\"\"Temporal Convolutional Network Forecaster.\"\"\"\n",
        "\n",
        "    def __init__(self, input_size: int, num_channels: List[int],\n",
        "                 kernel_size: int = 2, dropout: float = 0.2, **kwargs):\n",
        "        \"\"\"Initialize TCN model.\"\"\"\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = input_size if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TCNBlock(\n",
        "                in_channels, out_channels, kernel_size, stride=1,\n",
        "                dilation=dilation_size,\n",
        "                padding=(kernel_size-1) * dilation_size,\n",
        "                dropout=dropout\n",
        "            )]\n",
        "\n",
        "        self.network = torch.nn.Sequential(*layers)\n",
        "        self.output_layer = torch.nn.Linear(num_channels[-1], 1)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        encoder_input = x[\"encoder_cont\"].permute(0, 2, 1)\n",
        "        output = self.network(encoder_input)\n",
        "        output = output[:, :, -1]  # Take last time step\n",
        "        prediction = self.output_layer(output)\n",
        "        return prediction\n",
        "\n",
        "class ProphetLikeModel(pl.LightningModule):\n",
        "    \"\"\"Prophet-like model capturing trend and seasonality.\"\"\"\n",
        "\n",
        "    def __init__(self, seasonality: int, **kwargs):\n",
        "        \"\"\"Initialize Prophet-like model.\"\"\"\n",
        "        super().__init__()\n",
        "        self.trend = torch.nn.Linear(1, 1)\n",
        "        self.seasonality = torch.nn.Linear(seasonality, 1)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, x: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        time = x[\"encoder_cont\"][:, :, 0].unsqueeze(-1)\n",
        "        trend = self.trend(time)\n",
        "\n",
        "        seasonal_features = x[\"encoder_cont\"][:, :, 1:self.hparams.seasonality+1]\n",
        "        seasonality = self.seasonality(seasonal_features)\n",
        "\n",
        "        prediction = trend + seasonality\n",
        "        return prediction[:, -1, :]\n",
        "\n",
        "class BaseWrapper:\n",
        "    \"\"\"Base wrapper for all models.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        \"\"\"Initialize wrapper.\"\"\"\n",
        "        self.config = config\n",
        "        self.logger = logging.getLogger(f\"{self.__class__.__name__}\")\n",
        "        self.validator = DataValidator()\n",
        "        self.checkpointer = ModelCheckpointer(\"checkpoints\")\n",
        "        self.model = None\n",
        "        self.training_metrics = []\n",
        "\n",
        "    def prepare_data(self, df: pd.DataFrame, time_idx: str,\n",
        "                    target: str, group_ids: List[str]) -> None:\n",
        "        \"\"\"Prepare data for training.\"\"\"\n",
        "        # Validate data\n",
        "        self.validator.validate_dataframe(df, [time_idx, target] + group_ids)\n",
        "\n",
        "        # Create TimeSeriesDataSet\n",
        "        self.training = TimeSeriesDataSet(\n",
        "            df[df[time_idx] <= df[time_idx].max() - self.config.max_prediction_length],\n",
        "            time_idx=time_idx,\n",
        "            target=target,\n",
        "            group_ids=group_ids,\n",
        "            max_encoder_length=self.config.max_encoder_length,\n",
        "            max_prediction_length=self.config.max_prediction_length,\n",
        "            static_categoricals=group_ids,\n",
        "            time_varying_known_reals=[time_idx],\n",
        "            time_varying_unknown_reals=[target],\n",
        "            target_normalizer=None,\n",
        "            allow_missings=True,\n",
        "        )\n",
        "\n",
        "        self.validation = TimeSeriesDataSet.from_dataset(\n",
        "            self.training,\n",
        "            df[df[time_idx] > df[time_idx].max() - self.config.max_prediction_length],\n",
        "            min_prediction_idx=df[time_idx].max() - self.config.max_prediction_length + 1\n",
        "        )\n",
        "\n",
        "        self.train_dataloader = DataLoader(\n",
        "            self.training, batch_size=self.config.batch_size, shuffle=True\n",
        "        )\n",
        "        self.val_dataloader = DataLoader(\n",
        "            self.validation, batch_size=self.config.batch_size\n",
        "        )\n",
        "\n",
        "    def fit(self) -> None:\n",
        "        \"\"\"Train the model.\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not initialized\")\n",
        "\n",
        "        trainer = pl.Trainer(\n",
        "            max_epochs=self.config.max_epochs,\n",
        "            callbacks=[\n",
        "                EarlyStopping(\n",
        "                    monitor=\"val_loss\",\n",
        "                    min_delta=1e-4,\n",
        "                    patience=5,\n",
        "                    verbose=False,\n",
        "                    mode=\"min\"\n",
        "                )\n",
        "            ],\n",
        "            gradient_clip_val=0.1,\n",
        "        )\n",
        "\n",
        "        trainer.fit(\n",
        "            self.model,\n",
        "            train_dataloaders=self.train_dataloader,\n",
        "            val_dataloaders=self.val_dataloader\n",
        "        )\n",
        "\n",
        "    def predict(self, df: pd.DataFrame) -> np.ndarray:\n",
        "        \"\"\"Make predictions.\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained\")\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(\n",
        "                self.validation.to_dataloader(df, batch_size=self.config.batch_size)\n",
        "            )\n",
        "        return predictions.numpy()\n",
        "\n",
        "def generate_sample_data(n_assets: int = 5, n_days: int = 100,\n",
        "                        seed: int = 42) -> pd.DataFrame:\n",
        "    \"\"\"Generate sample financial data for testing.\n",
        "\n",
        "    Args:\n",
        "        n_assets: Number of assets\n",
        "        n_days: Number of days\n",
        "        seed: Random seed\n",
        "\n",
        "    Returns:\n",
        "        DataFrame containing sample data\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    dates = [datetime.today() - timedelta(days=x) for x in range(n_days)]\n",
        "    dates.reverse()\n",
        "\n",
        "    data = {\n",
        "        'time': dates * n_assets,\n",
        "        'group_id': np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "VHXn706ZsGPW",
        "outputId": "d2f40578-18eb-497e-df00-8edef42cab89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-1-92dd88ec71fe>, line 423)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-92dd88ec71fe>\"\u001b[0;36m, line \u001b[0;32m423\u001b[0m\n\u001b[0;31m    'group_id': np\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import yaml\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List, Dict, Any\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    \"\"\"Base configuration for all models.\"\"\"\n",
        "    model_name: str\n",
        "    max_epochs: int = 30\n",
        "    batch_size: int = 64\n",
        "    learning_rate: float = 0.03\n",
        "    hidden_size: int = 16\n",
        "    dropout: float = 0.1\n",
        "    max_encoder_length: int = 30\n",
        "    max_prediction_length: int = 7\n",
        "\n",
        "    @classmethod\n",
        "    def from_yaml(cls, yaml_path: str) -> 'ModelConfig':\n",
        "        \"\"\"Load configuration from YAML file.\"\"\"\n",
        "        with open(yaml_path, 'r') as f:\n",
        "            config_dict = yaml.safe_load(f)\n",
        "        return cls(**config_dict)\n",
        "\n",
        "    def to_yaml(self, yaml_path: str) -> None:\n",
        "        \"\"\"Save configuration to YAML file.\"\"\"\n",
        "        with open(yaml_path, 'w') as f:\n",
        "            yaml.dump(self.__dict__, f)\n",
        "\n",
        "class DataValidator:\n",
        "    \"\"\"Validates input data quality.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def validate_dataframe(df: pd.DataFrame, required_columns: List[str]) -> bool:\n",
        "        \"\"\"\n",
        "        Validate DataFrame structure and content.\n",
        "\n",
        "        Args:\n",
        "            df: Input DataFrame\n",
        "            required_columns: List of required column names\n",
        "\n",
        "        Returns:\n",
        "            bool: True if validation passes\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If validation fails\n",
        "        \"\"\"\n",
        "        # Check for required columns\n",
        "        missing_cols = set(required_columns) - set(df.columns)\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Check for null values\n",
        "        null_cols = df.columns[df.isnull().any()].tolist()\n",
        "        if null_cols:\n",
        "            raise ValueError(f\"Null values found in columns: {null_cols}\")\n",
        "\n",
        "        # Check for infinite values\n",
        "        inf_cols = df.columns[np.isinf(df.select_dtypes(include=np.number)).any()].tolist()\n",
        "        if inf_cols:\n",
        "            raise ValueError(f\"Infinite values found in columns: {inf_cols}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "class ModelCheckpointer:\n",
        "    \"\"\"Handles model checkpointing and recovery.\"\"\"\n",
        "\n",
        "    def __init__(self, checkpoint_dir: str):\n",
        "        self.checkpoint_dir = Path(checkpoint_dir)\n",
        "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def save_checkpoint(self, model: torch.nn.Module, epoch: int,\n",
        "                       optimizer: torch.optim.Optimizer, loss: float) -> str:\n",
        "        \"\"\"Save model checkpoint.\"\"\"\n",
        "        checkpoint_path = self.checkpoint_dir / f\"checkpoint_epoch_{epoch}.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "        }, checkpoint_path)\n",
        "        return str(checkpoint_path)\n",
        "\n",
        "    def load_checkpoint(self, model: torch.nn.Module,\n",
        "                       optimizer: torch.optim.Optimizer,\n",
        "                       checkpoint_path: str) -> tuple:\n",
        "        \"\"\"Load model checkpoint.\"\"\"\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        return checkpoint['epoch'], checkpoint['loss']\n",
        "\n",
        "class BaseWrapper:\n",
        "    \"\"\"Enhanced base wrapper with improved functionality.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        self.config = config\n",
        "        self.logger = logging.getLogger(f\"{self.__class__.__name__}\")\n",
        "        self.validator = DataValidator()\n",
        "        self.checkpointer = ModelCheckpointer(\"checkpoints\")\n",
        "        self.model = None\n",
        "        self.training_metrics = []\n",
        "\n",
        "    def log_metrics(self, metrics: Dict[str, Any]) -> None:\n",
        "        \"\"\"Log training metrics.\"\"\"\n",
        "        self.training_metrics.append(metrics)\n",
        "        self.logger.info(f\"Metrics: {metrics}\")\n",
        "\n",
        "    def save_metrics(self, path: str) -> None:\n",
        "        \"\"\"Save training metrics to file.\"\"\"\n",
        "        pd.DataFrame(self.training_metrics).to_csv(path, index=False)"
      ],
      "metadata": {
        "id": "5Gv7_lJ4s_CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def generate_sample_data(n_assets: int = 5, n_days: int = 100, seed: int = 42) -> pd.DataFrame:\n",
        "    \"\"\"Generate sample financial data for testing.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Create dates\n",
        "    dates = [datetime.today() - timedelta(days=x) for x in range(n_days)]\n",
        "    dates.reverse()\n",
        "\n",
        "    # Generate data\n",
        "    data = {\n",
        "        'time': dates * n_assets,\n",
        "        'group_id': np.repeat(range(n_assets), n_days),\n",
        "        'returns': np.random.normal(0, 0.02, n_assets * n_days),\n",
        "        'volume': np.random.lognormal(0, 1, n_assets * n_days),\n",
        "        'price': np.random.lognormal(4, 0.1, n_assets * n_days),\n",
        "        'volatility': np.random.gamma(2, 0.1, n_assets * n_days)\n",
        "    }\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Example 1: AutoRegressive Model\n",
        "def run_autoregressive_example():\n",
        "    # Generate data\n",
        "    df = generate_sample_data()\n",
        "\n",
        "    # Configure model\n",
        "    config = ModelConfig(\n",
        "        model_name='AutoRegressive',\n",
        "        max_epochs=20,\n",
        "        hidden_size=16\n",
        "    )\n",
        "\n",
        "    # Initialize and train\n",
        "    model = AutoRegressiveModel(\n",
        "        input_size=len(df.columns) - 2,  # Exclude time and group_id\n",
        "        output_size=1\n",
        "    )\n",
        "\n",
        "    wrapper = BaseWrapper(config)\n",
        "    wrapper.model = model\n",
        "\n",
        "    # Train and evaluate\n",
        "    wrapper.prepare_data(df, time_idx='time', target='returns', group_ids=['group_id'])\n",
        "    wrapper.fit()\n",
        "    predictions = wrapper.predict(df.tail(10))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example 2: LSTM Model\n",
        "def run_lstm_example():\n",
        "    df = generate_sample_data()\n",
        "\n",
        "    config = ModelConfig(\n",
        "        model_name='LSTM',\n",
        "        max_epochs=20,\n",
        "        hidden_size=32,\n",
        "        num_layers=2\n",
        "    )\n",
        "\n",
        "    model = LSTMForecaster(\n",
        "        input_size=len(df.columns) - 2,\n",
        "        hidden_size=config.hidden_size,\n",
        "        num_layers=2\n",
        "    )\n",
        "\n",
        "    wrapper = BaseWrapper(config)\n",
        "    wrapper.model = model\n",
        "    wrapper.prepare_data(df, time_idx='time', target='returns', group_ids=['group_id'])\n",
        "    wrapper.fit()\n",
        "\n",
        "    return wrapper.predict(df.tail(10))\n",
        "\n",
        "# Example 3: TCN Model\n",
        "def run_tcn_example():\n",
        "    df = generate_sample_data()\n",
        "\n",
        "    config = ModelConfig(\n",
        "        model_name='TCN',\n",
        "        max_epochs=20,\n",
        "        hidden_size=32\n",
        "    )\n",
        "\n",
        "    model = TCNForecaster(\n",
        "        input_size=len(df.columns) - 2,\n",
        "        num_channels=[32, 32, 32],\n",
        "        kernel_size=3\n",
        "    )\n",
        "\n",
        "    wrapper = BaseWrapper(config)\n",
        "    wrapper.model = model\n",
        "    wrapper.prepare_data(df, time_idx='time', target='returns', group_ids=['group_id'])\n",
        "    wrapper.fit()\n",
        "\n",
        "    return wrapper.predict(df.tail(10))\n",
        "\n",
        "# Example 4: ProphetLike Model\n",
        "def run_prophet_example():\n",
        "    df = generate_sample_data()\n",
        "\n",
        "    config = ModelConfig(\n",
        "        model_name='ProphetLike',\n",
        "        max_epochs=20,\n",
        "        seasonality=10\n",
        "    )\n",
        "\n",
        "    model = ProphetLikeModel(seasonality=10)\n",
        "\n",
        "    wrapper = BaseWrapper(config)\n",
        "    wrapper.model = model\n",
        "    wrapper.prepare_data(df, time_idx='time', target='returns', group_ids=['group_id'])\n",
        "    wrapper.fit()\n",
        "\n",
        "    return wrapper.predict(df.tail(10))\n",
        "\n",
        "# Run all examples\n",
        "if __name__ == \"__main__\":\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    models = {\n",
        "        'AutoRegressive': run_autoregressive_example,\n",
        "        'LSTM': run_lstm_example,\n",
        "        'TCN': run_tcn_example,\n",
        "        'ProphetLike': run_prophet_example\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for model_name, run_func in models.items():\n",
        "        try:\n",
        "            logger.info(f\"Running {model_name} example...\")\n",
        "            predictions = run_func()\n",
        "            results[model_name] = predictions\n",
        "            logger.info(f\"{model_name} completed successfully\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error running {model_name}: {str(e)}\")\n",
        "\n",
        "    # Compare results\n",
        "    comparison_df = pd.DataFrame({\n",
        "        model_name: results[model_name]['predictions'].mean()\n",
        "        for model_name in results.keys()\n",
        "    })\n",
        "\n",
        "    print(\"\\nModel Comparison:\")\n",
        "    print(comparison_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4CY_aDUtiod",
        "outputId": "dd01a447-426d-4247-a3a0-12909a8b98d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error running AutoRegressive: name 'AutoRegressiveModel' is not defined\n",
            "ERROR:__main__:Error running LSTM: ModelConfig.__init__() got an unexpected keyword argument 'num_layers'\n",
            "ERROR:__main__:Error running TCN: name 'TCNForecaster' is not defined\n",
            "ERROR:__main__:Error running ProphetLike: ModelConfig.__init__() got an unexpected keyword argument 'seasonality'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Comparison:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example configuration file"
      ],
      "metadata": {
        "id": "jfgv1Ut6trh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config.yaml\n",
        "model_name: LSTM\n",
        "max_epochs: 30\n",
        "batch_size: 64\n",
        "learning_rate: 0.03\n",
        "hidden_size: 32\n",
        "dropout: 0.1\n",
        "max_encoder_length: 30\n",
        "max_prediction_length: 7\n",
        "num_layers: 2  # LSTM specific\n",
        "kernel_size: 3  # TCN specific\n",
        "seasonality: 10  # ProphetLike specific"
      ],
      "metadata": {
        "id": "wuDOCuTetvME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "class TestModelBaseStructure(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.config = ModelConfig(model_name='LSTM')\n",
        "        self.sample_data = generate_sample_data(n_assets=2, n_days=50)\n",
        "\n",
        "    def test_data_validator(self):\n",
        "        validator = DataValidator()\n",
        "\n",
        "        # Test valid data\n",
        "        self.assertTrue(validator.validate_dataframe(\n",
        "            self.sample_data,\n",
        "            ['time', 'group_id', 'returns']\n",
        "        ))\n",
        "\n",
        "        # Test invalid data\n",
        "        invalid_df = self.sample_data.copy()\n",
        "        invalid_df.loc[0, 'returns'] = np.nan\n",
        "        with self.assertRaises(ValueError):\n",
        "            validator.validate_dataframe(invalid_df, ['time', 'group_id', 'returns'])\n",
        "\n",
        "    def test_model_checkpointing(self):\n",
        "        checkpointer = ModelCheckpointer(\"test_checkpoints\")\n",
        "        model = LSTMForecaster(input_size=5, hidden_size=16, num_layers=2)\n",
        "        optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "        # Test saving\n",
        "        checkpoint_path = checkpointer.save_checkpoint(model, 1, optimizer, 0.5)\n",
        "        self.assertTrue(Path(checkpoint_path).exists())\n",
        "\n",
        "        # Test loading\n",
        "        new_model = LSTMForecaster(input_size=5, hidden_size=16, num_layers=2)\n",
        "        new_optimizer = torch.optim.Adam(new_model.parameters())\n",
        "        epoch, loss = checkpointer.load_checkpoint(new_model, new_optimizer, checkpoint_path)\n",
        "        self.assertEqual(epoch, 1)\n",
        "        self.assertEqual(loss, 0.5)\n",
        "\n",
        "    def tearDown(self):\n",
        "        # Clean up test checkpoints\n",
        "        for file in Path(\"test_checkpoints\").glob(\"*.pt\"):\n",
        "            file.unlink()\n",
        "        Path(\"test_checkpoints\").rmdir()\n",
        "\n",
        "class TestModels(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.sample_data = generate_sample_data()\n",
        "\n",
        "    def test_autoregressive_model(self):\n",
        "        model = AutoRegressiveModel(input_size=5)\n",
        "        self.assertIsInstance(model, torch.nn.Module)\n",
        "\n",
        "        # Test forward pass\n",
        "        x = {\"encoder_cont\": torch.randn(2, 10, 5)}\n",
        "        output = model(x)\n",
        "        self.assertEqual(output.shape, (2, 1))\n",
        "\n",
        "    def test_lstm_model(self):\n",
        "        model = LSTMForecaster(input_size=5, hidden_size=16, num_layers=2)\n",
        "        self.assertIsInstance(model, torch.nn.Module)\n",
        "\n",
        "        # Test forward pass\n",
        "        x = {\"encoder_cont\": torch.randn(2, 10, 5)}\n",
        "        output = model(x)\n",
        "        self.assertEqual(output.shape, (2, 1))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "OPGBA4f4ty9m",
        "outputId": "a0ddbd11-46c4-4c86-cade-bcc5ef9f3d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "E\n",
            "======================================================================\n",
            "ERROR: /root/ (unittest.loader._FailedTest)\n",
            "----------------------------------------------------------------------\n",
            "AttributeError: module '__main__' has no attribute '/root/'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.002s\n",
            "\n",
            "FAILED (errors=1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "True",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2024/10/24"
      ],
      "metadata": {
        "id": "z9Sdn60r3NrQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR6oZwJ93XIp",
        "outputId": "1c20e47e-e410-49e8-a7a8-8e171dfdc473"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.6.1)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.10.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.2.0)\n",
            "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Downloading torchmetrics-1.5.1-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.11.8 pytorch_lightning-2.4.0 torchmetrics-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import yaml\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List, Dict, Any, Tuple, Union\n",
        "from datetime import datetime, timedelta\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from itertools import product\n",
        "from scipy import stats\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    \"\"\"Configuration for model parameters.\"\"\"\n",
        "    model_name: str\n",
        "    max_epochs: int = 30\n",
        "    batch_size: int = 64\n",
        "    learning_rate: float = 0.001\n",
        "    hidden_size: int = 128\n",
        "    dropout: float = 0.1\n",
        "    max_encoder_length: int = 30\n",
        "    max_prediction_length: int = 7\n",
        "    num_layers: int = 2\n",
        "    num_heads: int = 8\n",
        "\n",
        "    @classmethod\n",
        "    def from_yaml(cls, yaml_path: str) -> 'ModelConfig':\n",
        "        with open(yaml_path, 'r') as f:\n",
        "            config_dict = yaml.safe_load(f)\n",
        "        return cls(**config_dict)\n",
        "\n",
        "class FinancialDataset(Dataset):\n",
        "    \"\"\"Dataset for financial time series with multiple outputs.\"\"\"\n",
        "    def __init__(self, X1, X2, y_class=None, y_alloc=None, is_train=True):\n",
        "        self.X1 = torch.tensor(X1, dtype=torch.float32)\n",
        "        self.X2 = torch.tensor(X2, dtype=torch.float32)\n",
        "        if y_class is not None:\n",
        "            self.y_class = torch.tensor(y_class, dtype=torch.long)\n",
        "        if y_alloc is not None:\n",
        "            self.y_alloc = torch.tensor(y_alloc, dtype=torch.float32)\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_train:\n",
        "            return (self.X1[idx], self.X2[idx],\n",
        "                   self.y_class[idx], self.y_alloc[idx])\n",
        "        return self.X1[idx], self.X2[idx]\n",
        "\n",
        "class BaseModel(pl.LightningModule):\n",
        "    \"\"\"Base model with common functionality.\"\"\"\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(),\n",
        "                                   lr=self.config.learning_rate)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='min', factor=0.1, patience=5)\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": scheduler,\n",
        "            \"monitor\": \"val_loss\"\n",
        "        }\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        X1, X2, y_class, y_alloc = batch\n",
        "        class_out, alloc_out = self(X1, X2)\n",
        "\n",
        "        # Classification loss\n",
        "        class_loss = F.cross_entropy(\n",
        "            class_out.view(-1, class_out.size(-1)),\n",
        "            y_class.view(-1)\n",
        "        )\n",
        "\n",
        "        # Allocation loss (MSE)\n",
        "        alloc_loss = F.mse_loss(alloc_out, y_alloc)\n",
        "\n",
        "        # Sharpe ratio computation for allocation\n",
        "        returns = (alloc_out * y_alloc).sum(dim=1)\n",
        "        sharpe = torch.mean(returns) / (torch.std(returns) + 1e-6)\n",
        "\n",
        "        total_loss = class_loss + alloc_loss - 0.1 * sharpe\n",
        "\n",
        "        self.log('train_loss', total_loss)\n",
        "        return total_loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        X1, X2, y_class, y_alloc = batch\n",
        "        class_out, alloc_out = self(X1, X2)\n",
        "\n",
        "        class_loss = F.cross_entropy(\n",
        "            class_out.view(-1, class_out.size(-1)),\n",
        "            y_class.view(-1)\n",
        "        )\n",
        "        alloc_loss = F.mse_loss(alloc_out, y_alloc)\n",
        "\n",
        "        returns = (alloc_out * y_alloc).sum(dim=1)\n",
        "        sharpe = torch.mean(returns) / (torch.std(returns) + 1e-6)\n",
        "\n",
        "        self.log('val_loss', class_loss + alloc_loss - 0.1 * sharpe)\n",
        "        self.log('val_sharpe', sharpe)\n",
        "\n",
        "# Model Implementations\n",
        "\n",
        "class MatrixModel(BaseModel):\n",
        "    \"\"\"Matrix regression with dual output heads.\"\"\"\n",
        "    def __init__(self, config: ModelConfig, input_size: int,\n",
        "                 num_securities: int):\n",
        "        super().__init__(config)\n",
        "        self.A = torch.nn.Parameter(\n",
        "            torch.randn(1, num_securities))\n",
        "        self.B_class = torch.nn.Parameter(\n",
        "            torch.randn(input_size, 3))\n",
        "        self.B_alloc = torch.nn.Parameter(\n",
        "            torch.randn(input_size, 1))\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x = torch.cat([x1.view(x1.size(0), -1),\n",
        "                      x2.view(x2.size(0), -1)], dim=1)\n",
        "        class_out = self.A @ x @ self.B_class\n",
        "        alloc_out = F.softmax(self.A @ x @ self.B_alloc, dim=1)\n",
        "        return class_out, alloc_out\n",
        "\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"LSTM with dual output heads.\"\"\"\n",
        "    def __init__(self, config: ModelConfig, input_size: int,\n",
        "                 num_securities: int):\n",
        "        super().__init__(config)\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=config.hidden_size,\n",
        "            num_layers=config.num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=config.dropout\n",
        "        )\n",
        "        self.class_head = torch.nn.Linear(\n",
        "            config.hidden_size, num_securities * 3)\n",
        "        self.alloc_head = torch.nn.Linear(\n",
        "            config.hidden_size, num_securities)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x = torch.cat([x1, x2], dim=2)\n",
        "        out, _ = self.lstm(x)\n",
        "        last_hidden = out[:, -1, :]\n",
        "\n",
        "        class_out = self.class_head(last_hidden)\n",
        "        class_out = class_out.view(-1, num_securities, 3)\n",
        "\n",
        "        alloc_out = self.alloc_head(last_hidden)\n",
        "        alloc_out = F.softmax(alloc_out, dim=1)\n",
        "\n",
        "        return class_out, alloc_out\n",
        "\n",
        "class TransformerModel(BaseModel):\n",
        "    \"\"\"Transformer with dual output heads.\"\"\"\n",
        "    def __init__(self, config: ModelConfig, input_size: int,\n",
        "                 num_securities: int):\n",
        "        super().__init__(config)\n",
        "        self.embedding = torch.nn.Linear(input_size, config.hidden_size)\n",
        "        encoder_layer = torch.nn.TransformerEncoderLayer(\n",
        "            d_model=config.hidden_size,\n",
        "            nhead=config.num_heads,\n",
        "            dropout=config.dropout\n",
        "        )\n",
        "        self.transformer = torch.nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=config.num_layers\n",
        "        )\n",
        "        self.class_head = torch.nn.Linear(\n",
        "            config.hidden_size, num_securities * 3)\n",
        "        self.alloc_head = torch.nn.Linear(\n",
        "            config.hidden_size, num_securities)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x = torch.cat([x1, x2], dim=2)\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        out = self.transformer(x)\n",
        "        out = out[-1]\n",
        "\n",
        "        class_out = self.class_head(out)\n",
        "        class_out = class_out.view(-1, num_securities, 3)\n",
        "\n",
        "        alloc_out = self.alloc_head(out)\n",
        "        alloc_out = F.softmax(alloc_out, dim=1)\n",
        "\n",
        "        return class_out, alloc_out\n",
        "\n",
        "def prepare_data(df: pd.DataFrame,\n",
        "                window_size: int = 20,\n",
        "                prediction_horizon: int = 1):\n",
        "    \"\"\"Prepare data for training and testing.\"\"\"\n",
        "    # Assume df has columns: timestamp, features (X1), features (X2),\n",
        "    # class labels, returns\n",
        "\n",
        "    scaler_X1 = MinMaxScaler()\n",
        "    scaler_X2 = MinMaxScaler()\n",
        "\n",
        "    X1 = scaler_X1.fit_transform(df[X1_columns].values)\n",
        "    X2 = scaler_X2.fit_transform(df[X2_columns].values)\n",
        "    y_class = df[class_columns].values\n",
        "    returns = df[return_columns].values\n",
        "\n",
        "    # Create windows\n",
        "    X1_windows, X2_windows, y_class_windows, return_windows = [], [], [], []\n",
        "\n",
        "    for i in range(len(df) - window_size - prediction_horizon + 1):\n",
        "        X1_windows.append(X1[i:i+window_size])\n",
        "        X2_windows.append(X2[i:i+window_size])\n",
        "        y_class_windows.append(y_class[i+window_size+prediction_horizon-1])\n",
        "        return_windows.append(returns[i+window_size+prediction_horizon-1])\n",
        "\n",
        "    # Convert to arrays\n",
        "    X1_windows = np.array(X1_windows)\n",
        "    X2_windows = np.array(X2_windows)\n",
        "    y_class_windows = np.array(y_class_windows)\n",
        "    return_windows = np.array(return_windows)\n",
        "\n",
        "    # Train/test split\n",
        "    train_size = int(0.8 * len(X1_windows))\n",
        "\n",
        "    train_dataset = FinancialDataset(\n",
        "        X1_windows[:train_size],\n",
        "        X2_windows[:train_size],\n",
        "        y_class_windows[:train_size],\n",
        "        return_windows[:train_size]\n",
        "    )\n",
        "\n",
        "    test_dataset = FinancialDataset(\n",
        "        X1_windows[train_size:],\n",
        "        X2_windows[train_size:],\n",
        "        y_class_windows[train_size:],\n",
        "        return_windows[train_size:]\n",
        "    )\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def train_and_evaluate(model: BaseModel,\n",
        "                      train_dataset: Dataset,\n",
        "                      test_dataset: Dataset,\n",
        "                      config: ModelConfig):\n",
        "    \"\"\"Train and evaluate a model.\"\"\"\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=config.batch_size\n",
        "    )\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=config.max_epochs,\n",
        "        callbacks=[\n",
        "            EarlyStopping(\n",
        "                monitor=\"val_loss\",\n",
        "                patience=5\n",
        "            )\n",
        "        ],\n",
        "        gradient_clip_val=0.1\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, train_loader, test_loader)\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    all_returns = []\n",
        "    all_class_preds = []\n",
        "    all_class_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            X1, X2, y_class, y_alloc = batch\n",
        "            class_out, alloc_out = model(X1, X2)\n",
        "\n",
        "            returns = (alloc_out * y_alloc).sum(dim=1)\n",
        "            all_returns.extend(returns.cpu().numpy())\n",
        "\n",
        "            _, predicted = torch.max(class_out.data, 2)\n",
        "            all_class_preds.extend(predicted.cpu().numpy().flatten())\n",
        "            all_class_true.extend(y_class.cpu().numpy().flatten())\n",
        "\n",
        "    # Calculate metrics\n",
        "    returns = np.array(all_returns)\n",
        "    sharpe = np.mean(returns) / (np.std(returns) + 1e-6)\n",
        "    kappa = cohen_kappa_score(all_class_true, all_class_preds)\n",
        "\n",
        "    print(f\"Sharpe Ratio: {sharpe:.4f}\")\n",
        "    print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
        "\n",
        "    return sharpe, kappa\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load configuration\n",
        "    config = ModelConfig(\n",
        "        model_name=\"transformer\",\n",
        "        max_epochs=30,\n",
        "        batch_size=64,\n",
        "        learning_rate=0.001,\n",
        "        hidden_size=128,\n",
        "        dropout=0.1\n",
        "    )\n",
        "\n",
        "    # Generate sample data (replace with real data)\n",
        "    num_samples = 1000\n",
        "    num_features_x1 = 10\n",
        "    num_features_x2 = 5\n",
        "    num_securities = 5\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'timestamp': pd.date_range(\n",
        "            start='2023-01-01',\n",
        "            periods=num_samples,\n",
        "            freq='D'\n",
        "        )\n",
        "    })\n",
        "\n",
        "    # Add features and targets\n",
        "    for i in range(num_features_x1):\n",
        "        df[f'x1_{i}'] = np.random.randn(num_samples)\n",
        "    for i in range(num_features_x2):\n",
        "        df[f'x2_{i}'] = np.random.randn(num_samples)\n",
        "    for i in range(num_securities):\n",
        "        df[f'class_{i}'] = np.random.randint(0, 3, num_samples)\n",
        "        df[f'return_{i}'] = np.random.randn(num_samples)\n",
        "\n",
        "    # Prepare data\n",
        "    X1_columns = [f'x1_{i}' for i in range(num_features_x1)]\n",
        "    X2_columns = [f'x2_{i}' for i in range(num_features_x2)]\n",
        "    class_columns = [f'class_{i}' for i in range(num_securities)]\n",
        "    return_columns = [f'return_{i}' for i in range(num_securities)]\n",
        "\n",
        "    train_dataset, test_dataset = prepare_data(df)\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = TransformerModel(\n",
        "        config,\n",
        "        input_size=num_features_x1 + num_features_x2,\n",
        "        num_securities=num_securities\n",
        "    )\n",
        "\n",
        "    sharpe, kappa = train_and_evaluate(\n",
        "        model,\n",
        "        train_dataset,\n",
        "        test_dataset,\n",
        "        config\n",
        "    )\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462,
          "referenced_widgets": [
            "8c623da5397d4d1e92253f717bd9b688",
            "a1cd538ca7ae4bb599a2898dfbf7b08c",
            "b417fa22a6eb47a4b8fdc8490d1a71b6",
            "eb5e580b4784416cbf6e698545cad529",
            "67c644b6cae7453a87cc04676da56a4b",
            "cb606b618d8649e48849874f93468b84",
            "ad937243d72e4463ae793de486a6df59",
            "81143868f6d049e2b1d8187dc306f92e",
            "61f2c7b02e8a4f1dba79da171d55f15f",
            "2fcec5d2e4cf4f25a7ba025c4d817c29",
            "52e12cb482c54a97a03750aa013a2328",
            "0c5f3e9fc0144f2db1d73cf1a02ad4ee",
            "36d9d5064dce4aa7b3c777662af628ed",
            "ada9f712358e4ab48e61c1f522c64f0c",
            "c211278507ca4536ae4a72deb30c0420",
            "e4f6ce14e27347a8a4e5e382bf946c74",
            "86adcf7eb21d466c82e8337fa009073b",
            "7b30baefc3d04ec296f6958f59b650f6",
            "c88507be1d9249239602167fa118c93e",
            "980b254ee86d450a9bfb978b271b61db",
            "b46b1578284f4c82878eeaec67542a3f",
            "cd500e9f6baa4884a6754d00e1589206",
            "3d4f061b00694486b4791c0b42cc1167",
            "7ccc8eddec4244e5bdffec03961b7dc2",
            "92677997b7ba4d70ab7dcf605148e026",
            "a716e342b0004a5f88c4454e1f689f0f",
            "4a8b311f348f4f2c8754c078f5fa685b",
            "fe142ac5d9404851bfa1bb823fffde3a",
            "c03fb217129240b4a3559a68f9c37755",
            "c4c481a567ed4f4aa62b9933df015346",
            "976697817c404f668072fd9653379410",
            "240533edc3d24228b9c82669f343be8a",
            "5a81e5da6547485fa5e45f51a5776278",
            "731dc9e78dbc48ad90793a135c612600",
            "42b01062f563474fa42a30b0501ba0d8",
            "09c6ded36d8549068f77b5fc53340bc5",
            "b0f7ef73dc5043058ae2d717a44c565f",
            "f98b3b78bebe4cdd9ac248a933c044c9",
            "46cb21c196fb489da13a17ac2d136e92",
            "f2517b31bc514ccdb72dfaefa76004e8",
            "5706001789af439db3f8616f39976753",
            "b1f6f3726d514c9ebbb503db7bfd5d51",
            "fe9fc7932a99402794ef93a403c7ca2c",
            "fbcdc141855d42198f485df6a011bbaf",
            "de6995a61e184166936a7f848bf690ec",
            "557ea6fafe1d4f90ad659506b04e4355",
            "8d416405b1d947f4bee5c0a349717d2c",
            "05582b564d9e43b1b9af223c0b264d35",
            "067b6587679542c199356b5f8d272f19",
            "b4dcf3b2e5d3498e8ae29de6ac4d685e",
            "2d310023f53f4f1a935a8a91b1857c18",
            "5b0b651cf5114a1ab80aad988b446fc6",
            "33ac45b164564522ad6e4542eacd5256",
            "2858b2e2a8e24eeaa7651732bb2a96b3",
            "4f53df645fee47fea26bec89474096d3",
            "fad0c6f3c19141b1b31bae9173e5dd23",
            "4510fb8a65cd41a798901d8bb27749e9",
            "bf1720921b294c39986bd01490a9ec89",
            "45c03d76f47748fab7a52994cb494d11",
            "f804ac4488ed40c8be8e7a3008f0e4be",
            "c40c2f7c18d448e19e9dbe7622299307",
            "b7f1a724a16e491d9393cc5f3780fdfd",
            "7999e459482c46a99dcc60c88e95c916",
            "f2f02120dc264b6a9fd119307de402ce",
            "98f384523feb45ffbfd7e0e502612654",
            "b80a8958e81648aba746fb9c9eb58b2e",
            "38467aa64dc742a6af97c4effc388d0c",
            "e7644515d2c14671ae08df2210405f90",
            "c58c3cb647fe48a9bba1ab25cb6c08a4",
            "92121391d7d440f997c04d90159e329c",
            "31254012a5a34cb0be4ee190e590546d",
            "fe4ca4526ca74349a07f3e79147f7185",
            "f0d0e19fafdc45318c8a7611ec7155b0",
            "a872536867ca418baf5fdb1a91500105",
            "eb901a803b694e3194f8a77e1ee401c0",
            "266d1d551509467e91e94925684ab5ff",
            "97693fd92a0d498f9ffff6db328960c7",
            "0dde1b916f414c2480eb3071cab17c2d",
            "9999a3caa2a14452bee7088dddd7de91",
            "60f6fce1b50d42f5bbad7960b1651dad",
            "bceadfc4d2784685a648b543a507cde6",
            "973faa901dec4173857288b8dbf07b6f",
            "0bb1a7f0130c49f19f42c47632435442",
            "a1b94d72544448c398538f1ca2927b33",
            "e38760fa373140ca9517aadfab9f05bd",
            "7b9f99d99db24ee2ba20a35a18878422",
            "88d7f25d3a634639b9dd77b5101a3d85",
            "4f2757ad322745a7b6c23b0e9ea6a7ac",
            "36d04b9bce3f4c2798476b2ca0086643",
            "fd35bdb8af87453689b229bcda35b082",
            "0b6dbeb3fc3440ac82e56893e2213b69",
            "f558413902054b8fa362e51caaf24ed8",
            "46b036d694dc47019c50fe1164648a55",
            "a1f03f5487c3456f93d4fcea9a58e336",
            "d54dceba635c40d5b921da53057b1e25",
            "9af43ec91483484da1fbd4652bb8d676",
            "c1d81685995040cdaea4d04f3fc6975b",
            "f7b99878ff7c459292e1e7cd83f3db14",
            "ab59be30b8d94135ad689b6413c9abaf",
            "7b26fc557a2340678218130604ce253c",
            "187cdec024e344449fc796ff02ed6d7e",
            "75d3f3a50ebd46bf80173e411fc4a354",
            "62688c6ff21a45089ef6727382ffa249",
            "a7ceb7dba3b9474eb453f355a91132d0",
            "9e9c10dd46bc4527972476c8271bab60",
            "6061dbbabc314b2baf5da15881e5b0d9",
            "16bae428ed7d4544859685acbaeb2d24",
            "4f1d333bd043497bb24533c953411b8f",
            "4a89f902449144c99e511dc0ad9be9fc",
            "ed2aa2c4616f43bca8876053e8e48e0e"
          ]
        },
        "id": "bDtVvLod3QKk",
        "outputId": "5f7b7b3f-3676-4125-c324-71ccade0f349"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name        | Type               | Params | Mode \n",
            "-----------------------------------------------------------\n",
            "0 | embedding   | Linear             | 2.0 K  | train\n",
            "1 | transformer | TransformerEncoder | 1.2 M  | train\n",
            "2 | class_head  | Linear             | 1.9 K  | train\n",
            "3 | alloc_head  | Linear             | 645    | train\n",
            "-----------------------------------------------------------\n",
            "1.2 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.2 M     Total params\n",
            "4.763     Total estimated model params size (MB)\n",
            "25        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c623da5397d4d1e92253f717bd9b688"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c5f3e9fc0144f2db1d73cf1a02ad4ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d4f061b00694486b4791c0b42cc1167"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "731dc9e78dbc48ad90793a135c612600"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de6995a61e184166936a7f848bf690ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fad0c6f3c19141b1b31bae9173e5dd23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38467aa64dc742a6af97c4effc388d0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dde1b916f414c2480eb3071cab17c2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36d04b9bce3f4c2798476b2ca0086643"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b26fc557a2340678218130604ce253c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharpe Ratio: 0.0121\n",
            "Cohen's Kappa: 0.0066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    model = MatrixModel(\n",
        "        config,\n",
        "        input_size=num_features_x1 + num_features_x2,\n",
        "        num_securities=num_securities\n",
        "    )\n",
        "\n",
        "    sharpe, kappa = train_and_evaluate(\n",
        "        model,\n",
        "        train_dataset,\n",
        "        test_dataset,\n",
        "        config\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647,
          "referenced_widgets": [
            "1a8a0ab276e24f5a89b8bf7cc738253a",
            "28643e66b7a7442eb1d0f0164de4b0f8",
            "21af0967a93f499294e20fccf962d155",
            "fda709f35eb546569c2b31bda78f08d9",
            "be8fed3767cb451d9741117c4c340530",
            "845a3719924947c38cdda9a33ec2f051",
            "3b4b39e11a96473693bcdb254f7b40dc",
            "c5033f3c8658422387218c3c800e29d5",
            "03fb0033c4734935b280d07f9040bd12",
            "1d2ce11f0f2244c7808193759296a61f",
            "dc3e36377322404d9ec8dfba8ccf3a4f"
          ]
        },
        "id": "ZWfV6Fpm3-a6",
        "outputId": "2c13e6a0-a3ca-475c-8d66-c349d943d73c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name         | Type | Params | Mode\n",
            "---------------------------------------------\n",
            "  | other params | n/a  | 65     | n/a \n",
            "---------------------------------------------\n",
            "65        Trainable params\n",
            "0         Non-trainable params\n",
            "65        Total params\n",
            "0.000     Total estimated model params size (MB)\n",
            "0         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a8a0ab276e24f5a89b8bf7cc738253a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (1x5 and 64x300)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-90798acb53b9>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m sharpe, kappa = train_and_evaluate(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-e59636338fa8>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, train_dataset, test_dataset, config)\u001b[0m\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         )\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;31m# run step hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0;31m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         )\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstep_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_redirection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-e59636338fa8>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_alloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mclass_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malloc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         class_loss = F.cross_entropy(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-e59636338fa8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    138\u001b[0m         x = torch.cat([x1.view(x1.size(0), -1), \n\u001b[1;32m    139\u001b[0m                       x2.view(x2.size(0), -1)], dim=1)\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mclass_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0malloc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB_alloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclass_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malloc_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x5 and 64x300)"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrynMv2DesCwSi/J8ntJR4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c623da5397d4d1e92253f717bd9b688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1cd538ca7ae4bb599a2898dfbf7b08c",
              "IPY_MODEL_b417fa22a6eb47a4b8fdc8490d1a71b6",
              "IPY_MODEL_eb5e580b4784416cbf6e698545cad529"
            ],
            "layout": "IPY_MODEL_67c644b6cae7453a87cc04676da56a4b"
          }
        },
        "a1cd538ca7ae4bb599a2898dfbf7b08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb606b618d8649e48849874f93468b84",
            "placeholder": "​",
            "style": "IPY_MODEL_ad937243d72e4463ae793de486a6df59",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "b417fa22a6eb47a4b8fdc8490d1a71b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81143868f6d049e2b1d8187dc306f92e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61f2c7b02e8a4f1dba79da171d55f15f",
            "value": 2
          }
        },
        "eb5e580b4784416cbf6e698545cad529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fcec5d2e4cf4f25a7ba025c4d817c29",
            "placeholder": "​",
            "style": "IPY_MODEL_52e12cb482c54a97a03750aa013a2328",
            "value": " 2/2 [00:00&lt;00:00,  5.02it/s]"
          }
        },
        "67c644b6cae7453a87cc04676da56a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "cb606b618d8649e48849874f93468b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad937243d72e4463ae793de486a6df59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81143868f6d049e2b1d8187dc306f92e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f2c7b02e8a4f1dba79da171d55f15f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fcec5d2e4cf4f25a7ba025c4d817c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e12cb482c54a97a03750aa013a2328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c5f3e9fc0144f2db1d73cf1a02ad4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36d9d5064dce4aa7b3c777662af628ed",
              "IPY_MODEL_ada9f712358e4ab48e61c1f522c64f0c",
              "IPY_MODEL_c211278507ca4536ae4a72deb30c0420"
            ],
            "layout": "IPY_MODEL_e4f6ce14e27347a8a4e5e382bf946c74"
          }
        },
        "36d9d5064dce4aa7b3c777662af628ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86adcf7eb21d466c82e8337fa009073b",
            "placeholder": "​",
            "style": "IPY_MODEL_7b30baefc3d04ec296f6958f59b650f6",
            "value": "Epoch 7: 100%"
          }
        },
        "ada9f712358e4ab48e61c1f522c64f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c88507be1d9249239602167fa118c93e",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_980b254ee86d450a9bfb978b271b61db",
            "value": 13
          }
        },
        "c211278507ca4536ae4a72deb30c0420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b46b1578284f4c82878eeaec67542a3f",
            "placeholder": "​",
            "style": "IPY_MODEL_cd500e9f6baa4884a6754d00e1589206",
            "value": " 13/13 [00:05&lt;00:00,  2.44it/s, v_num=0]"
          }
        },
        "e4f6ce14e27347a8a4e5e382bf946c74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "86adcf7eb21d466c82e8337fa009073b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b30baefc3d04ec296f6958f59b650f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c88507be1d9249239602167fa118c93e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980b254ee86d450a9bfb978b271b61db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b46b1578284f4c82878eeaec67542a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd500e9f6baa4884a6754d00e1589206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d4f061b00694486b4791c0b42cc1167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ccc8eddec4244e5bdffec03961b7dc2",
              "IPY_MODEL_92677997b7ba4d70ab7dcf605148e026",
              "IPY_MODEL_a716e342b0004a5f88c4454e1f689f0f"
            ],
            "layout": "IPY_MODEL_4a8b311f348f4f2c8754c078f5fa685b"
          }
        },
        "7ccc8eddec4244e5bdffec03961b7dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe142ac5d9404851bfa1bb823fffde3a",
            "placeholder": "​",
            "style": "IPY_MODEL_c03fb217129240b4a3559a68f9c37755",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "92677997b7ba4d70ab7dcf605148e026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c481a567ed4f4aa62b9933df015346",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_976697817c404f668072fd9653379410",
            "value": 4
          }
        },
        "a716e342b0004a5f88c4454e1f689f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_240533edc3d24228b9c82669f343be8a",
            "placeholder": "​",
            "style": "IPY_MODEL_5a81e5da6547485fa5e45f51a5776278",
            "value": " 4/4 [00:00&lt;00:00, 11.21it/s]"
          }
        },
        "4a8b311f348f4f2c8754c078f5fa685b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "fe142ac5d9404851bfa1bb823fffde3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c03fb217129240b4a3559a68f9c37755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4c481a567ed4f4aa62b9933df015346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "976697817c404f668072fd9653379410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "240533edc3d24228b9c82669f343be8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a81e5da6547485fa5e45f51a5776278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "731dc9e78dbc48ad90793a135c612600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42b01062f563474fa42a30b0501ba0d8",
              "IPY_MODEL_09c6ded36d8549068f77b5fc53340bc5",
              "IPY_MODEL_b0f7ef73dc5043058ae2d717a44c565f"
            ],
            "layout": "IPY_MODEL_f98b3b78bebe4cdd9ac248a933c044c9"
          }
        },
        "42b01062f563474fa42a30b0501ba0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46cb21c196fb489da13a17ac2d136e92",
            "placeholder": "​",
            "style": "IPY_MODEL_f2517b31bc514ccdb72dfaefa76004e8",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "09c6ded36d8549068f77b5fc53340bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5706001789af439db3f8616f39976753",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1f6f3726d514c9ebbb503db7bfd5d51",
            "value": 4
          }
        },
        "b0f7ef73dc5043058ae2d717a44c565f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe9fc7932a99402794ef93a403c7ca2c",
            "placeholder": "​",
            "style": "IPY_MODEL_fbcdc141855d42198f485df6a011bbaf",
            "value": " 4/4 [00:00&lt;00:00, 12.61it/s]"
          }
        },
        "f98b3b78bebe4cdd9ac248a933c044c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "46cb21c196fb489da13a17ac2d136e92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2517b31bc514ccdb72dfaefa76004e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5706001789af439db3f8616f39976753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1f6f3726d514c9ebbb503db7bfd5d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe9fc7932a99402794ef93a403c7ca2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbcdc141855d42198f485df6a011bbaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de6995a61e184166936a7f848bf690ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_557ea6fafe1d4f90ad659506b04e4355",
              "IPY_MODEL_8d416405b1d947f4bee5c0a349717d2c",
              "IPY_MODEL_05582b564d9e43b1b9af223c0b264d35"
            ],
            "layout": "IPY_MODEL_067b6587679542c199356b5f8d272f19"
          }
        },
        "557ea6fafe1d4f90ad659506b04e4355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4dcf3b2e5d3498e8ae29de6ac4d685e",
            "placeholder": "​",
            "style": "IPY_MODEL_2d310023f53f4f1a935a8a91b1857c18",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "8d416405b1d947f4bee5c0a349717d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b0b651cf5114a1ab80aad988b446fc6",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33ac45b164564522ad6e4542eacd5256",
            "value": 4
          }
        },
        "05582b564d9e43b1b9af223c0b264d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2858b2e2a8e24eeaa7651732bb2a96b3",
            "placeholder": "​",
            "style": "IPY_MODEL_4f53df645fee47fea26bec89474096d3",
            "value": " 4/4 [00:00&lt;00:00,  8.14it/s]"
          }
        },
        "067b6587679542c199356b5f8d272f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "b4dcf3b2e5d3498e8ae29de6ac4d685e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d310023f53f4f1a935a8a91b1857c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b0b651cf5114a1ab80aad988b446fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ac45b164564522ad6e4542eacd5256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2858b2e2a8e24eeaa7651732bb2a96b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f53df645fee47fea26bec89474096d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fad0c6f3c19141b1b31bae9173e5dd23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4510fb8a65cd41a798901d8bb27749e9",
              "IPY_MODEL_bf1720921b294c39986bd01490a9ec89",
              "IPY_MODEL_45c03d76f47748fab7a52994cb494d11"
            ],
            "layout": "IPY_MODEL_f804ac4488ed40c8be8e7a3008f0e4be"
          }
        },
        "4510fb8a65cd41a798901d8bb27749e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c40c2f7c18d448e19e9dbe7622299307",
            "placeholder": "​",
            "style": "IPY_MODEL_b7f1a724a16e491d9393cc5f3780fdfd",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "bf1720921b294c39986bd01490a9ec89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7999e459482c46a99dcc60c88e95c916",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2f02120dc264b6a9fd119307de402ce",
            "value": 4
          }
        },
        "45c03d76f47748fab7a52994cb494d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f384523feb45ffbfd7e0e502612654",
            "placeholder": "​",
            "style": "IPY_MODEL_b80a8958e81648aba746fb9c9eb58b2e",
            "value": " 4/4 [00:00&lt;00:00, 10.12it/s]"
          }
        },
        "f804ac4488ed40c8be8e7a3008f0e4be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "c40c2f7c18d448e19e9dbe7622299307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7f1a724a16e491d9393cc5f3780fdfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7999e459482c46a99dcc60c88e95c916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2f02120dc264b6a9fd119307de402ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98f384523feb45ffbfd7e0e502612654": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b80a8958e81648aba746fb9c9eb58b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38467aa64dc742a6af97c4effc388d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7644515d2c14671ae08df2210405f90",
              "IPY_MODEL_c58c3cb647fe48a9bba1ab25cb6c08a4",
              "IPY_MODEL_92121391d7d440f997c04d90159e329c"
            ],
            "layout": "IPY_MODEL_31254012a5a34cb0be4ee190e590546d"
          }
        },
        "e7644515d2c14671ae08df2210405f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe4ca4526ca74349a07f3e79147f7185",
            "placeholder": "​",
            "style": "IPY_MODEL_f0d0e19fafdc45318c8a7611ec7155b0",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "c58c3cb647fe48a9bba1ab25cb6c08a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a872536867ca418baf5fdb1a91500105",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb901a803b694e3194f8a77e1ee401c0",
            "value": 4
          }
        },
        "92121391d7d440f997c04d90159e329c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_266d1d551509467e91e94925684ab5ff",
            "placeholder": "​",
            "style": "IPY_MODEL_97693fd92a0d498f9ffff6db328960c7",
            "value": " 4/4 [00:00&lt;00:00, 13.25it/s]"
          }
        },
        "31254012a5a34cb0be4ee190e590546d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "fe4ca4526ca74349a07f3e79147f7185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0d0e19fafdc45318c8a7611ec7155b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a872536867ca418baf5fdb1a91500105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb901a803b694e3194f8a77e1ee401c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "266d1d551509467e91e94925684ab5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97693fd92a0d498f9ffff6db328960c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dde1b916f414c2480eb3071cab17c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9999a3caa2a14452bee7088dddd7de91",
              "IPY_MODEL_60f6fce1b50d42f5bbad7960b1651dad",
              "IPY_MODEL_bceadfc4d2784685a648b543a507cde6"
            ],
            "layout": "IPY_MODEL_973faa901dec4173857288b8dbf07b6f"
          }
        },
        "9999a3caa2a14452bee7088dddd7de91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb1a7f0130c49f19f42c47632435442",
            "placeholder": "​",
            "style": "IPY_MODEL_a1b94d72544448c398538f1ca2927b33",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "60f6fce1b50d42f5bbad7960b1651dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e38760fa373140ca9517aadfab9f05bd",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b9f99d99db24ee2ba20a35a18878422",
            "value": 4
          }
        },
        "bceadfc4d2784685a648b543a507cde6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88d7f25d3a634639b9dd77b5101a3d85",
            "placeholder": "​",
            "style": "IPY_MODEL_4f2757ad322745a7b6c23b0e9ea6a7ac",
            "value": " 4/4 [00:00&lt;00:00, 11.80it/s]"
          }
        },
        "973faa901dec4173857288b8dbf07b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "0bb1a7f0130c49f19f42c47632435442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1b94d72544448c398538f1ca2927b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e38760fa373140ca9517aadfab9f05bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b9f99d99db24ee2ba20a35a18878422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88d7f25d3a634639b9dd77b5101a3d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2757ad322745a7b6c23b0e9ea6a7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36d04b9bce3f4c2798476b2ca0086643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd35bdb8af87453689b229bcda35b082",
              "IPY_MODEL_0b6dbeb3fc3440ac82e56893e2213b69",
              "IPY_MODEL_f558413902054b8fa362e51caaf24ed8"
            ],
            "layout": "IPY_MODEL_46b036d694dc47019c50fe1164648a55"
          }
        },
        "fd35bdb8af87453689b229bcda35b082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1f03f5487c3456f93d4fcea9a58e336",
            "placeholder": "​",
            "style": "IPY_MODEL_d54dceba635c40d5b921da53057b1e25",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "0b6dbeb3fc3440ac82e56893e2213b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9af43ec91483484da1fbd4652bb8d676",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1d81685995040cdaea4d04f3fc6975b",
            "value": 4
          }
        },
        "f558413902054b8fa362e51caaf24ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7b99878ff7c459292e1e7cd83f3db14",
            "placeholder": "​",
            "style": "IPY_MODEL_ab59be30b8d94135ad689b6413c9abaf",
            "value": " 4/4 [00:00&lt;00:00, 11.62it/s]"
          }
        },
        "46b036d694dc47019c50fe1164648a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "a1f03f5487c3456f93d4fcea9a58e336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d54dceba635c40d5b921da53057b1e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9af43ec91483484da1fbd4652bb8d676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d81685995040cdaea4d04f3fc6975b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7b99878ff7c459292e1e7cd83f3db14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab59be30b8d94135ad689b6413c9abaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b26fc557a2340678218130604ce253c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_187cdec024e344449fc796ff02ed6d7e",
              "IPY_MODEL_75d3f3a50ebd46bf80173e411fc4a354",
              "IPY_MODEL_62688c6ff21a45089ef6727382ffa249"
            ],
            "layout": "IPY_MODEL_a7ceb7dba3b9474eb453f355a91132d0"
          }
        },
        "187cdec024e344449fc796ff02ed6d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9c10dd46bc4527972476c8271bab60",
            "placeholder": "​",
            "style": "IPY_MODEL_6061dbbabc314b2baf5da15881e5b0d9",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "75d3f3a50ebd46bf80173e411fc4a354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16bae428ed7d4544859685acbaeb2d24",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f1d333bd043497bb24533c953411b8f",
            "value": 4
          }
        },
        "62688c6ff21a45089ef6727382ffa249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a89f902449144c99e511dc0ad9be9fc",
            "placeholder": "​",
            "style": "IPY_MODEL_ed2aa2c4616f43bca8876053e8e48e0e",
            "value": " 4/4 [00:00&lt;00:00, 12.42it/s]"
          }
        },
        "a7ceb7dba3b9474eb453f355a91132d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "9e9c10dd46bc4527972476c8271bab60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6061dbbabc314b2baf5da15881e5b0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16bae428ed7d4544859685acbaeb2d24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f1d333bd043497bb24533c953411b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a89f902449144c99e511dc0ad9be9fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed2aa2c4616f43bca8876053e8e48e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a8a0ab276e24f5a89b8bf7cc738253a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28643e66b7a7442eb1d0f0164de4b0f8",
              "IPY_MODEL_21af0967a93f499294e20fccf962d155",
              "IPY_MODEL_fda709f35eb546569c2b31bda78f08d9"
            ],
            "layout": "IPY_MODEL_be8fed3767cb451d9741117c4c340530"
          }
        },
        "28643e66b7a7442eb1d0f0164de4b0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_845a3719924947c38cdda9a33ec2f051",
            "placeholder": "​",
            "style": "IPY_MODEL_3b4b39e11a96473693bcdb254f7b40dc",
            "value": "Sanity Checking DataLoader 0:   0%"
          }
        },
        "21af0967a93f499294e20fccf962d155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5033f3c8658422387218c3c800e29d5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03fb0033c4734935b280d07f9040bd12",
            "value": 0
          }
        },
        "fda709f35eb546569c2b31bda78f08d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d2ce11f0f2244c7808193759296a61f",
            "placeholder": "​",
            "style": "IPY_MODEL_dc3e36377322404d9ec8dfba8ccf3a4f",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "be8fed3767cb451d9741117c4c340530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "845a3719924947c38cdda9a33ec2f051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b4b39e11a96473693bcdb254f7b40dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5033f3c8658422387218c3c800e29d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03fb0033c4734935b280d07f9040bd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d2ce11f0f2244c7808193759296a61f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc3e36377322404d9ec8dfba8ccf3a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}