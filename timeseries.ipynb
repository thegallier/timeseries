{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUtuo2uQA5otqInUnrvFAR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thegallier/timeseries/blob/main/timeseries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from itertools import product\n",
        "import time\n",
        "\n",
        "# Parameters\n",
        "num_timesteps = 5000  # Reduced for practical purposes\n",
        "num_securities = 10\n",
        "num_features_per_security = 4\n",
        "num_classes = 3\n",
        "num_features = num_securities * num_features_per_security\n",
        "\n",
        "# Generate timestamps\n",
        "timestamps = np.arange(num_timesteps)\n",
        "\n",
        "# Generate random data for the primary dataset\n",
        "X_data = np.random.rand(num_timesteps, num_features).astype(np.float32)\n",
        "y_data = np.random.randint(0, num_classes, size=(num_timesteps, num_securities)).astype(np.int64)\n",
        "\n",
        "# Generate the second dataset\n",
        "# 3 strings and 2 floats per timestamp\n",
        "str_columns = ['str1', 'str2', 'str3']\n",
        "float_columns = ['float1', 'float2']\n",
        "second_dataset = {\n",
        "    'timestamp': timestamps,\n",
        "    'str1': np.random.choice(['A', 'B', 'C'], num_timesteps),\n",
        "    'str2': np.random.choice(['D', 'E', 'F'], num_timesteps),\n",
        "    'str3': np.random.choice(['G', 'H', 'I'], num_timesteps),\n",
        "    'float1': np.random.rand(num_timesteps),\n",
        "    'float2': np.random.rand(num_timesteps),\n",
        "}\n",
        "\n",
        "# Encode string columns\n",
        "label_encoders = {}\n",
        "for col in str_columns:\n",
        "    le = LabelEncoder()\n",
        "    second_dataset[col] = le.fit_transform(second_dataset[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Combine all features from the second dataset\n",
        "second_X_data = np.column_stack([second_dataset[col] for col in str_columns + float_columns]).astype(np.float32)\n",
        "\n",
        "# Min-max scaling for both datasets\n",
        "scaler_X = MinMaxScaler()\n",
        "X_data = scaler_X.fit_transform(X_data)\n",
        "\n",
        "scaler_second_X = MinMaxScaler()\n",
        "second_X_data = scaler_second_X.fit_transform(second_X_data)\n",
        "\n",
        "def add_positional_encoding(X, timestamps, option='shared'):\n",
        "    \"\"\"\n",
        "    Add positional encoding to the feature matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - X: Feature matrix.\n",
        "    - timestamps: Array of timestamps.\n",
        "    - option: 'shared' or 'per_security'.\n",
        "\n",
        "    Returns:\n",
        "    - X with positional encoding added.\n",
        "    \"\"\"\n",
        "    if option == 'shared':\n",
        "        pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(X.shape[1]) / X.shape[1]))\n",
        "        X_pe = X + pe.astype(np.float32)\n",
        "    elif option == 'per_security':\n",
        "        pe_list = []\n",
        "        for i in range(num_securities):\n",
        "            pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(num_features_per_security) / num_features_per_security))\n",
        "            pe_list.append(pe)\n",
        "        pe_concat = np.hstack(pe_list)\n",
        "        X_pe = X + pe_concat.astype(np.float32)\n",
        "    else:\n",
        "        X_pe = X  # No positional encoding\n",
        "    return X_pe\n",
        "\n",
        "# Apply positional encoding\n",
        "positional_encoding_option = 'shared'  # 'shared' or 'per_security'\n",
        "X_data = add_positional_encoding(X_data, timestamps, positional_encoding_option)\n",
        "\n",
        "def create_windows(X1, X2, y, window_size, horizon):\n",
        "    \"\"\"\n",
        "    Create sliding windows for time series data.\n",
        "\n",
        "    Parameters:\n",
        "    - X1: Primary dataset features.\n",
        "    - X2: Secondary dataset features.\n",
        "    - y: Target variable.\n",
        "    - window_size: Size of the window.\n",
        "    - horizon: Prediction horizon.\n",
        "\n",
        "    Returns:\n",
        "    - Tuples of windows for X1, X2, and y.\n",
        "    \"\"\"\n",
        "    X1_windows = []\n",
        "    X2_windows = []\n",
        "    y_windows = []\n",
        "    for i in range(len(X1) - window_size - horizon + 1):\n",
        "        X1_windows.append(X1[i:i+window_size])\n",
        "        X2_windows.append(X2[i:i+window_size])\n",
        "        y_windows.append(y[i+window_size+horizon-1])\n",
        "    return np.array(X1_windows), np.array(X2_windows), np.array(y_windows)\n",
        "\n",
        "# Define window sizes\n",
        "window_size = 20\n",
        "horizon = 1\n",
        "\n",
        "# Create windows\n",
        "X1_windows, X2_windows, y_windows = create_windows(X_data, second_X_data, y_data, window_size, horizon)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(X1_windows) * train_ratio)\n",
        "\n",
        "X1_train = X1_windows[:train_size]\n",
        "X2_train = X2_windows[:train_size]\n",
        "y_train = y_windows[:train_size]\n",
        "\n",
        "X1_test = X1_windows[train_size:]\n",
        "X2_test = X2_windows[train_size:]\n",
        "y_test = y_windows[train_size:]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X1_train_tensor = torch.tensor(X1_train)\n",
        "X2_train_tensor = torch.tensor(X2_train)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "\n",
        "X1_test_tensor = torch.tensor(X1_test)\n",
        "X2_test_tensor = torch.tensor(X2_test)\n",
        "y_test_tensor = torch.tensor(y_test)\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for time series data with two feature sets.\n",
        "\n",
        "    Parameters:\n",
        "    - X1: Primary dataset features.\n",
        "    - X2: Secondary dataset features.\n",
        "    - y: Target variable.\n",
        "    \"\"\"\n",
        "    def __init__(self, X1, X2, y):\n",
        "        self.X1 = X1.float()\n",
        "        self.X2 = X2.float()\n",
        "        self.y = y.long()\n",
        "    def __len__(self):\n",
        "        return len(self.X1)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X1[idx], self.X2[idx], self.y[idx]\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = TimeSeriesDataset(X1_train_tensor, X2_train_tensor, y_train_tensor)\n",
        "test_dataset = TimeSeriesDataset(X1_test_tensor, X2_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class MatrixRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, num_features):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(1, num_securities))\n",
        "        self.B = nn.Parameter(torch.randn(num_features, num_classes))\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten over time\n",
        "        out = self.A @ x @ self.B  # Shape: (batch_size, num_classes)\n",
        "        out = out.view(-1, num_securities, num_classes)\n",
        "        return out\n",
        "\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_securities, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.linear = nn.Linear(input_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.linear(x)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, window_size)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        out = x.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_securities, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures global dependencies.\n",
        "    - Parallel computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Requires large datasets.\n",
        "    - Computationally intensive.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.embedding = nn.Linear(num_features, 128)\n",
        "        self.pos_encoder = PositionalEncoding(128)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=2)\n",
        "        self.decoder = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), x.size(1), -1)  # (batch_size, window_size, num_features)\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # (sequence_length, batch_size, embedding_dim)\n",
        "        output = self.transformer_encoder(x)\n",
        "        output = output[-1, :, :]  # Last output\n",
        "        output = self.decoder(output)\n",
        "        output = output.view(-1, self.num_securities, num_classes)\n",
        "        return output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional Encoding for Transformer.\n",
        "\n",
        "    Adds positional information to the embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        if d_model % 2 == 1:\n",
        "            pe[:, 1::2] = torch.sin(position * div_term)\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(1)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return x\n",
        "\n",
        "class SimpleRNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple Recurrent Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures sequential dependencies.\n",
        "    - Simpler than LSTM.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Struggles with long-term dependencies.\n",
        "    - May suffer from vanishing gradients.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_securities, num_classes):\n",
        "        super(SimpleRNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.rnn.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined Model: Merges outputs from two models.\n",
        "\n",
        "    Advantages:\n",
        "    - Leverages multiple data sources.\n",
        "    - Potentially better performance.\n",
        "\n",
        "    Disadvantages:\n",
        "    - More complex.\n",
        "    - Computationally intensive.\n",
        "    \"\"\"\n",
        "    def __init__(self, model1, model2, num_classes, num_securities):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.model1 = model1\n",
        "        self.model2 = model2\n",
        "        self.fc = nn.Linear(num_classes * 2, num_classes)\n",
        "        self.num_securities = num_securities\n",
        "    def forward(self, x1, x2):\n",
        "        outputs1 = self.model1(x1)\n",
        "        outputs2 = self.model2(x2)\n",
        "        outputs = torch.cat((outputs1, outputs2), dim=2)\n",
        "        batch_size = outputs.size(0)\n",
        "        outputs = outputs.view(-1, outputs.size(2))\n",
        "        final_output = self.fc(outputs)\n",
        "        final_output = final_output.view(batch_size, self.num_securities, -1)\n",
        "        return final_output\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs, device, writer):\n",
        "    \"\"\"\n",
        "    Training loop for the model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The model to train.\n",
        "    - train_loader: DataLoader for training data.\n",
        "    - criterion: Loss function.\n",
        "    - optimizer: Optimizer.\n",
        "    - num_epochs: Number of epochs.\n",
        "    - device: Computation device.\n",
        "    - writer: TensorBoard SummaryWriter.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    global_step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X1_batch, X2_batch, y_batch in train_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            loss = 0\n",
        "            for i in range(num_securities):\n",
        "                loss += criterion(outputs[:, i, :], y_batch[:, i])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            writer.add_scalar('Training Loss', loss.item(), global_step)\n",
        "            global_step += 1\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "        # Save checkpoint\n",
        "        torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pth')\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test set.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The model to evaluate.\n",
        "    - test_loader: DataLoader for test data.\n",
        "    - device: Computation device.\n",
        "\n",
        "    Returns:\n",
        "    - Cohen's kappa score.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for X1_batch, X2_batch, y_batch in test_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            _, predicted = torch.max(outputs.data, 2)\n",
        "            total += y_batch.numel()\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy().flatten())\n",
        "            all_targets.extend(y_batch.cpu().numpy().flatten())\n",
        "    accuracy = 100 * correct / total\n",
        "    kappa = cohen_kappa_score(all_targets, all_preds)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
        "    print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
        "    return kappa\n",
        "\n",
        "def hyperparameter_tuning(hyperparams, train_loader, test_loader, device):\n",
        "    \"\"\"\n",
        "    Perform hyperparameter tuning.\n",
        "\n",
        "    Parameters:\n",
        "    - hyperparams: Dictionary of hyperparameters to try.\n",
        "    - train_loader: DataLoader for training data.\n",
        "    - test_loader: DataLoader for test data.\n",
        "    - device: Computation device.\n",
        "    \"\"\"\n",
        "    best_kappa = -1\n",
        "    best_params = None\n",
        "    for params in product(*hyperparams.values()):\n",
        "        param_dict = dict(zip(hyperparams.keys(), params))\n",
        "        print(f\"Trying hyperparameters: {param_dict}\")\n",
        "        model1 = TransformerModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "        model2 = LSTMModel(input_size=second_X_data.shape[1], hidden_size=param_dict['hidden_size'],\n",
        "                           num_layers=param_dict['num_layers'], num_securities=num_securities, num_classes=num_classes)\n",
        "        combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "        optimizer = torch.optim.Adam(combined_model.parameters(), lr=param_dict['learning_rate'])\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        writer = SummaryWriter()\n",
        "        train_model(combined_model, train_loader, criterion, optimizer, param_dict['num_epochs'], device, writer)\n",
        "        kappa = evaluate_model(combined_model, test_loader, device)\n",
        "        writer.close()\n",
        "        if kappa > best_kappa:\n",
        "            best_kappa = kappa\n",
        "            best_params = param_dict\n",
        "    print(f\"Best Cohen's Kappa: {best_kappa:.4f} with parameters: {best_params}\")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters for tuning\n",
        "hyperparams = {\n",
        "    'hidden_size': [64, 128],\n",
        "    'num_layers': [1, 2],\n",
        "    'learning_rate': [0.001, 0.0001],\n",
        "    'num_epochs': [5]\n",
        "}\n",
        "\n",
        "# Start hyperparameter tuning\n",
        "hyperparameter_tuning(hyperparams, train_loader, test_loader, device)\n",
        "\n",
        "model = LSTMModel(input_size=num_features, hidden_size=128, num_layers=2, num_securities=num_securities, num_classes=num_classes)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "\n",
        "evaluate_model(model, test_loader, device)\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "ZsbxjP02ubWt",
        "outputId": "08ab86d7-ef53-47f5-f082-53dce48c1991"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying hyperparameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.001, 'num_epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'TransformerModel' object has no attribute 'num_securities'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e6422f7a8e77>\u001b[0m in \u001b[0;36m<cell line: 483>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;31m# Start hyperparameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m \u001b[0mhyperparameter_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_securities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_securities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-e6422f7a8e77>\u001b[0m in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(hyperparams, train_loader, test_loader, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0mkappa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-e6422f7a8e77>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, device, writer)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_securities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-e6422f7a8e77>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_securities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_securities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0moutputs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0moutputs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-e6422f7a8e77>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Last output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_securities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1729\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TransformerModel' object has no attribute 'num_securities'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from itertools import product\n",
        "import time\n",
        "\n",
        "# Parameters\n",
        "num_timesteps = 5000  # Reduced for practical purposes\n",
        "num_securities = 10  # Number of different securities\n",
        "num_features_per_security = 4  # Features per security\n",
        "num_classes = 3  # Number of target classes\n",
        "num_features = num_securities * num_features_per_security  # Total number of features\n",
        "\n",
        "# Generate timestamps\n",
        "timestamps = np.arange(num_timesteps)\n",
        "\n",
        "# Generate random data for the primary dataset (X_data) and labels (y_data)\n",
        "X_data = np.random.rand(num_timesteps, num_features).astype(np.float32)  # Random features\n",
        "y_data = np.random.randint(0, num_classes, size=(num_timesteps, num_securities)).astype(np.int64)  # Random labels\n",
        "\n",
        "# Generate the second dataset with 3 categorical strings and 2 continuous floats per timestamp\n",
        "str_columns = ['str1', 'str2', 'str3']\n",
        "float_columns = ['float1', 'float2']\n",
        "second_dataset = {\n",
        "    'timestamp': timestamps,\n",
        "    'str1': np.random.choice(['A', 'B', 'C'], num_timesteps),\n",
        "    'str2': np.random.choice(['D', 'E', 'F'], num_timesteps),\n",
        "    'str3': np.random.choice(['G', 'H', 'I'], num_timesteps),\n",
        "    'float1': np.random.rand(num_timesteps),\n",
        "    'float2': np.random.rand(num_timesteps),\n",
        "}\n",
        "\n",
        "# Encode categorical string columns using LabelEncoder\n",
        "label_encoders = {}\n",
        "for col in str_columns:\n",
        "    le = LabelEncoder()\n",
        "    second_dataset[col] = le.fit_transform(second_dataset[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Combine all features from the second dataset into a single array\n",
        "second_X_data = np.column_stack([second_dataset[col] for col in str_columns + float_columns]).astype(np.float32)\n",
        "\n",
        "# Apply Min-Max scaling to both datasets\n",
        "scaler_X = MinMaxScaler()\n",
        "X_data = scaler_X.fit_transform(X_data)\n",
        "\n",
        "scaler_second_X = MinMaxScaler()\n",
        "second_X_data = scaler_second_X.fit_transform(second_X_data)\n",
        "\n",
        "def add_positional_encoding(X, timestamps, option='shared'):\n",
        "    \"\"\"\n",
        "    Add positional encoding to the feature matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - X (ndarray): Feature matrix.\n",
        "    - timestamps (ndarray): Array of timestamps.\n",
        "    - option (str): 'shared' or 'per_security'.\n",
        "\n",
        "    Returns:\n",
        "    - X_pe (ndarray): X with positional encoding added.\n",
        "    \"\"\"\n",
        "    if option == 'shared':\n",
        "        # Shared positional encoding across all features\n",
        "        pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(X.shape[1]) / X.shape[1]))\n",
        "        X_pe = X + pe.astype(np.float32)\n",
        "    elif option == 'per_security':\n",
        "        # Separate positional encoding for each security\n",
        "        pe_list = []\n",
        "        for i in range(num_securities):\n",
        "            pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(num_features_per_security) / num_features_per_security))\n",
        "            pe_list.append(pe)\n",
        "        pe_concat = np.hstack(pe_list)\n",
        "        X_pe = X + pe_concat.astype(np.float32)\n",
        "    else:\n",
        "        X_pe = X  # No positional encoding\n",
        "    return X_pe\n",
        "\n",
        "# Apply positional encoding\n",
        "positional_encoding_option = 'shared'  # 'shared' or 'per_security'\n",
        "X_data = add_positional_encoding(X_data, timestamps, positional_encoding_option)\n",
        "\n",
        "def create_windows(X1, X2, y, window_size, horizon):\n",
        "    \"\"\"\n",
        "    Create sliding windows for time series data.\n",
        "\n",
        "    Parameters:\n",
        "    - X1 (ndarray): Primary dataset features.\n",
        "    - X2 (ndarray): Secondary dataset features.\n",
        "    - y (ndarray): Target variable.\n",
        "    - window_size (int): Size of the window.\n",
        "    - horizon (int): Prediction horizon.\n",
        "\n",
        "    Returns:\n",
        "    - Tuple[np.ndarray, np.ndarray, np.ndarray]: Tuples of windows for X1, X2, and y.\n",
        "    \"\"\"\n",
        "    X1_windows = []\n",
        "    X2_windows = []\n",
        "    y_windows = []\n",
        "    for i in range(len(X1) - window_size - horizon + 1):\n",
        "        X1_windows.append(X1[i:i+window_size])\n",
        "        X2_windows.append(X2[i:i+window_size])\n",
        "        y_windows.append(y[i+window_size+horizon-1])\n",
        "    return np.array(X1_windows), np.array(X2_windows), np.array(y_windows)\n",
        "\n",
        "# Define window sizes\n",
        "window_size = 20\n",
        "horizon = 1\n",
        "\n",
        "# Create windows\n",
        "X1_windows, X2_windows, y_windows = create_windows(X_data, second_X_data, y_data, window_size, horizon)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(X1_windows) * train_ratio)\n",
        "\n",
        "X1_train = X1_windows[:train_size]\n",
        "X2_train = X2_windows[:train_size]\n",
        "y_train = y_windows[:train_size]\n",
        "\n",
        "X1_test = X1_windows[train_size:]\n",
        "X2_test = X2_windows[train_size:]\n",
        "y_test = y_windows[train_size:]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X1_train_tensor = torch.tensor(X1_train)\n",
        "X2_train_tensor = torch.tensor(X2_train)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "\n",
        "X1_test_tensor = torch.tensor(X1_test)\n",
        "X2_test_tensor = torch.tensor(X2_test)\n",
        "y_test_tensor = torch.tensor(y_test)\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for time series data with two feature sets.\n",
        "\n",
        "    Parameters:\n",
        "    - X1 (torch.Tensor): Primary dataset features.\n",
        "    - X2 (torch.Tensor): Secondary dataset features.\n",
        "    - y (torch.Tensor): Target variable.\n",
        "    \"\"\"\n",
        "    def __init__(self, X1, X2, y):\n",
        "        self.X1 = X1.float()\n",
        "        self.X2 = X2.float()\n",
        "        self.y = y.long()\n",
        "    def __len__(self):\n",
        "        return len(self.X1)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X1[idx], self.X2[idx], self.y[idx]\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = TimeSeriesDataset(X1_train_tensor, X2_train_tensor, y_train_tensor)\n",
        "test_dataset = TimeSeriesDataset(X1_test_tensor, X2_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class MatrixRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, num_features):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(1, num_securities))\n",
        "        self.B = nn.Parameter(torch.randn(num_features, num_classes))\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten over time\n",
        "        out = self.A @ x @ self.B  # Shape: (batch_size, num_classes)\n",
        "        out = out.view(-1, num_securities, num_classes)\n",
        "        return out\n",
        "\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_securities, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.linear = nn.Linear(input_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.linear(x)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, window_size)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        out = x.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_securities, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures global dependencies.\n",
        "    - Parallel computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Requires large datasets.\n",
        "    - Computationally intensive.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.embedding = nn.Linear(num_features, 128)\n",
        "        self.pos_encoder = PositionalEncoding(128)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=2)\n",
        "        self.decoder = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), x.size(1), -1)  # (batch_size, window_size, num_features)\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # (sequence_length, batch_size, embedding_dim)\n",
        "        output = self.transformer_encoder(x)\n",
        "        output = output[-1, :, :]  # Last output\n",
        "        output = self.decoder(output)\n",
        "        output = output.view(-1, self.num_securities, self.num_classes)\n",
        "        return output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional Encoding for Transformer.\n",
        "\n",
        "    Adds positional information to the embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        if d_model % 2 == 1:\n",
        "            pe[:, 1::2] = torch.sin(position * div_term)\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(1)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return x\n",
        "\n",
        "class SimpleRNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple Recurrent Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures sequential dependencies.\n",
        "    - Simpler than LSTM.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Struggles with long-term dependencies.\n",
        "    - May suffer from vanishing gradients.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_securities, num_classes):\n",
        "        super(SimpleRNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.rnn.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined Model: Merges outputs from two models.\n",
        "\n",
        "    Advantages:\n",
        "    - Leverages multiple data sources.\n",
        "    - Potentially better performance.\n",
        "\n",
        "    Disadvantages:\n",
        "    - More complex.\n",
        "    - Computationally intensive.\n",
        "    \"\"\"\n",
        "    def __init__(self, model1, model2, num_classes, num_securities):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.model1 = model1\n",
        "        self.model2 = model2\n",
        "        self.fc = nn.Linear(num_classes * 2, num_classes)\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "    def forward(self, x1, x2):\n",
        "        outputs1 = self.model1(x1)\n",
        "        outputs2 = self.model2(x2)\n",
        "        outputs = torch.cat((outputs1, outputs2), dim=2)\n",
        "        batch_size = outputs.size(0)\n",
        "        outputs = outputs.view(-1, outputs.size(2))\n",
        "        final_output = self.fc(outputs)\n",
        "        final_output = final_output.view(batch_size, self.num_securities, -1)\n",
        "        return final_output\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs, device, writer):\n",
        "    \"\"\"\n",
        "    Training loop for the model.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to train.\n",
        "    - train_loader (DataLoader): DataLoader for training data.\n",
        "    - criterion (nn.Module): Loss function.\n",
        "    - optimizer (torch.optim.Optimizer): Optimizer.\n",
        "    - num_epochs (int): Number of epochs.\n",
        "    - device (torch.device): Computation device.\n",
        "    - writer (SummaryWriter): TensorBoard SummaryWriter.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    global_step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X1_batch, X2_batch, y_batch in train_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            loss = 0\n",
        "            for i in range(num_securities):\n",
        "                loss += criterion(outputs[:, i, :], y_batch[:, i])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            writer.add_scalar('Training Loss', loss.item(), global_step)\n",
        "            global_step += 1\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "        # Save checkpoint\n",
        "        torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pth')\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test set.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to evaluate.\n",
        "    - test_loader (DataLoader): DataLoader for test data.\n",
        "    - device (torch.device): Computation device.\n",
        "\n",
        "    Returns:\n",
        "    - float: Cohen's kappa score.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for X1_batch, X2_batch, y_batch in test_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            _, predicted = torch.max(outputs.data, 2)\n",
        "            total += y_batch.numel()\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy().flatten())\n",
        "            all_targets.extend(y_batch.cpu().numpy().flatten())\n",
        "    accuracy = 100 * correct / total\n",
        "    kappa = cohen_kappa_score(all_targets, all_preds)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
        "    print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
        "    return kappa\n",
        "\n",
        "def hyperparameter_tuning(hyperparams, train_loader, test_loader, device):\n",
        "    \"\"\"\n",
        "    Perform hyperparameter tuning.\n",
        "\n",
        "    Parameters:\n",
        "    - hyperparams (dict): Dictionary of hyperparameters to try.\n",
        "    - train_loader (DataLoader): DataLoader for training data.\n",
        "    - test_loader (DataLoader): DataLoader for test data.\n",
        "    - device (torch.device): Computation device.\n",
        "    \"\"\"\n",
        "    best_kappa = -1\n",
        "    best_params = None\n",
        "    for params in product(*hyperparams.values()):\n",
        "        param_dict = dict(zip(hyperparams.keys(), params))\n",
        "        print(f\"Trying hyperparameters: {param_dict}\")\n",
        "        model1 = TransformerModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "        model2 = LSTMModel(input_size=second_X_data.shape[1], hidden_size=param_dict['hidden_size'],\n",
        "                           num_layers=param_dict['num_layers'], num_securities=num_securities, num_classes=num_classes)\n",
        "        combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "        optimizer = torch.optim.Adam(combined_model.parameters(), lr=param_dict['learning_rate'])\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        writer = SummaryWriter()\n",
        "        train_model(combined_model, train_loader, criterion, optimizer, param_dict['num_epochs'], device, writer)\n",
        "        kappa = evaluate_model(combined_model, test_loader, device)\n",
        "        writer.close()\n",
        "        if kappa > best_kappa:\n",
        "            best_kappa = kappa\n",
        "            best_params = param_dict\n",
        "    print(f\"Best Cohen's Kappa: {best_kappa:.4f} with parameters: {best_params}\")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters for tuning\n",
        "hyperparams = {\n",
        "    'hidden_size': [64, 128],\n",
        "    'num_layers': [1, 2],\n",
        "    'learning_rate': [0.001, 0.0001],\n",
        "    'num_epochs': [5]\n",
        "}\n",
        "\n",
        "# Start hyperparameter tuning\n",
        "hyperparameter_tuning(hyperparams, train_loader, test_loader, device)\n",
        "\n",
        "# Example 1: Combine TransformerModel and LSTMModel\n",
        "print(\"\\nTraining Combined Model 1: TransformerModel + LSTMModel\")\n",
        "model1 = TransformerModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = LSTMModel(input_size=second_X_data.shape[1], hidden_size=128, num_layers=2, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 2: Combine CNNModel and SimpleRNNModel\n",
        "print(\"\\nTraining Combined Model 2: CNNModel + SimpleRNNModel\")\n",
        "model1 = CNNModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = SimpleRNNModel(input_size=second_X_data.shape[1], hidden_size=64, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 3: Combine LogisticRegressionModel and LSTMModel\n",
        "print(\"\\nTraining Combined Model 3: LogisticRegressionModel + LSTMModel\")\n",
        "model1 = LogisticRegressionModel(input_size=num_features*window_size, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = LSTMModel(input_size=second_X_data.shape[1], hidden_size=128, num_layers=1, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ozPGMJjwveMB",
        "outputId": "40928672-0e89-4203-c942-95f0e72f7994"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying hyperparameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.001, 'num_epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 11.0394\n",
            "Epoch [2/5], Loss: 11.0018\n",
            "Epoch [3/5], Loss: 10.9970\n",
            "Epoch [4/5], Loss: 10.9921\n",
            "Epoch [5/5], Loss: 10.9896\n",
            "Accuracy on test set: 33.48%\n",
            "Cohen's Kappa: -0.0003\n",
            "Trying hyperparameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.0001, 'num_epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 11.0810\n",
            "Epoch [2/5], Loss: 11.0141\n",
            "Epoch [3/5], Loss: 11.0052\n",
            "Epoch [4/5], Loss: 10.9961\n",
            "Epoch [5/5], Loss: 10.9905\n",
            "Accuracy on test set: 33.35%\n",
            "Cohen's Kappa: 0.0000\n",
            "Trying hyperparameters: {'hidden_size': 64, 'num_layers': 2, 'learning_rate': 0.001, 'num_epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 11.0532\n",
            "Epoch [2/5], Loss: 11.0046\n",
            "Epoch [3/5], Loss: 11.0050\n",
            "Epoch [4/5], Loss: 11.0034\n",
            "Epoch [5/5], Loss: 10.9962\n",
            "Accuracy on test set: 32.83%\n",
            "Cohen's Kappa: -0.0075\n",
            "Trying hyperparameters: {'hidden_size': 64, 'num_layers': 2, 'learning_rate': 0.0001, 'num_epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 11.0312\n",
            "Epoch [2/5], Loss: 11.0012\n",
            "Epoch [3/5], Loss: 10.9903\n",
            "Epoch [4/5], Loss: 10.9895\n",
            "Epoch [5/5], Loss: 10.9827\n",
            "Accuracy on test set: 33.79%\n",
            "Cohen's Kappa: 0.0015\n",
            "Trying hyperparameters: {'hidden_size': 128, 'num_layers': 1, 'learning_rate': 0.001, 'num_epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 11.0546\n",
            "Epoch [2/5], Loss: 11.0149\n",
            "Epoch [3/5], Loss: 11.0106\n",
            "Epoch [4/5], Loss: 10.9984\n",
            "Epoch [5/5], Loss: 10.9936\n",
            "Accuracy on test set: 32.73%\n",
            "Cohen's Kappa: -0.0084\n",
            "Trying hyperparameters: {'hidden_size': 128, 'num_layers': 1, 'learning_rate': 0.0001, 'num_epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 11.2512\n",
            "Epoch [2/5], Loss: 11.0308\n",
            "Epoch [3/5], Loss: 11.0050\n",
            "Epoch [4/5], Loss: 10.9968\n",
            "Epoch [5/5], Loss: 10.9971\n",
            "Accuracy on test set: 32.03%\n",
            "Cohen's Kappa: -0.0194\n",
            "Trying hyperparameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.001, 'num_epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 11.0756\n",
            "Epoch [2/5], Loss: 11.0242\n",
            "Epoch [3/5], Loss: 11.0151\n",
            "Epoch [4/5], Loss: 11.0062\n",
            "Epoch [5/5], Loss: 11.0032\n",
            "Accuracy on test set: 33.87%\n",
            "Cohen's Kappa: 0.0108\n",
            "Trying hyperparameters: {'hidden_size': 128, 'num_layers': 2, 'learning_rate': 0.0001, 'num_epochs': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 11.0780\n",
            "Epoch [2/5], Loss: 11.0124\n",
            "Epoch [3/5], Loss: 10.9964\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4034ed44d46f>\u001b[0m in \u001b[0;36m<cell line: 487>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;31m# Start hyperparameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m \u001b[0mhyperparameter_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;31m# Example 1: Combine TransformerModel and LSTMModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-4034ed44d46f>\u001b[0m in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(hyperparams, train_loader, test_loader, device)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mkappa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-4034ed44d46f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, device, writer)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_securities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-4034ed44d46f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0moutputs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0moutputs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-4034ed44d46f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (sequence_length, batch_size, embedding_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Last output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask_for_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_nested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    203\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2574\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2575\u001b[0m         )\n\u001b[0;32m-> 2576\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m def rms_norm(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### added more models\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from itertools import product\n",
        "import time\n",
        "\n",
        "# Parameters\n",
        "num_timesteps = 5000  # Reduced for practical purposes\n",
        "num_securities = 10  # Number of different securities\n",
        "num_features_per_security = 4  # Features per security\n",
        "num_classes = 3  # Number of target classes\n",
        "num_features = num_securities * num_features_per_security  # Total number of features\n",
        "\n",
        "# Generate timestamps\n",
        "timestamps = np.arange(num_timesteps)\n",
        "\n",
        "# Generate random data for the primary dataset (X_data) and labels (y_data)\n",
        "X_data = np.random.rand(num_timesteps, num_features).astype(np.float32)  # Random features\n",
        "y_data = np.random.randint(0, num_classes, size=(num_timesteps, num_securities)).astype(np.int64)  # Random labels\n",
        "\n",
        "# Generate the second dataset with 3 categorical strings and 2 continuous floats per timestamp\n",
        "str_columns = ['str1', 'str2', 'str3']\n",
        "float_columns = ['float1', 'float2']\n",
        "second_dataset = {\n",
        "    'timestamp': timestamps,\n",
        "    'str1': np.random.choice(['A', 'B', 'C'], num_timesteps),\n",
        "    'str2': np.random.choice(['D', 'E', 'F'], num_timesteps),\n",
        "    'str3': np.random.choice(['G', 'H', 'I'], num_timesteps),\n",
        "    'float1': np.random.rand(num_timesteps),\n",
        "    'float2': np.random.rand(num_timesteps),\n",
        "}\n",
        "\n",
        "# Encode categorical string columns using LabelEncoder\n",
        "label_encoders = {}\n",
        "for col in str_columns:\n",
        "    le = LabelEncoder()\n",
        "    second_dataset[col] = le.fit_transform(second_dataset[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Combine all features from the second dataset into a single array\n",
        "second_X_data = np.column_stack([second_dataset[col] for col in str_columns + float_columns]).astype(np.float32)\n",
        "\n",
        "# Apply Min-Max scaling to both datasets\n",
        "scaler_X = MinMaxScaler()\n",
        "X_data = scaler_X.fit_transform(X_data)\n",
        "\n",
        "scaler_second_X = MinMaxScaler()\n",
        "second_X_data = scaler_second_X.fit_transform(second_X_data)\n",
        "\n",
        "def add_positional_encoding(X, timestamps, option='shared'):\n",
        "    \"\"\"\n",
        "    Add positional encoding to the feature matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - X (ndarray): Feature matrix.\n",
        "    - timestamps (ndarray): Array of timestamps.\n",
        "    - option (str): 'shared' or 'per_security'.\n",
        "\n",
        "    Returns:\n",
        "    - X_pe (ndarray): X with positional encoding added.\n",
        "    \"\"\"\n",
        "    if option == 'shared':\n",
        "        # Shared positional encoding across all features\n",
        "        pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(X.shape[1]) / X.shape[1]))\n",
        "        X_pe = X + pe.astype(np.float32)\n",
        "    elif option == 'per_security':\n",
        "        # Separate positional encoding for each security\n",
        "        pe_list = []\n",
        "        for i in range(num_securities):\n",
        "            pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(num_features_per_security) / num_features_per_security))\n",
        "            pe_list.append(pe)\n",
        "        pe_concat = np.hstack(pe_list)\n",
        "        X_pe = X + pe_concat.astype(np.float32)\n",
        "    else:\n",
        "        X_pe = X  # No positional encoding\n",
        "    return X_pe\n",
        "\n",
        "# Apply positional encoding\n",
        "positional_encoding_option = 'shared'  # 'shared' or 'per_security'\n",
        "X_data = add_positional_encoding(X_data, timestamps, positional_encoding_option)\n",
        "\n",
        "def create_windows(X1, X2, y, window_size, horizon):\n",
        "    \"\"\"\n",
        "    Create sliding windows for time series data.\n",
        "\n",
        "    Parameters:\n",
        "    - X1 (ndarray): Primary dataset features.\n",
        "    - X2 (ndarray): Secondary dataset features.\n",
        "    - y (ndarray): Target variable.\n",
        "    - window_size (int): Size of the window.\n",
        "    - horizon (int): Prediction horizon.\n",
        "\n",
        "    Returns:\n",
        "    - Tuple[np.ndarray, np.ndarray, np.ndarray]: Tuples of windows for X1, X2, and y.\n",
        "    \"\"\"\n",
        "    X1_windows = []\n",
        "    X2_windows = []\n",
        "    y_windows = []\n",
        "    for i in range(len(X1) - window_size - horizon + 1):\n",
        "        X1_windows.append(X1[i:i+window_size])\n",
        "        X2_windows.append(X2[i:i+window_size])\n",
        "        y_windows.append(y[i+window_size+horizon-1])\n",
        "    return np.array(X1_windows), np.array(X2_windows), np.array(y_windows)\n",
        "\n",
        "# Define window sizes\n",
        "window_size = 20\n",
        "horizon = 1\n",
        "\n",
        "# Create windows\n",
        "X1_windows, X2_windows, y_windows = create_windows(X_data, second_X_data, y_data, window_size, horizon)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(X1_windows) * train_ratio)\n",
        "\n",
        "X1_train = X1_windows[:train_size]\n",
        "X2_train = X2_windows[:train_size]\n",
        "y_train = y_windows[:train_size]\n",
        "\n",
        "X1_test = X1_windows[train_size:]\n",
        "X2_test = X2_windows[train_size:]\n",
        "y_test = y_windows[train_size:]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X1_train_tensor = torch.tensor(X1_train)\n",
        "X2_train_tensor = torch.tensor(X2_train)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "\n",
        "X1_test_tensor = torch.tensor(X1_test)\n",
        "X2_test_tensor = torch.tensor(X2_test)\n",
        "y_test_tensor = torch.tensor(y_test)\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for time series data with two feature sets.\n",
        "\n",
        "    Parameters:\n",
        "    - X1 (torch.Tensor): Primary dataset features.\n",
        "    - X2 (torch.Tensor): Secondary dataset features.\n",
        "    - y (torch.Tensor): Target variable.\n",
        "    \"\"\"\n",
        "    def __init__(self, X1, X2, y):\n",
        "        self.X1 = X1.float()\n",
        "        self.X2 = X2.float()\n",
        "        self.y = y.long()\n",
        "    def __len__(self):\n",
        "        return len(self.X1)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X1[idx], self.X2[idx], self.y[idx]\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = TimeSeriesDataset(X1_train_tensor, X2_train_tensor, y_train_tensor)\n",
        "test_dataset = TimeSeriesDataset(X1_test_tensor, X2_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class MatrixRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "\n",
        "    Parameters:\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_features (int): Total number of features.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, num_features):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(1, num_securities))\n",
        "        self.B = nn.Parameter(torch.randn(num_features, num_classes))\n",
        "        self.num_securities = num_securities\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten over time\n",
        "        out = self.A @ x @ self.B  # Shape: (batch_size, num_classes)\n",
        "        out = out.view(-1, self.num_securities, num_classes)\n",
        "        return out\n",
        "\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_securities, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.linear = nn.Linear(input_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.linear(x)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "\n",
        "    Parameters:\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, window_size)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        out = x.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - hidden_size (int): Size of hidden state.\n",
        "    - num_layers (int): Number of LSTM layers.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_securities, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures global dependencies.\n",
        "    - Parallel computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Requires large datasets.\n",
        "    - Computationally intensive.\n",
        "\n",
        "    Parameters:\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.embedding = nn.Linear(num_features, 128)\n",
        "        self.pos_encoder = PositionalEncoding(128)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=2)\n",
        "        self.decoder = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), x.size(1), -1)  # (batch_size, window_size, num_features)\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # (sequence_length, batch_size, embedding_dim)\n",
        "        output = self.transformer_encoder(x)\n",
        "        output = output[-1, :, :]  # Last output\n",
        "        output = self.decoder(output)\n",
        "        output = output.view(-1, self.num_securities, self.num_classes)\n",
        "        return output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional Encoding for Transformer.\n",
        "\n",
        "    Adds positional information to the embeddings.\n",
        "\n",
        "    Parameters:\n",
        "    - d_model (int): Embedding dimension.\n",
        "    - max_len (int): Maximum sequence length.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        if d_model % 2 == 1:\n",
        "            pe[:, 1::2] = torch.sin(position * div_term)\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(1)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return x\n",
        "\n",
        "class SimpleRNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple Recurrent Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures sequential dependencies.\n",
        "    - Simpler than LSTM.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Struggles with long-term dependencies.\n",
        "    - May suffer from vanishing gradients.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - hidden_size (int): Size of hidden state.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_securities, num_classes):\n",
        "        super(SimpleRNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "# Missing Models with Docstrings and Comments\n",
        "\n",
        "class GNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures relationships between securities.\n",
        "    - Utilizes attention mechanisms.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Requires graph structure.\n",
        "\n",
        "    Parameters:\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_features_per_security (int): Features per security.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, num_features_per_security, num_classes):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        # Create a linear layer for each security\n",
        "        self.gcn_layers = nn.ModuleList([nn.Linear(num_features_per_security, 64) for _ in range(num_securities)])\n",
        "        # Multi-head attention mechanism\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=64, num_heads=4, batch_first=True)\n",
        "        # Fully connected layer for classification\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, window_size, num_features)\n",
        "        batch_size = x.size(0)\n",
        "        x = x[:, -1, :]  # Use the last time step\n",
        "        x = x.view(batch_size, self.num_securities, -1)  # (batch_size, num_securities, num_features_per_security)\n",
        "        node_embeddings = []\n",
        "        for i in range(self.num_securities):\n",
        "            h = self.gcn_layers[i](x[:, i, :])  # (batch_size, 64)\n",
        "            node_embeddings.append(h)\n",
        "        h = torch.stack(node_embeddings, dim=1)  # (batch_size, num_securities, 64)\n",
        "        # Apply attention mechanism\n",
        "        attn_output, _ = self.attention(h, h, h)\n",
        "        out = self.fc(attn_output)  # (batch_size, num_securities, num_classes)\n",
        "        return out\n",
        "\n",
        "class MambaModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Mamba Model: Combines CNN and LSTM architectures.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures both local and long-term dependencies.\n",
        "    - Utilizes CNN for feature extraction and LSTM for temporal patterns.\n",
        "\n",
        "    Disadvantages:\n",
        "    - More complex and computationally intensive.\n",
        "\n",
        "    Parameters:\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(MambaModel, self).__init__()\n",
        "        # Convolutional layer\n",
        "        self.cnn = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, batch_first=True)\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, window_size, num_features)\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, window_size)\n",
        "        x = F.relu(self.cnn(x))  # Apply CNN\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, new_window_size, channels)\n",
        "        h0 = torch.zeros(2, x.size(0), 128).to(x.device)  # Initial hidden state\n",
        "        c0 = torch.zeros(2, x.size(0), 128).to(x.device)  # Initial cell state\n",
        "        out, _ = self.lstm(x, (h0, c0))  # Apply LSTM\n",
        "        out = out[:, -1, :]  # Get the last output\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, num_classes)\n",
        "        return out\n",
        "\n",
        "class LiquidNetModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Liquid Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Dynamic adaptation to inputs.\n",
        "    - Good for time-series data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Relatively new, less tested.\n",
        "    - May be complex to tune.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - hidden_size (int): Size of hidden state.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_securities, num_classes):\n",
        "        super(LiquidNetModel, self).__init__()\n",
        "        # RNN Cell with ReLU activation\n",
        "        self.rnn_cell = nn.RNNCell(input_size, hidden_size, nonlinearity='relu')\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h_t = torch.zeros(x.size(0), self.rnn_cell.hidden_size).to(x.device)  # Initial hidden state\n",
        "        for t in range(x.size(1)):\n",
        "            h_t = self.rnn_cell(x[:, t, :], h_t)  # Update hidden state\n",
        "        out = self.fc(h_t)\n",
        "        out = out.view(-1, self.num_securities, num_classes)\n",
        "        return out\n",
        "\n",
        "class HiddenMarkovModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Hidden Markov Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Probabilistic approach.\n",
        "    - Good for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Simplified version here.\n",
        "    - May not capture complex patterns.\n",
        "\n",
        "    Parameters:\n",
        "    - num_states (int): Number of hidden states.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_states, num_securities, num_classes):\n",
        "        super(HiddenMarkovModel, self).__init__()\n",
        "        self.num_states = num_states\n",
        "        # Start probabilities\n",
        "        self.start_prob = nn.Parameter(torch.randn(num_states))\n",
        "        # Transition probabilities\n",
        "        self.transition_prob = nn.Parameter(torch.randn(num_states, num_states))\n",
        "        # Emission probabilities\n",
        "        self.emission_prob = nn.Parameter(torch.randn(num_states, num_classes))\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        # Simplified; in practice, you'd implement the forward algorithm\n",
        "        out = torch.softmax(self.emission_prob, dim=1)\n",
        "        out = out.unsqueeze(0).unsqueeze(0).repeat(batch_size, self.num_securities, 1)\n",
        "        return out\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined Model: Merges outputs from two models.\n",
        "\n",
        "    Advantages:\n",
        "    - Leverages multiple data sources.\n",
        "    - Potentially better performance.\n",
        "\n",
        "    Disadvantages:\n",
        "    - More complex.\n",
        "    - Computationally intensive.\n",
        "\n",
        "    Parameters:\n",
        "    - model1 (nn.Module): First model.\n",
        "    - model2 (nn.Module): Second model.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    - num_securities (int): Number of securities.\n",
        "    \"\"\"\n",
        "    def __init__(self, model1, model2, num_classes, num_securities):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.model1 = model1\n",
        "        self.model2 = model2\n",
        "        self.fc = nn.Linear(num_classes * 2, num_classes)\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "    def forward(self, x1, x2):\n",
        "        outputs1 = self.model1(x1)\n",
        "        outputs2 = self.model2(x2)\n",
        "        outputs = torch.cat((outputs1, outputs2), dim=2)\n",
        "        batch_size = outputs.size(0)\n",
        "        outputs = outputs.view(-1, outputs.size(2))\n",
        "        final_output = self.fc(outputs)\n",
        "        final_output = final_output.view(batch_size, self.num_securities, -1)\n",
        "        return final_output\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs, device, writer):\n",
        "    \"\"\"\n",
        "    Training loop for the model.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to train.\n",
        "    - train_loader (DataLoader): DataLoader for training data.\n",
        "    - criterion (nn.Module): Loss function.\n",
        "    - optimizer (torch.optim.Optimizer): Optimizer.\n",
        "    - num_epochs (int): Number of epochs.\n",
        "    - device (torch.device): Computation device.\n",
        "    - writer (SummaryWriter): TensorBoard SummaryWriter.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    global_step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X1_batch, X2_batch, y_batch in train_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            loss = 0\n",
        "            for i in range(num_securities):\n",
        "                loss += criterion(outputs[:, i, :], y_batch[:, i])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            writer.add_scalar('Training Loss', loss.item(), global_step)\n",
        "            global_step += 1\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "        # Save checkpoint\n",
        "        torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pth')\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test set.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to evaluate.\n",
        "    - test_loader (DataLoader): DataLoader for test data.\n",
        "    - device (torch.device): Computation device.\n",
        "\n",
        "    Returns:\n",
        "    - float: Cohen's kappa score.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for X1_batch, X2_batch, y_batch in test_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            _, predicted = torch.max(outputs.data, 2)\n",
        "            total += y_batch.numel()\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy().flatten())\n",
        "            all_targets.extend(y_batch.cpu().numpy().flatten())\n",
        "    accuracy = 100 * correct / total\n",
        "    kappa = cohen_kappa_score(all_targets, all_preds)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
        "    print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
        "    return kappa\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Examples of combination models using the new models\n",
        "\n",
        "# Example 1: Combine GNNModel and TransformerModel\n",
        "print(\"\\nTraining Combined Model 1: GNNModel + TransformerModel\")\n",
        "model1 = GNNModel(num_securities=num_securities, num_features_per_security=num_features_per_security, num_classes=num_classes)\n",
        "model2 = TransformerModel(num_features=second_X_data.shape[1], num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 2: Combine MambaModel and LSTMModel\n",
        "print(\"\\nTraining Combined Model 2: MambaModel + LSTMModel\")\n",
        "model1 = MambaModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = LSTMModel(input_size=second_X_data.shape[1], hidden_size=64, num_layers=1, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 3: Combine LiquidNetModel and CNNModel\n",
        "print(\"\\nTraining Combined Model 3: LiquidNetModel + CNNModel\")\n",
        "model1 = LiquidNetModel(input_size=num_features, hidden_size=128, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = CNNModel(num_features=second_X_data.shape[1], num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 4: Combine HiddenMarkovModel and LogisticRegressionModel\n",
        "print(\"\\nTraining Combined Model 4: HiddenMarkovModel + LogisticRegressionModel\")\n",
        "model1 = HiddenMarkovModel(num_states=5, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = LogisticRegressionModel(input_size=second_X_data.shape[1]*window_size, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 5: Combine GNNModel and MambaModel\n",
        "print(\"\\nTraining Combined Model 5: GNNModel + MambaModel\")\n",
        "model1 = GNNModel(num_securities=num_securities, num_features_per_security=num_features_per_security, num_classes=num_classes)\n",
        "model2 = MambaModel(num_features=second_X_data.shape[1], num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "EFhIcnJFydX9",
        "outputId": "0642d514-60dc-46fb-d2a9-8cf4d0741555"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Combined Model 1: GNNModel + TransformerModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 11.0695\n",
            "Epoch [2/5], Loss: 11.0211\n",
            "Epoch [3/5], Loss: 11.0052\n",
            "Epoch [4/5], Loss: 10.9866\n",
            "Epoch [5/5], Loss: 10.9811\n",
            "Accuracy on test set: 32.63%\n",
            "Cohen's Kappa: -0.0071\n",
            "\n",
            "Training Combined Model 2: MambaModel + LSTMModel\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MambaModel' object has no attribute 'num_securities'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-9ae3b7bd3277>\u001b[0m in \u001b[0;36m<cell line: 662>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-9ae3b7bd3277>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, device, writer)\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_securities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-9ae3b7bd3277>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0moutputs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0moutputs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-9ae3b7bd3277>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Get the last output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_securities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1729\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MambaModel' object has no attribute 'num_securities'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from itertools import product\n",
        "import time\n",
        "\n",
        "# Parameters\n",
        "num_timesteps = 5000  # Reduced for practical purposes\n",
        "num_securities = 10  # Number of different securities\n",
        "num_features_per_security = 4  # Features per security\n",
        "num_classes = 3  # Number of target classes\n",
        "num_features = num_securities * num_features_per_security  # Total number of features\n",
        "\n",
        "# Generate timestamps\n",
        "timestamps = np.arange(num_timesteps)\n",
        "\n",
        "# Generate random data for the primary dataset (X_data) and labels (y_data)\n",
        "X_data = np.random.rand(num_timesteps, num_features).astype(np.float32)  # Random features\n",
        "y_data = np.random.randint(0, num_classes, size=(num_timesteps, num_securities)).astype(np.int64)  # Random labels\n",
        "\n",
        "# Generate the second dataset with 3 categorical strings and 2 continuous floats per timestamp\n",
        "str_columns = ['str1', 'str2', 'str3']\n",
        "float_columns = ['float1', 'float2']\n",
        "second_dataset = {\n",
        "    'timestamp': timestamps,\n",
        "    'str1': np.random.choice(['A', 'B', 'C'], num_timesteps),\n",
        "    'str2': np.random.choice(['D', 'E', 'F'], num_timesteps),\n",
        "    'str3': np.random.choice(['G', 'H', 'I'], num_timesteps),\n",
        "    'float1': np.random.rand(num_timesteps),\n",
        "    'float2': np.random.rand(num_timesteps),\n",
        "}\n",
        "\n",
        "# Encode categorical string columns using LabelEncoder\n",
        "label_encoders = {}\n",
        "for col in str_columns:\n",
        "    le = LabelEncoder()\n",
        "    second_dataset[col] = le.fit_transform(second_dataset[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Combine all features from the second dataset into a single array\n",
        "second_X_data = np.column_stack([second_dataset[col] for col in str_columns + float_columns]).astype(np.float32)\n",
        "\n",
        "# Apply Min-Max scaling to both datasets\n",
        "scaler_X = MinMaxScaler()\n",
        "X_data = scaler_X.fit_transform(X_data)\n",
        "\n",
        "scaler_second_X = MinMaxScaler()\n",
        "second_X_data = scaler_second_X.fit_transform(second_X_data)\n",
        "\n",
        "def add_positional_encoding(X, timestamps, option='shared'):\n",
        "    \"\"\"\n",
        "    Add positional encoding to the feature matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - X (ndarray): Feature matrix.\n",
        "    - timestamps (ndarray): Array of timestamps.\n",
        "    - option (str): 'shared' or 'per_security'.\n",
        "\n",
        "    Returns:\n",
        "    - X_pe (ndarray): X with positional encoding added.\n",
        "    \"\"\"\n",
        "    if option == 'shared':\n",
        "        # Shared positional encoding across all features\n",
        "        pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(X.shape[1]) / X.shape[1]))\n",
        "        X_pe = X + pe.astype(np.float32)\n",
        "    elif option == 'per_security':\n",
        "        # Separate positional encoding for each security\n",
        "        pe_list = []\n",
        "        for i in range(num_securities):\n",
        "            pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(num_features_per_security) / num_features_per_security))\n",
        "            pe_list.append(pe)\n",
        "        pe_concat = np.hstack(pe_list)\n",
        "        X_pe = X + pe_concat.astype(np.float32)\n",
        "    else:\n",
        "        X_pe = X  # No positional encoding\n",
        "    return X_pe\n",
        "\n",
        "# Apply positional encoding\n",
        "positional_encoding_option = 'shared'  # 'shared' or 'per_security'\n",
        "X_data = add_positional_encoding(X_data, timestamps, positional_encoding_option)\n",
        "\n",
        "def create_windows(X1, X2, y, window_size, horizon):\n",
        "    \"\"\"\n",
        "    Create sliding windows for time series data.\n",
        "\n",
        "    Parameters:\n",
        "    - X1 (ndarray): Primary dataset features.\n",
        "    - X2 (ndarray): Secondary dataset features.\n",
        "    - y (ndarray): Target variable.\n",
        "    - window_size (int): Size of the window.\n",
        "    - horizon (int): Prediction horizon.\n",
        "\n",
        "    Returns:\n",
        "    - Tuple[np.ndarray, np.ndarray, np.ndarray]: Tuples of windows for X1, X2, and y.\n",
        "    \"\"\"\n",
        "    X1_windows = []\n",
        "    X2_windows = []\n",
        "    y_windows = []\n",
        "    for i in range(len(X1) - window_size - horizon + 1):\n",
        "        X1_windows.append(X1[i:i+window_size])\n",
        "        X2_windows.append(X2[i:i+window_size])\n",
        "        y_windows.append(y[i+window_size+horizon-1])\n",
        "    return np.array(X1_windows), np.array(X2_windows), np.array(y_windows)\n",
        "\n",
        "# Define window sizes\n",
        "window_size = 20\n",
        "horizon = 1\n",
        "\n",
        "# Create windows\n",
        "X1_windows, X2_windows, y_windows = create_windows(X_data, second_X_data, y_data, window_size, horizon)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(X1_windows) * train_ratio)\n",
        "\n",
        "X1_train = X1_windows[:train_size]\n",
        "X2_train = X2_windows[:train_size]\n",
        "y_train = y_windows[:train_size]\n",
        "\n",
        "X1_test = X1_windows[train_size:]\n",
        "X2_test = X2_windows[train_size:]\n",
        "y_test = y_windows[train_size:]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X1_train_tensor = torch.tensor(X1_train)\n",
        "X2_train_tensor = torch.tensor(X2_train)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "\n",
        "X1_test_tensor = torch.tensor(X1_test)\n",
        "X2_test_tensor = torch.tensor(X2_test)\n",
        "y_test_tensor = torch.tensor(y_test)\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for time series data with two feature sets.\n",
        "\n",
        "    Parameters:\n",
        "    - X1 (torch.Tensor): Primary dataset features.\n",
        "    - X2 (torch.Tensor): Secondary dataset features.\n",
        "    - y (torch.Tensor): Target variable.\n",
        "    \"\"\"\n",
        "    def __init__(self, X1, X2, y):\n",
        "        self.X1 = X1.float()\n",
        "        self.X2 = X2.float()\n",
        "        self.y = y.long()\n",
        "    def __len__(self):\n",
        "        return len(self.X1)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X1[idx], self.X2[idx], self.y[idx]\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = TimeSeriesDataset(X1_train_tensor, X2_train_tensor, y_train_tensor)\n",
        "test_dataset = TimeSeriesDataset(X1_test_tensor, X2_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class MatrixRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "\n",
        "    Parameters:\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, num_features, num_classes):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(1, num_securities))\n",
        "        self.B = nn.Parameter(torch.randn(num_features, num_classes))\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten over time\n",
        "        out = self.A @ x @ self.B  # Shape: (batch_size, num_classes)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_securities, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.linear = nn.Linear(input_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.linear(x)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "\n",
        "    Parameters:\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, window_size)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        out = x.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - hidden_size (int): Size of hidden state.\n",
        "    - num_layers (int): Number of LSTM layers.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_securities, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures global dependencies.\n",
        "    - Parallel computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Requires large datasets.\n",
        "    - Computationally intensive.\n",
        "\n",
        "    Parameters:\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.embedding = nn.Linear(num_features, 128)\n",
        "        self.pos_encoder = PositionalEncoding(128)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=2)\n",
        "        self.decoder = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), x.size(1), -1)  # (batch_size, window_size, num_features)\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # (sequence_length, batch_size, embedding_dim)\n",
        "        output = self.transformer_encoder(x)\n",
        "        output = output[-1, :, :]  # Last output\n",
        "        output = self.decoder(output)\n",
        "        output = output.view(-1, self.num_securities, self.num_classes)\n",
        "        return output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional Encoding for Transformer.\n",
        "\n",
        "    Adds positional information to the embeddings.\n",
        "\n",
        "    Parameters:\n",
        "    - d_model (int): Embedding dimension.\n",
        "    - max_len (int): Maximum sequence length.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        if d_model % 2 == 1:\n",
        "            pe[:, 1::2] = torch.sin(position * div_term)\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(1)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return x\n",
        "\n",
        "class SimpleRNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple Recurrent Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures sequential dependencies.\n",
        "    - Simpler than LSTM.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Struggles with long-term dependencies.\n",
        "    - May suffer from vanishing gradients.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - hidden_size (int): Size of hidden state.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_securities, num_classes):\n",
        "        super(SimpleRNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "# Missing Models with Docstrings and Comments\n",
        "\n",
        "class GNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures relationships between securities.\n",
        "    - Utilizes attention mechanisms.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Requires graph structure.\n",
        "\n",
        "    Parameters:\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_features_per_security (int): Features per security.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, num_features_per_security, num_classes):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        # Create a linear layer for each security\n",
        "        self.gcn_layers = nn.ModuleList([nn.Linear(num_features_per_security, 64) for _ in range(num_securities)])\n",
        "        # Multi-head attention mechanism\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=64, num_heads=4, batch_first=True)\n",
        "        # Fully connected layer for classification\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, window_size, num_features)\n",
        "        batch_size = x.size(0)\n",
        "        x = x[:, -1, :]  # Use the last time step\n",
        "        x = x.view(batch_size, self.num_securities, -1)  # (batch_size, num_securities, num_features_per_security)\n",
        "        node_embeddings = []\n",
        "        for i in range(self.num_securities):\n",
        "            h = self.gcn_layers[i](x[:, i, :])  # (batch_size, 64)\n",
        "            node_embeddings.append(h)\n",
        "        h = torch.stack(node_embeddings, dim=1)  # (batch_size, num_securities, 64)\n",
        "        # Apply attention mechanism\n",
        "        attn_output, _ = self.attention(h, h, h)\n",
        "        out = self.fc(attn_output)  # (batch_size, num_securities, num_classes)\n",
        "        return out\n",
        "\n",
        "class MambaModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Mamba Model: Combines CNN and LSTM architectures.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures both local and long-term dependencies.\n",
        "    - Utilizes CNN for feature extraction and LSTM for temporal patterns.\n",
        "\n",
        "    Disadvantages:\n",
        "    - More complex and computationally intensive.\n",
        "\n",
        "    Parameters:\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(MambaModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        # Convolutional layer\n",
        "        self.cnn = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, batch_first=True)\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, window_size, num_features)\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, window_size)\n",
        "        x = F.relu(self.cnn(x))  # Apply CNN\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, new_window_size, channels)\n",
        "        h0 = torch.zeros(2, x.size(0), 128).to(x.device)  # Initial hidden state\n",
        "        c0 = torch.zeros(2, x.size(0), 128).to(x.device)  # Initial cell state\n",
        "        out, _ = self.lstm(x, (h0, c0))  # Apply LSTM\n",
        "        out = out[:, -1, :]  # Get the last output\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LiquidNetModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Liquid Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Dynamic adaptation to inputs.\n",
        "    - Good for time-series data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Relatively new, less tested.\n",
        "    - May be complex to tune.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - hidden_size (int): Size of hidden state.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_securities, num_classes):\n",
        "        super(LiquidNetModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        # RNN Cell with ReLU activation\n",
        "        self.rnn_cell = nn.RNNCell(input_size, hidden_size, nonlinearity='relu')\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h_t = torch.zeros(x.size(0), self.rnn_cell.hidden_size).to(x.device)  # Initial hidden state\n",
        "        for t in range(x.size(1)):\n",
        "            h_t = self.rnn_cell(x[:, t, :], h_t)  # Update hidden state\n",
        "        out = self.fc(h_t)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class HiddenMarkovModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Hidden Markov Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Probabilistic approach.\n",
        "    - Good for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Simplified version here.\n",
        "    - May not capture complex patterns.\n",
        "\n",
        "    Parameters:\n",
        "    - num_states (int): Number of hidden states.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_states, num_securities, num_classes):\n",
        "        super(HiddenMarkovModel, self).__init__()\n",
        "        self.num_states = num_states\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        # Start probabilities\n",
        "        self.start_prob = nn.Parameter(torch.randn(num_states))\n",
        "        # Transition probabilities\n",
        "        self.transition_prob = nn.Parameter(torch.randn(num_states, num_states))\n",
        "        # Emission probabilities\n",
        "        self.emission_prob = nn.Parameter(torch.randn(num_states, num_classes))\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        # Simplified; in practice, you'd implement the forward algorithm\n",
        "        out = torch.softmax(self.emission_prob, dim=1)\n",
        "        out = out.unsqueeze(0).unsqueeze(0).repeat(batch_size, self.num_securities, 1)\n",
        "        return out\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined Model: Merges outputs from two models.\n",
        "\n",
        "    Advantages:\n",
        "    - Leverages multiple data sources.\n",
        "    - Potentially better performance.\n",
        "\n",
        "    Disadvantages:\n",
        "    - More complex.\n",
        "    - Computationally intensive.\n",
        "\n",
        "    Parameters:\n",
        "    - model1 (nn.Module): First model.\n",
        "    - model2 (nn.Module): Second model.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    - num_securities (int): Number of securities.\n",
        "    \"\"\"\n",
        "    def __init__(self, model1, model2, num_classes, num_securities):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.model1 = model1\n",
        "        self.model2 = model2\n",
        "        self.fc = nn.Linear(num_classes * 2, num_classes)\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "    def forward(self, x1, x2):\n",
        "        outputs1 = self.model1(x1)\n",
        "        outputs2 = self.model2(x2)\n",
        "        outputs = torch.cat((outputs1, outputs2), dim=2)\n",
        "        batch_size = outputs.size(0)\n",
        "        outputs = outputs.view(-1, outputs.size(2))\n",
        "        final_output = self.fc(outputs)\n",
        "        final_output = final_output.view(batch_size, self.num_securities, -1)\n",
        "        return final_output\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs, device, writer):\n",
        "    \"\"\"\n",
        "    Training loop for the model.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to train.\n",
        "    - train_loader (DataLoader): DataLoader for training data.\n",
        "    - criterion (nn.Module): Loss function.\n",
        "    - optimizer (torch.optim.Optimizer): Optimizer.\n",
        "    - num_epochs (int): Number of epochs.\n",
        "    - device (torch.device): Computation device.\n",
        "    - writer (SummaryWriter): TensorBoard SummaryWriter.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    global_step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X1_batch, X2_batch, y_batch in train_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            loss = 0\n",
        "            for i in range(num_securities):\n",
        "                loss += criterion(outputs[:, i, :], y_batch[:, i])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            writer.add_scalar('Training Loss', loss.item(), global_step)\n",
        "            global_step += 1\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "        # Save checkpoint\n",
        "        torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pth')\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test set.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to evaluate.\n",
        "    - test_loader (DataLoader): DataLoader for test data.\n",
        "    - device (torch.device): Computation device.\n",
        "\n",
        "    Returns:\n",
        "    - float: Cohen's kappa score.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for X1_batch, X2_batch, y_batch in test_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            _, predicted = torch.max(outputs.data, 2)\n",
        "            total += y_batch.numel()\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy().flatten())\n",
        "            all_targets.extend(y_batch.cpu().numpy().flatten())\n",
        "    accuracy = 100 * correct / total\n",
        "    kappa = cohen_kappa_score(all_targets, all_preds)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
        "    print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
        "    return kappa\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Examples of combination models using the new models\n",
        "\n",
        "# Example 1: Combine GNNModel and TransformerModel\n",
        "print(\"\\nTraining Combined Model 1: GNNModel + TransformerModel\")\n",
        "model1 = GNNModel(num_securities=num_securities, num_features_per_security=num_features_per_security, num_classes=num_classes)\n",
        "model2 = TransformerModel(num_features=second_X_data.shape[1], num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 2: Combine MambaModel and LSTMModel\n",
        "print(\"\\nTraining Combined Model 2: MambaModel + LSTMModel\")\n",
        "model1 = MambaModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = LSTMModel(input_size=second_X_data.shape[1], hidden_size=64, num_layers=1, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 3: Combine LiquidNetModel and CNNModel\n",
        "print(\"\\nTraining Combined Model 3: LiquidNetModel + CNNModel\")\n",
        "model1 = LiquidNetModel(input_size=num_features, hidden_size=128, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = CNNModel(num_features=second_X_data.shape[1], num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 4: Combine HiddenMarkovModel and LogisticRegressionModel\n",
        "print(\"\\nTraining Combined Model 4: HiddenMarkovModel + LogisticRegressionModel\")\n",
        "model1 = HiddenMarkovModel(num_states=5, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = LogisticRegressionModel(input_size=second_X_data.shape[1]*window_size, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 5: Combine GNNModel and MambaModel\n",
        "print(\"\\nTraining Combined Model 5: GNNModel + MambaModel\")\n",
        "model1 = GNNModel(num_securities=num_securities, num_features_per_security=num_features_per_security, num_classes=num_classes)\n",
        "model2 = MambaModel(num_features=second_X_data.shape[1], num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "jYVOd0PXzi9j",
        "outputId": "87bf4191-cfbc-4adc-b456-605c28d3e41b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Combined Model 1: GNNModel + TransformerModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 11.0633\n",
            "Epoch [2/5], Loss: 11.0170\n",
            "Epoch [3/5], Loss: 11.0033\n",
            "Epoch [4/5], Loss: 10.9927\n",
            "Epoch [5/5], Loss: 10.9869\n",
            "Accuracy on test set: 33.32%\n",
            "Cohen's Kappa: -0.0002\n",
            "\n",
            "Training Combined Model 2: MambaModel + LSTMModel\n",
            "Epoch [1/5], Loss: 10.9977\n",
            "Epoch [2/5], Loss: 10.9867\n",
            "Epoch [3/5], Loss: 10.9827\n",
            "Epoch [4/5], Loss: 10.9759\n",
            "Epoch [5/5], Loss: 10.9718\n",
            "Accuracy on test set: 32.71%\n",
            "Cohen's Kappa: -0.0092\n",
            "\n",
            "Training Combined Model 3: LiquidNetModel + CNNModel\n",
            "Epoch [1/5], Loss: 11.0257\n",
            "Epoch [2/5], Loss: 10.9812\n",
            "Epoch [3/5], Loss: 10.9605\n",
            "Epoch [4/5], Loss: 10.9400\n",
            "Epoch [5/5], Loss: 10.9039\n",
            "Accuracy on test set: 33.71%\n",
            "Cohen's Kappa: 0.0057\n",
            "\n",
            "Training Combined Model 4: HiddenMarkovModel + LogisticRegressionModel\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-0d53ea5841f4>\u001b[0m in \u001b[0;36m<cell line: 694>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-0d53ea5841f4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, device, writer)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_securities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-0d53ea5841f4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0moutputs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0moutputs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-0d53ea5841f4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;31m# Simplified; in practice, you'd implement the forward algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memission_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_securities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from itertools import product\n",
        "import time\n",
        "\n",
        "# Parameters\n",
        "num_timesteps = 5000  # Total number of time steps\n",
        "num_securities = 10  # Number of different securities\n",
        "num_features_per_security = 4  # Features per security\n",
        "num_classes = 3  # Number of target classes\n",
        "num_features = num_securities * num_features_per_security  # Total number of features\n",
        "\n",
        "# Generate timestamps\n",
        "timestamps = np.arange(num_timesteps)\n",
        "\n",
        "# Generate random data for the primary dataset (X_data) and labels (y_data)\n",
        "X_data = np.random.rand(num_timesteps, num_features).astype(np.float32)  # Random features\n",
        "y_data = np.random.randint(0, num_classes, size=(num_timesteps, num_securities)).astype(np.int64)  # Random labels\n",
        "\n",
        "# Generate the second dataset with 3 categorical strings and 2 continuous floats per timestamp\n",
        "str_columns = ['str1', 'str2', 'str3']\n",
        "float_columns = ['float1', 'float2']\n",
        "second_dataset = {\n",
        "    'timestamp': timestamps,\n",
        "    'str1': np.random.choice(['A', 'B', 'C'], num_timesteps),\n",
        "    'str2': np.random.choice(['D', 'E', 'F'], num_timesteps),\n",
        "    'str3': np.random.choice(['G', 'H', 'I'], num_timesteps),\n",
        "    'float1': np.random.rand(num_timesteps),\n",
        "    'float2': np.random.rand(num_timesteps),\n",
        "}\n",
        "\n",
        "# Encode categorical string columns using LabelEncoder\n",
        "label_encoders = {}\n",
        "for col in str_columns:\n",
        "    le = LabelEncoder()\n",
        "    second_dataset[col] = le.fit_transform(second_dataset[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Combine all features from the second dataset into a single array\n",
        "second_X_data = np.column_stack([second_dataset[col] for col in str_columns + float_columns]).astype(np.float32)\n",
        "\n",
        "# Apply Min-Max scaling to both datasets\n",
        "scaler_X = MinMaxScaler()\n",
        "X_data = scaler_X.fit_transform(X_data)\n",
        "\n",
        "scaler_second_X = MinMaxScaler()\n",
        "second_X_data = scaler_second_X.fit_transform(second_X_data)\n",
        "\n",
        "def add_positional_encoding(X, timestamps, option='shared'):\n",
        "    \"\"\"\n",
        "    Add positional encoding to the feature matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - X (ndarray): Feature matrix.\n",
        "    - timestamps (ndarray): Array of timestamps.\n",
        "    - option (str): 'shared' or 'per_security'.\n",
        "\n",
        "    Returns:\n",
        "    - X_pe (ndarray): X with positional encoding added.\n",
        "    \"\"\"\n",
        "    if option == 'shared':\n",
        "        # Shared positional encoding across all features\n",
        "        pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(X.shape[1]) / X.shape[1]))\n",
        "        X_pe = X + pe.astype(np.float32)\n",
        "    elif option == 'per_security':\n",
        "        # Separate positional encoding for each security\n",
        "        pe_list = []\n",
        "        for i in range(num_securities):\n",
        "            pe = np.sin(timestamps[:, None] / 10000 ** (np.arange(num_features_per_security) / num_features_per_security))\n",
        "            pe_list.append(pe)\n",
        "        pe_concat = np.hstack(pe_list)\n",
        "        X_pe = X + pe_concat.astype(np.float32)\n",
        "    else:\n",
        "        X_pe = X  # No positional encoding\n",
        "    return X_pe\n",
        "\n",
        "# Apply positional encoding\n",
        "positional_encoding_option = 'shared'  # 'shared' or 'per_security'\n",
        "X_data = add_positional_encoding(X_data, timestamps, positional_encoding_option)\n",
        "\n",
        "def create_windows(X1, X2, y, window_size, horizon):\n",
        "    \"\"\"\n",
        "    Create sliding windows for time series data.\n",
        "\n",
        "    Parameters:\n",
        "    - X1 (ndarray): Primary dataset features.\n",
        "    - X2 (ndarray): Secondary dataset features.\n",
        "    - y (ndarray): Target variable.\n",
        "    - window_size (int): Size of the window.\n",
        "    - horizon (int): Prediction horizon.\n",
        "\n",
        "    Returns:\n",
        "    - Tuple[np.ndarray, np.ndarray, np.ndarray]: Tuples of windows for X1, X2, and y.\n",
        "    \"\"\"\n",
        "    X1_windows = []\n",
        "    X2_windows = []\n",
        "    y_windows = []\n",
        "    for i in range(len(X1) - window_size - horizon + 1):\n",
        "        X1_windows.append(X1[i:i+window_size])\n",
        "        X2_windows.append(X2[i:i+window_size])\n",
        "        y_windows.append(y[i+window_size+horizon-1])\n",
        "    return np.array(X1_windows), np.array(X2_windows), np.array(y_windows)\n",
        "\n",
        "# Define window sizes\n",
        "window_size = 20\n",
        "horizon = 1\n",
        "\n",
        "# Create windows\n",
        "X1_windows, X2_windows, y_windows = create_windows(X_data, second_X_data, y_data, window_size, horizon)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(X1_windows) * train_ratio)\n",
        "\n",
        "X1_train = X1_windows[:train_size]\n",
        "X2_train = X2_windows[:train_size]\n",
        "y_train = y_windows[:train_size]\n",
        "\n",
        "X1_test = X1_windows[train_size:]\n",
        "X2_test = X2_windows[train_size:]\n",
        "y_test = y_windows[train_size:]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X1_train_tensor = torch.tensor(X1_train)\n",
        "X2_train_tensor = torch.tensor(X2_train)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "\n",
        "X1_test_tensor = torch.tensor(X1_test)\n",
        "X2_test_tensor = torch.tensor(X2_test)\n",
        "y_test_tensor = torch.tensor(y_test)\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for time series data with two feature sets.\n",
        "\n",
        "    Parameters:\n",
        "    - X1 (torch.Tensor): Primary dataset features.\n",
        "    - X2 (torch.Tensor): Secondary dataset features.\n",
        "    - y (torch.Tensor): Target variable.\n",
        "    \"\"\"\n",
        "    def __init__(self, X1, X2, y):\n",
        "        self.X1 = X1.float()\n",
        "        self.X2 = X2.float()\n",
        "        self.y = y.long()\n",
        "    def __len__(self):\n",
        "        return len(self.X1)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X1[idx], self.X2[idx], self.y[idx]\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = TimeSeriesDataset(X1_train_tensor, X2_train_tensor, y_train_tensor)\n",
        "test_dataset = TimeSeriesDataset(X1_test_tensor, X2_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class MatrixRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "\n",
        "    Parameters:\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, num_features, num_classes):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(1, num_securities))\n",
        "        self.B = nn.Parameter(torch.randn(num_features, num_classes))\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten over time\n",
        "        out = self.A @ x @ self.B  # Shape: (batch_size, num_classes)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_securities, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.linear = nn.Linear(input_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.linear(x)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "\n",
        "    Parameters:\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, window_size)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        out = x.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - hidden_size (int): Size of hidden state.\n",
        "    - num_layers (int): Number of LSTM layers.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_securities, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures global dependencies.\n",
        "    - Parallel computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Requires large datasets.\n",
        "    - Computationally intensive.\n",
        "\n",
        "    Parameters:\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.embedding = nn.Linear(num_features, 128)\n",
        "        self.pos_encoder = PositionalEncoding(128)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=2)\n",
        "        self.decoder = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), x.size(1), -1)  # (batch_size, window_size, num_features)\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # (sequence_length, batch_size, embedding_dim)\n",
        "        output = self.transformer_encoder(x)\n",
        "        output = output[-1, :, :]  # Last output\n",
        "        output = self.decoder(output)\n",
        "        output = output.view(-1, self.num_securities, self.num_classes)\n",
        "        return output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional Encoding for Transformer.\n",
        "\n",
        "    Adds positional information to the embeddings.\n",
        "\n",
        "    Parameters:\n",
        "    - d_model (int): Embedding dimension.\n",
        "    - max_len (int): Maximum sequence length.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        if d_model % 2 == 1:\n",
        "            pe[:, 1::2] = torch.sin(position * div_term)\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(1)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return x\n",
        "\n",
        "class SimpleRNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple Recurrent Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures sequential dependencies.\n",
        "    - Simpler than LSTM.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Struggles with long-term dependencies.\n",
        "    - May suffer from vanishing gradients.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - hidden_size (int): Size of hidden state.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_securities, num_classes):\n",
        "        super(SimpleRNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "# Missing Models with Docstrings and Comments\n",
        "\n",
        "class GNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures relationships between securities.\n",
        "    - Utilizes attention mechanisms.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Requires graph structure.\n",
        "\n",
        "    Parameters:\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_features_per_security (int): Features per security.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, num_features_per_security, num_classes):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        # Create a linear layer for each security\n",
        "        self.gcn_layers = nn.ModuleList([nn.Linear(num_features_per_security, 64) for _ in range(num_securities)])\n",
        "        # Multi-head attention mechanism\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=64, num_heads=4, batch_first=True)\n",
        "        # Fully connected layer for classification\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, window_size, num_features)\n",
        "        batch_size = x.size(0)\n",
        "        x = x[:, -1, :]  # Use the last time step\n",
        "        x = x.view(batch_size, self.num_securities, -1)  # (batch_size, num_securities, num_features_per_security)\n",
        "        node_embeddings = []\n",
        "        for i in range(self.num_securities):\n",
        "            h = self.gcn_layers[i](x[:, i, :])  # (batch_size, 64)\n",
        "            node_embeddings.append(h)\n",
        "        h = torch.stack(node_embeddings, dim=1)  # (batch_size, num_securities, 64)\n",
        "        # Apply attention mechanism\n",
        "        attn_output, _ = self.attention(h, h, h)\n",
        "        out = self.fc(attn_output)  # (batch_size, num_securities, num_classes)\n",
        "        return out\n",
        "\n",
        "class MambaModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Mamba Model: Combines CNN and LSTM architectures.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures both local and long-term dependencies.\n",
        "    - Utilizes CNN for feature extraction and LSTM for temporal patterns.\n",
        "\n",
        "    Disadvantages:\n",
        "    - More complex and computationally intensive.\n",
        "\n",
        "    Parameters:\n",
        "    - num_features (int): Total number of features.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(MambaModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        # Convolutional layer\n",
        "        self.cnn = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, batch_first=True)\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(128, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, window_size, num_features)\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, window_size)\n",
        "        x = F.relu(self.cnn(x))  # Apply CNN\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, new_window_size, channels)\n",
        "        h0 = torch.zeros(2, x.size(0), 128).to(x.device)  # Initial hidden state\n",
        "        c0 = torch.zeros(2, x.size(0), 128).to(x.device)  # Initial cell state\n",
        "        out, _ = self.lstm(x, (h0, c0))  # Apply LSTM\n",
        "        out = out[:, -1, :]  # Get the last output\n",
        "        out = self.fc(out)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class LiquidNetModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Liquid Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Dynamic adaptation to inputs.\n",
        "    - Good for time-series data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Relatively new, less tested.\n",
        "    - May be complex to tune.\n",
        "\n",
        "    Parameters:\n",
        "    - input_size (int): Size of input features.\n",
        "    - hidden_size (int): Size of hidden state.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_securities, num_classes):\n",
        "        super(LiquidNetModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        # RNN Cell with ReLU activation\n",
        "        self.rnn_cell = nn.RNNCell(input_size, hidden_size, nonlinearity='relu')\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "    def forward(self, x):\n",
        "        h_t = torch.zeros(x.size(0), self.rnn_cell.hidden_size).to(x.device)  # Initial hidden state\n",
        "        for t in range(x.size(1)):\n",
        "            h_t = self.rnn_cell(x[:, t, :], h_t)  # Update hidden state\n",
        "        out = self.fc(h_t)\n",
        "        out = out.view(-1, self.num_securities, self.num_classes)\n",
        "        return out\n",
        "\n",
        "class HiddenMarkovModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Hidden Markov Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Probabilistic approach.\n",
        "    - Good for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Simplified version here.\n",
        "    - May not capture complex patterns.\n",
        "\n",
        "    Parameters:\n",
        "    - num_states (int): Number of hidden states.\n",
        "    - num_securities (int): Number of securities.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_states, num_securities, num_classes):\n",
        "        super(HiddenMarkovModel, self).__init__()\n",
        "        self.num_states = num_states\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        # Start probabilities\n",
        "        self.start_prob = nn.Parameter(torch.randn(num_states))\n",
        "        # Transition probabilities\n",
        "        self.transition_prob = nn.Parameter(torch.randn(num_states, num_states))\n",
        "        # Emission probabilities\n",
        "        self.emission_prob = nn.Parameter(torch.randn(num_states, num_classes))\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        # Simplified; in practice, you'd implement the forward algorithm\n",
        "        out = torch.softmax(self.emission_prob, dim=1)\n",
        "        # Corrected repeat dimensions to match tensor dimensions\n",
        "        out = out.unsqueeze(0).unsqueeze(0).repeat(batch_size, self.num_securities, 1, 1)\n",
        "        # Since the model expects output shape (batch_size, num_securities, num_classes)\n",
        "        # We need to aggregate over the hidden states (num_states)\n",
        "        out = torch.mean(out, dim=2)  # Average over hidden states\n",
        "        return out\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined Model: Merges outputs from two models.\n",
        "\n",
        "    Advantages:\n",
        "    - Leverages multiple data sources.\n",
        "    - Potentially better performance.\n",
        "\n",
        "    Disadvantages:\n",
        "    - More complex.\n",
        "    - Computationally intensive.\n",
        "\n",
        "    Parameters:\n",
        "    - model1 (nn.Module): First model.\n",
        "    - model2 (nn.Module): Second model.\n",
        "    - num_classes (int): Number of target classes.\n",
        "    - num_securities (int): Number of securities.\n",
        "    \"\"\"\n",
        "    def __init__(self, model1, model2, num_classes, num_securities):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.model1 = model1\n",
        "        self.model2 = model2\n",
        "        self.fc = nn.Linear(num_classes * 2, num_classes)\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "    def forward(self, x1, x2):\n",
        "        outputs1 = self.model1(x1)\n",
        "        outputs2 = self.model2(x2)\n",
        "        outputs = torch.cat((outputs1, outputs2), dim=2)\n",
        "        batch_size = outputs.size(0)\n",
        "        outputs = outputs.view(-1, outputs.size(2))\n",
        "        final_output = self.fc(outputs)\n",
        "        final_output = final_output.view(batch_size, self.num_securities, -1)\n",
        "        return final_output\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs, device, writer):\n",
        "    \"\"\"\n",
        "    Training loop for the model.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to train.\n",
        "    - train_loader (DataLoader): DataLoader for training data.\n",
        "    - criterion (nn.Module): Loss function.\n",
        "    - optimizer (torch.optim.Optimizer): Optimizer.\n",
        "    - num_epochs (int): Number of epochs.\n",
        "    - device (torch.device): Computation device.\n",
        "    - writer (SummaryWriter): TensorBoard SummaryWriter.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    global_step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X1_batch, X2_batch, y_batch in train_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            loss = 0\n",
        "            for i in range(num_securities):\n",
        "                loss += criterion(outputs[:, i, :], y_batch[:, i])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            writer.add_scalar('Training Loss', loss.item(), global_step)\n",
        "            global_step += 1\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "        # Save checkpoint\n",
        "        torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pth')\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test set.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to evaluate.\n",
        "    - test_loader (DataLoader): DataLoader for test data.\n",
        "    - device (torch.device): Computation device.\n",
        "\n",
        "    Returns:\n",
        "    - float: Cohen's kappa score.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for X1_batch, X2_batch, y_batch in test_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            _, predicted = torch.max(outputs.data, 2)\n",
        "            total += y_batch.numel()\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy().flatten())\n",
        "            all_targets.extend(y_batch.cpu().numpy().flatten())\n",
        "    accuracy = 100 * correct / total\n",
        "    kappa = cohen_kappa_score(all_targets, all_preds)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
        "    print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
        "    return kappa\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Examples of combination models using the new models\n",
        "\n",
        "# Example 1: Combine GNNModel and TransformerModel\n",
        "print(\"\\nTraining Combined Model 1: GNNModel + TransformerModel\")\n",
        "model1 = GNNModel(num_securities=num_securities, num_features_per_security=num_features_per_security, num_classes=num_classes)\n",
        "model2 = TransformerModel(num_features=second_X_data.shape[1], num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 2: Combine MambaModel and LSTMModel\n",
        "print(\"\\nTraining Combined Model 2: MambaModel + LSTMModel\")\n",
        "model1 = MambaModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = LSTMModel(input_size=second_X_data.shape[1], hidden_size=64, num_layers=1, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 3: Combine LiquidNetModel and CNNModel\n",
        "print(\"\\nTraining Combined Model 3: LiquidNetModel + CNNModel\")\n",
        "model1 = LiquidNetModel(input_size=num_features, hidden_size=128, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = CNNModel(num_features=second_X_data.shape[1], num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 4: Combine HiddenMarkovModel and LogisticRegressionModel\n",
        "print(\"\\nTraining Combined Model 4: HiddenMarkovModel + LogisticRegressionModel\")\n",
        "model1 = HiddenMarkovModel(num_states=5, num_securities=num_securities, num_classes=num_classes)\n",
        "model2 = LogisticRegressionModel(input_size=second_X_data.shape[1]*window_size, num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()\n",
        "\n",
        "# Example 5: Combine GNNModel and MambaModel\n",
        "print(\"\\nTraining Combined Model 5: GNNModel + MambaModel\")\n",
        "model1 = GNNModel(num_securities=num_securities, num_features_per_security=num_features_per_security, num_classes=num_classes)\n",
        "model2 = MambaModel(num_features=second_X_data.shape[1], num_securities=num_securities, num_classes=num_classes)\n",
        "combined_model = CombinedModel(model1, model2, num_classes, num_securities)\n",
        "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "writer = SummaryWriter()\n",
        "train_model(combined_model, train_loader, criterion, optimizer, num_epochs=5, device=device, writer=writer)\n",
        "evaluate_model(combined_model, test_loader, device)\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO-t4USs2aJt",
        "outputId": "f80724fc-919c-4259-b170-1af79720cfa9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Combined Model 1: GNNModel + TransformerModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 11.0967\n",
            "Epoch [2/5], Loss: 11.0186\n",
            "Epoch [3/5], Loss: 11.0025\n",
            "Epoch [4/5], Loss: 10.9973\n",
            "Epoch [5/5], Loss: 10.9875\n",
            "Accuracy on test set: 33.69%\n",
            "Cohen's Kappa: 0.0052\n",
            "\n",
            "Training Combined Model 2: MambaModel + LSTMModel\n",
            "Epoch [1/5], Loss: 11.0083\n",
            "Epoch [2/5], Loss: 10.9869\n",
            "Epoch [3/5], Loss: 10.9811\n",
            "Epoch [4/5], Loss: 10.9745\n",
            "Epoch [5/5], Loss: 10.9668\n",
            "Accuracy on test set: 32.87%\n",
            "Cohen's Kappa: -0.0069\n",
            "\n",
            "Training Combined Model 3: LiquidNetModel + CNNModel\n",
            "Epoch [1/5], Loss: 11.0202\n",
            "Epoch [2/5], Loss: 10.9822\n",
            "Epoch [3/5], Loss: 10.9718\n",
            "Epoch [4/5], Loss: 10.9498\n",
            "Epoch [5/5], Loss: 10.9361\n",
            "Accuracy on test set: 33.54%\n",
            "Cohen's Kappa: 0.0026\n",
            "\n",
            "Training Combined Model 4: HiddenMarkovModel + LogisticRegressionModel\n",
            "Epoch [1/5], Loss: 11.0855\n",
            "Epoch [2/5], Loss: 10.9962\n",
            "Epoch [3/5], Loss: 10.9837\n",
            "Epoch [4/5], Loss: 10.9777\n",
            "Epoch [5/5], Loss: 10.9678\n",
            "Accuracy on test set: 33.48%\n",
            "Cohen's Kappa: 0.0018\n",
            "\n",
            "Training Combined Model 5: GNNModel + MambaModel\n",
            "Epoch [1/5], Loss: 11.0007\n",
            "Epoch [2/5], Loss: 10.9868\n",
            "Epoch [3/5], Loss: 10.9797\n",
            "Epoch [4/5], Loss: 10.9756\n",
            "Epoch [5/5], Loss: 10.9714\n",
            "Accuracy on test set: 33.46%\n",
            "Cohen's Kappa: 0.0014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... [Previous code remains the same up to model definitions]\n",
        "\n",
        "# Instantiate models for primary and second datasets\n",
        "print(\"Training Combined Model with Transformer and LSTM...\")\n",
        "\n",
        "# Primary model\n",
        "primary_model = TransformerModel(num_features=num_features, num_securities=num_securities, num_classes=num_classes)\n",
        "# Secondary model\n",
        "secondary_model = LSTMModel(input_size=second_input_size, hidden_size=128, num_layers=2, num_securities=num_securities, num_classes=num_classes)\n",
        "\n",
        "# Define final linear layer\n",
        "class FinalModel(nn.Module):\n",
        "    def __init__(self, num_classes, num_securities):\n",
        "        super(FinalModel, self).__init__()\n",
        "        self.fc = nn.Linear(num_classes * 2, num_classes)\n",
        "        self.num_securities = num_securities\n",
        "    def forward(self, outputs1, outputs2):\n",
        "        # Concatenate over class dimension\n",
        "        outputs = torch.cat((outputs1, outputs2), dim=2)\n",
        "        # Pass through linear layer\n",
        "        batch_size = outputs.size(0)\n",
        "        outputs = outputs.view(-1, outputs.size(2))\n",
        "        final_output = self.fc(outputs)\n",
        "        final_output = final_output.view(batch_size, self.num_securities, -1)\n",
        "        return final_output\n",
        "\n",
        "final_model = FinalModel(num_classes=num_classes, num_securities=num_securities)\n",
        "\n",
        "# Combine the parameters of all models\n",
        "params = list(primary_model.parameters()) + list(secondary_model.parameters()) + list(final_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
        "\n",
        "# Updated training function\n",
        "def train_model(model1, model2, final_model, train_loader, criterion, optimizer, num_epochs, device):\n",
        "    model1 = model1.to(device)\n",
        "    model2 = model2.to(device)\n",
        "    final_model = final_model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model1.train()\n",
        "        model2.train()\n",
        "        final_model.train()\n",
        "        total_loss = 0\n",
        "        for X1_batch, X2_batch, y_batch in train_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs1 = model1(X1_batch)\n",
        "            outputs2 = model2(X2_batch)\n",
        "            final_output = final_model(outputs1, outputs2)\n",
        "            loss = 0\n",
        "            for i in range(num_securities):\n",
        "                loss += criterion(final_output[:, i, :], y_batch[:, i])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "# Updated evaluation function\n",
        "def evaluate_model(model1, model2, final_model, test_loader, device):\n",
        "    model1 = model1.to(device)\n",
        "    model2 = model2.to(device)\n",
        "    final_model = final_model.to(device)\n",
        "    model1.eval()\n",
        "    model2.eval()\n",
        "    final_model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for X1_batch, X2_batch, y_batch in test_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs1 = model1(X1_batch)\n",
        "            outputs2 = model2(X2_batch)\n",
        "            final_output = final_model(outputs1, outputs2)\n",
        "            _, predicted = torch.max(final_output.data, 2)\n",
        "            total += y_batch.numel()\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
        "\n",
        "# Start training\n",
        "train_model(primary_model, secondary_model, final_model, train_loader, criterion, optimizer, num_epochs, device)\n",
        "evaluate_model(primary_model, secondary_model, final_model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_ZCKOPo0MRM",
        "outputId": "2c2878d8-a5ca-4030-feca-75735a27c6df"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Combined Model with Transformer and LSTM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 11.0751\n",
            "Epoch [2/5], Loss: 11.0117\n",
            "Epoch [3/5], Loss: 11.0131\n",
            "Epoch [4/5], Loss: 11.0011\n",
            "Epoch [5/5], Loss: 10.9982\n",
            "Accuracy on test set: 32.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mamba-ssm[dev]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q63BomR20ts",
        "outputId": "f589912b-c135-4cc5-d549-3c2747b33b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mamba-ssm[dev]\n",
            "  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m959.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: mamba-ssm 2.2.2 does not provide the extra 'dev'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm[dev]) (2.4.0+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm[dev]) (24.1)\n",
            "Collecting ninja (from mamba-ssm[dev])\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba-ssm[dev]) (0.8.0)\n",
            "Collecting triton (from mamba-ssm[dev])\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm[dev]) (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm[dev]) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm[dev]) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm[dev]) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm[dev]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm[dev]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm[dev]) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm[dev]) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm[dev]) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm[dev]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm[dev]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm[dev]) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm[dev]) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm[dev]) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm[dev]) (4.66.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm[dev]) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm[dev]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm[dev]) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm[dev]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm[dev]) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm[dev]) (1.3.0)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mamba-ssm\n",
            "  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.2-cp310-cp310-linux_x86_64.whl size=323988104 sha256=6b082468a6abb6f6bc50c99263f17c6c7f5a2e8f6b275ed7998b81fb25279229\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/7c/90/9f963468ecc3791e36e388f9e7b4a4e1e3f90fbb340055aa4d\n",
            "Successfully built mamba-ssm\n",
            "Installing collected packages: ninja, triton, mamba-ssm\n",
            "Successfully installed mamba-ssm-2.2.2 ninja-1.11.1.1 triton-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class HiddenMarkovModel(nn.Module):\n",
        "    def __init__(self, num_states, num_securities, num_classes, num_features_per_security):\n",
        "        super(HiddenMarkovModel, self).__init__()\n",
        "        self.num_states = num_states\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.num_features_per_security = num_features_per_security\n",
        "\n",
        "        # Define parameters for start, transition, and emission probabilities\n",
        "        self.start_logits = nn.Parameter(torch.randn(num_securities, num_states))\n",
        "        self.trans_logits = nn.Parameter(torch.randn(num_securities, num_states, num_states))\n",
        "        self.emission_logits = nn.Parameter(torch.randn(num_securities, num_states, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, window_size, num_features)\n",
        "        batch_size, window_size, num_features = x.size()\n",
        "        device = x.device\n",
        "\n",
        "        # Reshape x to separate securities\n",
        "        x = x.view(batch_size, window_size, self.num_securities, self.num_features_per_security)\n",
        "        # For simplicity, we'll use the last time step\n",
        "        x_last = x[:, -1, :, :]  # Shape: (batch_size, num_securities, num_features_per_security)\n",
        "\n",
        "        # We'll compute the logits for each class per security\n",
        "        # For this simplified HMM, we'll combine start and emission logits to produce class logits\n",
        "        outputs = []\n",
        "        for s in range(self.num_securities):\n",
        "            # Compute the log probabilities for each class\n",
        "            # We use log-sum-exp over the states to compute the logits for each class\n",
        "            # start_logits[s]: (num_states,)\n",
        "            # emission_logits[s]: (num_states, num_classes)\n",
        "            start_log_probs = self.start_logits[s]  # (num_states,)\n",
        "            emission_log_probs = self.emission_logits[s]  # (num_states, num_classes)\n",
        "\n",
        "            # Compute logits for classes\n",
        "            logits = torch.logsumexp(start_log_probs.unsqueeze(1) + emission_log_probs, dim=0)  # (num_classes,)\n",
        "            outputs.append(logits.unsqueeze(0))  # (1, num_classes)\n",
        "\n",
        "        # Stack outputs over securities and expand to batch size\n",
        "        outputs = torch.cat(outputs, dim=0)  # (num_securities, num_classes)\n",
        "        outputs = outputs.unsqueeze(0).expand(batch_size, -1, -1)  # (batch_size, num_securities, num_classes)\n",
        "\n",
        "        return outputs  # Shape: (batch_size, num_securities, num_classes)\n",
        "\n",
        "\n",
        "# Adjusted training loop for HMM with continuous emissions\n",
        "def train_hmm_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
        "    model = model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for _, _, y_batch in train_loader:\n",
        "            y_batch = y_batch.to(device)  # Shape: (batch_size, num_securities)\n",
        "            y_batch = y_batch.unsqueeze(1).expand(-1, window_size, -1)  # (batch_size, window_size, num_securities)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(y_batch)  # outputs shape: (batch_size, window_size, num_securities)\n",
        "            loss = criterion(outputs.view(-1), torch.zeros_like(outputs.view(-1)))  # Dummy target\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "# Mamba Model Integration\n",
        "# Since you will install the Mamba package, we'll import and use it directly\n",
        "try:\n",
        "    from mamba_ssm.modules.mamba2 import Mamba2\n",
        "except ImportError:\n",
        "    raise ImportError(\"Please install the mamba_ssm package to use the MambaModel.\")\n",
        "\n",
        "class MambaModel(nn.Module):\n",
        "    def __init__(self, num_features, num_securities, num_classes):\n",
        "        super(MambaModel, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.mamba = Mamba2(\n",
        "            d_model=num_features,\n",
        "            d_state=64,\n",
        "            d_conv=4,\n",
        "            expand=2,\n",
        "        )\n",
        "\n",
        "        # Final linear layer to map to the desired output size\n",
        "        self.fc = nn.Linear(num_features, num_securities * num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, window_size, num_features)\n",
        "        batch_size = x.size(0)\n",
        "        x = x.view(batch_size, -1, x.size(-1))  # Ensure proper shape\n",
        "        y = self.mamba(x)\n",
        "        y = self.fc(y[:, -1, :])  # Use the last time step\n",
        "        y = y.view(batch_size, self.num_securities, self.num_classes)\n",
        "        return y\n",
        "\n"
      ],
      "metadata": {
        "id": "DG5yBaKs2x73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_single_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
        "    model = model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, _, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = 0\n",
        "            for i in range(num_securities):\n",
        "                loss += criterion(outputs[:, i, :], y_batch[:, i])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "def evaluate_single_model(model, test_loader, device):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, _, y_batch in test_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            _, predicted = torch.max(outputs.data, 2)\n",
        "            total += y_batch.numel()\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "fZgoErtS708b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and train Hidden Markov Model\n",
        "print(\"\\nTraining Hidden Markov Model...\")\n",
        "num_states = 5  # Number of hidden states\n",
        "\n",
        "hmm_model = HiddenMarkovModel(\n",
        "    num_states=num_states,\n",
        "    num_securities=num_securities,\n",
        "    num_classes=num_classes,\n",
        "    num_features_per_security=num_features//num_securities,\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(hmm_model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_single_model(hmm_model, train_loader, criterion, optimizer, num_epochs, device)\n",
        "evaluate_single_model(hmm_model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJU9C_j97QJN",
        "outputId": "c828d9d5-f237-4cbb-f166-7a8314da7b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Hidden Markov Model...\n",
            "Epoch [1/5], Loss: 11.9516\n",
            "Epoch [2/5], Loss: 11.0472\n",
            "Epoch [3/5], Loss: 10.9873\n",
            "Epoch [4/5], Loss: 10.9865\n",
            "Epoch [5/5], Loss: 10.9865\n",
            "Accuracy on test set: 33.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModelData2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_securities, num_classes):\n",
        "        super(LSTMModelData2, self).__init__()\n",
        "        self.num_securities = num_securities\n",
        "        self.num_classes = num_classes\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_securities * num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        h0 = torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])  # Use the last time step\n",
        "        out = out.view(batch_size, self.num_securities, self.num_classes)\n",
        "        return out"
      ],
      "metadata": {
        "id": "8P0vjHUM9YBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, X1, X2, y):\n",
        "        self.X1 = X1.float()\n",
        "        self.X2 = X2.float()\n",
        "        self.y = y.long()\n",
        "    def __len__(self):\n",
        "        return len(self.X1)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X1[idx], self.X2[idx], self.y[idx]\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = TimeSeriesDataset(X1_train_tensor, X2_train_tensor, y_train_tensor)\n",
        "test_dataset = TimeSeriesDataset(X1_test_tensor, X2_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "7BEaWLS58CZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, model1, model2):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.model1 = model1  # HMM for data1\n",
        "        self.model2 = model2  # LSTM for data2\n",
        "        self.num_securities = model1.num_securities\n",
        "        self.num_classes = model1.num_classes\n",
        "        # Final linear layer to combine the outputs\n",
        "        self.fc = nn.Linear(self.num_classes * 2, self.num_classes)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # x1: Input for data1 (HMM)\n",
        "        # x2: Input for data2 (LSTM)\n",
        "        outputs1 = self.model1(x1)  # (batch_size, num_securities, num_classes)\n",
        "        outputs2 = self.model2(x2)  # (batch_size, num_securities, num_classes)\n",
        "        # Concatenate the outputs over the class dimension\n",
        "        combined_outputs = torch.cat((outputs1, outputs2), dim=2)  # (batch_size, num_securities, num_classes * 2)\n",
        "        # Pass through the final linear layer\n",
        "        final_outputs = self.fc(combined_outputs)  # (batch_size, num_securities, num_classes)\n",
        "        return final_outputs"
      ],
      "metadata": {
        "id": "VVNbSMbG9gwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_combined_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
        "    model = model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X1_batch, X2_batch, y_batch in train_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            loss = 0\n",
        "            for i in range(model.num_securities):\n",
        "                loss += criterion(outputs[:, i, :], y_batch[:, i])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "def evaluate_combined_model(model, test_loader, device):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for X1_batch, X2_batch, y_batch in test_loader:\n",
        "            X1_batch = X1_batch.to(device)\n",
        "            X2_batch = X2_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs = model(X1_batch, X2_batch)\n",
        "            _, predicted = torch.max(outputs.data, 2)\n",
        "            total += y_batch.numel()\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "gV51uE6i9sA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_states = 5  # Number of hidden states\n",
        "hmm_model = HiddenMarkovModel(\n",
        "    num_states=num_states,\n",
        "    num_securities=num_securities,\n",
        "    num_classes=num_classes,\n",
        "    num_features_per_security=num_features_per_security,\n",
        ")\n",
        "\n",
        "# LSTM for data2\n",
        "input_size_data2 = X2_train_tensor.size(2)  # Number of features for data2\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "lstm_model_data2 = LSTMModelData2(\n",
        "    input_size=input_size_data2,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    num_securities=num_securities,\n",
        "    num_classes=num_classes,\n",
        ")\n",
        "\n",
        "# Combined model\n",
        "combined_model = CombinedModel(hmm_model, lstm_model_data2)\n",
        "\n",
        "# Combine parameters for optimization\n",
        "params = list(combined_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
        "\n",
        "# Train the combined model\n",
        "train_combined_model(combined_model, train_loader, criterion, optimizer, num_epochs, device)\n",
        "evaluate_combined_model(combined_model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSu4WIrD53xB",
        "outputId": "f7a9a29c-6884-4323-edd3-ca67ff515986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 33.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Time2Vec implementation\n",
        "class Time2Vec(nn.Module):\n",
        "    def __init__(self, seq_len, d_model):\n",
        "        super(Time2Vec, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.d_model = d_model\n",
        "        self.w0 = nn.Parameter(torch.randn(1))\n",
        "        self.b0 = nn.Parameter(torch.randn(1))\n",
        "        self.w = nn.Parameter(torch.randn(d_model - 1))\n",
        "        self.b = nn.Parameter(torch.randn(d_model - 1))\n",
        "\n",
        "    def forward(self, batch_size):\n",
        "        # Create time indices\n",
        "        t = torch.arange(self.seq_len).unsqueeze(-1).float().to(self.w0.device)  # Shape: (seq_len, 1)\n",
        "        # Linear component\n",
        "        v = self.w0 * t + self.b0  # Shape: (seq_len, 1)\n",
        "        # Periodic component\n",
        "        vp = torch.sin(self.w * t + self.b)  # Broadcasting over (seq_len, d_model - 1)\n",
        "        # Concatenate components\n",
        "        time_emb = torch.cat([v, vp], dim=-1)  # Shape: (seq_len, d_model)\n",
        "        # Expand to match batch size\n",
        "        time_emb = time_emb.unsqueeze(0).expand(batch_size, -1, -1)  # Shape: (batch_size, seq_len, d_model)\n",
        "        return time_emb\n",
        "\n",
        "# Corrected Multi-Head Attention Mechanism\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.out_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        batch_size = q.size(0)\n",
        "\n",
        "        # Perform linear projections and split into heads\n",
        "        q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1,2)\n",
        "        k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1,2)\n",
        "        v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1,2)\n",
        "\n",
        "        # Calculate attention scores\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # Concatenate heads\n",
        "        context = context.transpose(1,2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
        "        output = self.out_linear(context)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Corrected Gated Residual Network\n",
        "class GatedResidualNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GatedResidualNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.elu = nn.ELU()\n",
        "        self.fc2 = nn.Linear(hidden_size, 2 * input_size)  # Output size doubled for GLU\n",
        "        self.glu = nn.GLU(dim=-1)  # Splits last dimension into two halves\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.fc1(x)\n",
        "        x = self.elu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.glu(x)\n",
        "        return residual + x\n",
        "\n",
        "# Corrected Transformer Encoder Block\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, hidden_size):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.grn = GatedResidualNetwork(d_model, hidden_size)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attn_output = self.attention(x, x, x, mask)\n",
        "        x = self.norm1(x + attn_output)\n",
        "        grn_output = self.grn(x)\n",
        "        x = self.norm2(x + grn_output)\n",
        "        return x\n",
        "\n",
        "# Corrected Transformer Decoder Block\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, hidden_size):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.grn = GatedResidualNetwork(d_model, hidden_size)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
        "        # Self-attention with masking\n",
        "        attn_output = self.self_attention(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + attn_output)\n",
        "\n",
        "        # Cross-attention with encoder outputs\n",
        "        attn_output = self.cross_attention(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + attn_output)\n",
        "\n",
        "        # Apply GRN and residual connection\n",
        "        grn_output = self.grn(x)\n",
        "        x = self.norm3(x + grn_output)\n",
        "        return x\n",
        "\n",
        "# Corrected Portfolio Transformer Model\n",
        "class PortfolioTransformer(nn.Module):\n",
        "    def __init__(self, num_assets, d_model, num_heads, hidden_size, num_layers, seq_len):\n",
        "        super(PortfolioTransformer, self).__init__()\n",
        "        self.num_assets = num_assets\n",
        "        self.d_model = d_model\n",
        "        self.seq_len = seq_len\n",
        "        self.input_proj = nn.Linear(num_assets, d_model)\n",
        "        self.time2vec = Time2Vec(seq_len, d_model)\n",
        "        self.encoder_layers = nn.ModuleList(\n",
        "            [TransformerEncoder(d_model, num_heads, hidden_size) for _ in range(num_layers)]\n",
        "        )\n",
        "        self.decoder_layers = nn.ModuleList(\n",
        "            [TransformerDecoder(d_model, num_heads, hidden_size) for _ in range(num_layers)]\n",
        "        )\n",
        "        self.fc_out = nn.Linear(d_model, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, num_assets)\n",
        "        batch_size = x.size(0)\n",
        "        # Project input features to d_model\n",
        "        x_proj = self.input_proj(x)  # Shape: (batch_size, seq_len, d_model)\n",
        "        # Get time embeddings\n",
        "        time_emb = self.time2vec(batch_size)  # Shape: (batch_size, seq_len, d_model)\n",
        "        # Combine input embeddings and time embeddings\n",
        "        x = x_proj + time_emb  # Element-wise addition\n",
        "        # Encoder\n",
        "        for encoder in self.encoder_layers:\n",
        "            x = encoder(x)\n",
        "        # Decoder\n",
        "        dec_input = x\n",
        "        for decoder in self.decoder_layers:\n",
        "            x = decoder(dec_input, x)\n",
        "        s_i_t = self.fc_out(x)  # Output shape: (batch_size, seq_len, num_assets)\n",
        "        # Compute weights using the compound function\n",
        "        weights = torch.sign(s_i_t) * torch.softmax(torch.abs(s_i_t), dim=-1)\n",
        "        return weights"
      ],
      "metadata": {
        "id": "R6sf3SVposU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Generate random returns data: 100 securities over 1000 time steps\n",
        "num_securities = 100\n",
        "num_time_steps = 1000\n",
        "np.random.seed(42)  # For reproducibility\n",
        "\n",
        "# Simulate random returns\n",
        "returns_data = np.random.randn(num_time_steps, num_securities) * 0.01  # Small random returns\n",
        "prices = 100 + np.cumsum(returns_data, axis=0)  # Simulate price paths\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "prices = torch.tensor(prices, dtype=torch.float32)\n",
        "returns = torch.tensor(returns_data, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "BrPdsSy0o3YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Prepare the dataset\n",
        "sequence_length = 20  # Use last 20 days for prediction\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(len(prices) - sequence_length):\n",
        "    X.append(returns[i:i+sequence_length])\n",
        "    y.append(returns[i+sequence_length])\n",
        "\n",
        "X = torch.stack(X)  # Shape: (num_samples, seq_len, num_assets)\n",
        "y = torch.stack(y)  # Shape: (num_samples, num_assets)\n",
        "\n",
        "dataset = TensorDataset(X, y)\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Initialize the model\n",
        "num_assets = num_securities\n",
        "model = PortfolioTransformer(\n",
        "    num_assets=num_assets, d_model=64, num_heads=8, hidden_size=128, num_layers=4, seq_len=sequence_length\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "def train(model, optimizer, data_loader, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            portfolio_weights = model(batch_X)  # Output shape: (batch_size, seq_len, num_assets)\n",
        "            # Use the last time step's weights\n",
        "            portfolio_weights = portfolio_weights[:, -1, :]  # Shape: (batch_size, num_assets)\n",
        "            # Compute portfolio returns\n",
        "            portfolio_returns = torch.sum(portfolio_weights * batch_y, dim=1)\n",
        "            loss = sharpe_loss(portfolio_returns)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(data_loader):.4f}\")\n",
        "\n",
        "# Loss function (Negative Sharpe Ratio)\n",
        "def sharpe_loss(portfolio_returns, risk_free_rate=0.0):\n",
        "    # Assuming daily returns, annualize by multiplying by sqrt(252)\n",
        "    mean_return = torch.mean(portfolio_returns)\n",
        "    std_return = torch.std(portfolio_returns)\n",
        "    sharpe_ratio = (mean_return - risk_free_rate) / (std_return + 1e-6)\n",
        "    return -sharpe_ratio  # Negative for minimization\n",
        "\n",
        "# Train the model\n",
        "train(model, optimizer, data_loader, num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTj0mZgqo5xO",
        "outputId": "63031279-68ff-4f96-d549-40a0bf1d73f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.0155\n",
            "Epoch 2/10, Loss: -0.1249\n",
            "Epoch 3/10, Loss: -0.1783\n",
            "Epoch 4/10, Loss: -0.2097\n",
            "Epoch 5/10, Loss: -0.2230\n",
            "Epoch 6/10, Loss: -0.2474\n",
            "Epoch 7/10, Loss: -0.2255\n",
            "Epoch 8/10, Loss: -0.2514\n",
            "Epoch 9/10, Loss: -0.2554\n",
            "Epoch 10/10, Loss: -0.2540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## version 2"
      ],
      "metadata": {
        "id": "1lzRyXdVtM2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Advanced Time Encoding: Learnable Positional Encoding\n",
        "class LearnablePositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements learnable positional encoding for sequences.\n",
        "\n",
        "    Args:\n",
        "        seq_len (int): The maximum length of the input sequences.\n",
        "        d_model (int): The dimension of the model.\n",
        "    \"\"\"\n",
        "    def __init__(self, seq_len, d_model):\n",
        "        super(LearnablePositionalEncoding, self).__init__()\n",
        "        self.position_embeddings = nn.Embedding(seq_len, d_model)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass for positional encoding.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor of shape (batch_size, seq_len, d_model).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Positionally encoded tensor.\n",
        "        \"\"\"\n",
        "        positions = torch.arange(0, self.seq_len, device=x.device).unsqueeze(0)\n",
        "        pos_embed = self.position_embeddings(positions)\n",
        "        x = x + pos_embed\n",
        "        return x\n",
        "\n",
        "# PortfolioTransformer using PyTorch's nn.Transformer\n",
        "class PortfolioTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Portfolio Transformer model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets in the portfolio.\n",
        "        d_model (int): Dimension of the model.\n",
        "        nhead (int): Number of attention heads.\n",
        "        num_layers (int): Number of transformer encoder layers.\n",
        "        seq_len (int): Length of the input sequences.\n",
        "        dropout (float): Dropout probability.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, num_assets, d_model, nhead, num_layers, seq_len, dropout=0.1\n",
        "    ):\n",
        "        super(PortfolioTransformer, self).__init__()\n",
        "        self.num_assets = num_assets\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Input projection layer to map asset returns to model dimension\n",
        "        self.input_proj = nn.Linear(num_assets, d_model)\n",
        "\n",
        "        # Learnable positional encoding\n",
        "        self.pos_encoder = LearnablePositionalEncoding(seq_len, d_model)\n",
        "\n",
        "        # Transformer encoder layers\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layers, num_layers=num_layers\n",
        "        )\n",
        "\n",
        "        # Output layer to map back to asset space\n",
        "        self.fc_out = nn.Linear(d_model, num_assets)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"\n",
        "        Initializes weights for better convergence.\n",
        "        \"\"\"\n",
        "        initrange = 0.1\n",
        "        self.input_proj.weight.data.uniform_(-initrange, initrange)\n",
        "        self.input_proj.bias.data.zero_()\n",
        "        self.fc_out.bias.data.zero_()\n",
        "        self.fc_out.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor of shape (batch_size, seq_len, num_assets).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Portfolio weights of shape (batch_size, seq_len, num_assets).\n",
        "        \"\"\"\n",
        "        # Project input to model dimension and scale\n",
        "        x = self.input_proj(x) * np.sqrt(self.d_model)\n",
        "        # Add positional encoding\n",
        "        x = self.pos_encoder(x)\n",
        "        # Pass through transformer encoder\n",
        "        x = self.transformer_encoder(x)\n",
        "        # Map back to asset space\n",
        "        s_i_t = self.fc_out(x)  # Shape: (batch_size, seq_len, num_assets)\n",
        "        # Apply activation and normalize weights\n",
        "        weights = torch.tanh(s_i_t)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=-1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "def sharpe_loss(\n",
        "    portfolio_returns, portfolio_weights, prev_weights, transaction_cost=0.0002\n",
        "):\n",
        "    \"\"\"\n",
        "    Computes the negative Sharpe ratio as the loss function, including transaction costs.\n",
        "\n",
        "    Args:\n",
        "        portfolio_returns (Tensor): Portfolio returns of shape (batch_size,).\n",
        "        portfolio_weights (Tensor): Current portfolio weights of shape (batch_size, num_assets).\n",
        "        prev_weights (Tensor): Previous portfolio weights of shape (batch_size, num_assets).\n",
        "        transaction_cost (float): Transaction cost rate per unit weight change.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Loss value (negative Sharpe ratio).\n",
        "    \"\"\"\n",
        "    # Compute transaction costs based on weight changes\n",
        "    tc = transaction_cost * torch.sum(torch.abs(portfolio_weights - prev_weights), dim=1)\n",
        "    # Net returns after subtracting transaction costs\n",
        "    net_returns = portfolio_returns - tc\n",
        "    # Compute mean and standard deviation of returns\n",
        "    mean_return = torch.mean(net_returns)\n",
        "    std_return = torch.std(net_returns)\n",
        "    # Compute Sharpe ratio\n",
        "    sharpe_ratio = mean_return / (std_return + 1e-6)\n",
        "    # Return negative Sharpe ratio for minimization\n",
        "    return -sharpe_ratio\n",
        "\n",
        "def compute_expected_time_to_target(portfolio_returns, target_sharpe, window=20):\n",
        "    \"\"\"\n",
        "    Estimates the expected time to reach the target Sharpe ratio.\n",
        "\n",
        "    Args:\n",
        "        portfolio_returns (list): List of past portfolio returns.\n",
        "        target_sharpe (float): Target Sharpe ratio.\n",
        "        window (int): Window size for rolling calculation.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Estimated time to reach the target Sharpe ratio.\n",
        "    \"\"\"\n",
        "    # If insufficient data, return zero\n",
        "    if len(portfolio_returns) < window:\n",
        "        return torch.tensor(0.0)\n",
        "    # Compute rolling mean and std\n",
        "    recent_returns = torch.tensor(portfolio_returns[-window:])\n",
        "    rolling_returns = torch.mean(recent_returns)\n",
        "    rolling_std = torch.std(recent_returns)\n",
        "    rolling_sharpe = rolling_returns / (rolling_std + 1e-6)\n",
        "    # Estimate time to target\n",
        "    if rolling_sharpe >= target_sharpe:\n",
        "        time_to_target = torch.tensor(0.0)\n",
        "    else:\n",
        "        # Simplified estimation\n",
        "        time_to_target = (target_sharpe - rolling_sharpe) * window\n",
        "    return time_to_target\n",
        "\n",
        "def adjust_position_scaling(portfolio_weights, time_to_target, scaling_factor=0.1):\n",
        "    \"\"\"\n",
        "    Adjusts position scaling based on the estimated time to target Sharpe ratio.\n",
        "\n",
        "    Args:\n",
        "        portfolio_weights (Tensor): Current portfolio weights.\n",
        "        time_to_target (Tensor): Estimated time to reach target Sharpe ratio.\n",
        "        scaling_factor (float): Factor to control scaling sensitivity.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Adjusted portfolio weights.\n",
        "    \"\"\"\n",
        "    # Compute scaling coefficient\n",
        "    scaling = 1.0 - scaling_factor * torch.sigmoid(time_to_target)\n",
        "    # Adjust portfolio weights\n",
        "    adjusted_weights = portfolio_weights * scaling\n",
        "    return adjusted_weights\n",
        "\n",
        "def train(model, optimizer, data_loader, num_epochs, target_sharpe=1.0):\n",
        "    \"\"\"\n",
        "    Trains the PortfolioTransformer model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PortfolioTransformer model.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer.\n",
        "        data_loader (DataLoader): DataLoader for training data.\n",
        "        num_epochs (int): Number of training epochs.\n",
        "        target_sharpe (float): Target Sharpe ratio for scaling positions.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    portfolio_returns_history = []\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass to get portfolio weights\n",
        "            portfolio_weights = model(batch_X)\n",
        "            # Use the last time step's weights\n",
        "            portfolio_weights = portfolio_weights[:, -1, :]\n",
        "            # Initialize prev_weights with zeros matching portfolio_weights\n",
        "            prev_weights = torch.zeros_like(portfolio_weights)\n",
        "            # Compute portfolio returns\n",
        "            portfolio_returns = torch.sum(portfolio_weights * batch_y, dim=1)\n",
        "            # Adjust positions based on expected time to target\n",
        "            time_to_target = compute_expected_time_to_target(\n",
        "                portfolio_returns_history, target_sharpe\n",
        "            )\n",
        "            portfolio_weights = adjust_position_scaling(\n",
        "                portfolio_weights, time_to_target\n",
        "            )\n",
        "            # Update returns history\n",
        "            portfolio_returns_history.extend(portfolio_returns.tolist())\n",
        "            # Compute loss with transaction costs\n",
        "            loss = sharpe_loss(portfolio_returns, portfolio_weights, prev_weights)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            # Update prev_weights for the next batch\n",
        "            prev_weights = portfolio_weights.detach()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(data_loader):.4f}\")\n",
        "\n",
        "def backtest(model, data, train_size, test_size, sequence_length, target_sharpe=1.0):\n",
        "    \"\"\"\n",
        "    Performs backtesting by training on a subset of data and testing on future data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PortfolioTransformer model.\n",
        "        data (Tensor): Asset returns data.\n",
        "        train_size (int): Number of samples for training.\n",
        "        test_size (int): Number of samples for testing.\n",
        "        sequence_length (int): Length of input sequences.\n",
        "        target_sharpe (float): Target Sharpe ratio for scaling positions.\n",
        "    \"\"\"\n",
        "    num_samples = len(data) - sequence_length\n",
        "    train_indices = range(train_size)\n",
        "    test_indices = range(train_size, train_size + test_size)\n",
        "\n",
        "    # Prepare training data\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for i in train_indices:\n",
        "        X_train.append(data[i:i+sequence_length])\n",
        "        y_train.append(data[i+sequence_length])\n",
        "    X_train = torch.stack(X_train)\n",
        "    y_train = torch.stack(y_train)\n",
        "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Prepare test data\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    for i in test_indices:\n",
        "        X_test.append(data[i:i+sequence_length])\n",
        "        y_test.append(data[i+sequence_length])\n",
        "    X_test = torch.stack(X_test)\n",
        "    y_test = torch.stack(y_test)\n",
        "\n",
        "    # Train the model\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "    train(model, optimizer, train_loader, num_epochs=10, target_sharpe=target_sharpe)\n",
        "\n",
        "    # Backtest on test data\n",
        "    model.eval()\n",
        "    prev_weights = torch.zeros(y_test.size(1))\n",
        "    portfolio_returns_history = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(X_test)):\n",
        "            batch_X = X_test[i:i+1]  # Shape: (1, seq_len, num_assets)\n",
        "            batch_y = y_test[i:i+1]  # Shape: (1, num_assets)\n",
        "            # Get portfolio weights\n",
        "            portfolio_weights = model(batch_X)\n",
        "            portfolio_weights = portfolio_weights[:, -1, :]\n",
        "            # Compute portfolio returns\n",
        "            portfolio_returns = torch.sum(portfolio_weights * batch_y, dim=1)\n",
        "            # Adjust positions based on expected time to target\n",
        "            time_to_target = compute_expected_time_to_target(\n",
        "                portfolio_returns_history, target_sharpe=target_sharpe\n",
        "            )\n",
        "            portfolio_weights = adjust_position_scaling(\n",
        "                portfolio_weights, time_to_target\n",
        "            )\n",
        "            # Update returns history\n",
        "            portfolio_returns_history.extend(portfolio_returns.tolist())\n",
        "            # Update prev_weights\n",
        "            prev_weights = portfolio_weights.detach()\n",
        "        # Compute cumulative returns and Sharpe ratio\n",
        "        portfolio_returns = np.array(portfolio_returns_history)\n",
        "        cumulative_returns = np.cumprod(1 + portfolio_returns) - 1\n",
        "        mean_return = np.mean(portfolio_returns)\n",
        "        std_return = np.std(portfolio_returns)\n",
        "        sharpe_ratio = mean_return / (std_return + 1e-6) * np.sqrt(252)\n",
        "        print(f\"Cumulative Return: {cumulative_returns[-1]:.4f}\")\n",
        "        print(f\"Annualized Sharpe Ratio: {sharpe_ratio:.4f}\")"
      ],
      "metadata": {
        "id": "udFpzIeosoq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Generate random returns data: 100 securities over 1000 time steps\n",
        "num_securities = 100\n",
        "num_time_steps = 1000\n",
        "\n",
        "# Simulate random returns (e.g., normally distributed with small mean and std)\n",
        "returns_data = np.random.normal(loc=0.001, scale=0.01, size=(num_time_steps, num_securities))\n",
        "returns = torch.tensor(returns_data, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "Qmk8tSvSswV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "sequence_length = 20\n",
        "train_size = 700\n",
        "test_size = 200\n",
        "num_assets = num_securities\n",
        "\n",
        "# Initialize the model\n",
        "model = PortfolioTransformer(\n",
        "    num_assets=num_assets,\n",
        "    d_model=64,\n",
        "    nhead=8,\n",
        "    num_layers=4,\n",
        "    seq_len=sequence_length,\n",
        "    dropout=0.1\n",
        ")\n",
        "\n",
        "# Run backtest\n",
        "backtest(model, returns, train_size, test_size, sequence_length, target_sharpe=1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRQEHmx-s2Lt",
        "outputId": "968a8d84-fb43-4a7a-cec6-66b7d2efa499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: -0.4861\n",
            "Epoch 2/10, Loss: -0.7983\n",
            "Epoch 3/10, Loss: -0.8931\n",
            "Epoch 4/10, Loss: -0.9067\n",
            "Epoch 5/10, Loss: -0.9006\n",
            "Epoch 6/10, Loss: -0.9224\n",
            "Epoch 7/10, Loss: -0.9115\n",
            "Epoch 8/10, Loss: -0.9196\n",
            "Epoch 9/10, Loss: -0.9191\n",
            "Epoch 10/10, Loss: -0.9201\n",
            "Cumulative Return: 0.2299\n",
            "Annualized Sharpe Ratio: 12.6064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "# Parameters\n",
        "num_timesteps = 5000  # Total number of time steps\n",
        "num_assets = 10       # Number of assets in the portfolio\n",
        "seq_len = 20          # Length of input sequences\n",
        "d_model = 64          # Model dimension for Transformer\n",
        "batch_size = 64       # Batch size for training\n",
        "num_epochs = 5        # Number of training epochs\n",
        "\n",
        "# Generate synthetic returns data\n",
        "np.random.seed(42)\n",
        "returns_data = np.random.normal(0, 0.01, size=(num_timesteps, num_assets)).astype(np.float32)\n",
        "returns_data = torch.tensor(returns_data)\n",
        "\n",
        "# Dataset and DataLoader for training\n",
        "class ReturnsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for asset returns.\n",
        "\n",
        "    Args:\n",
        "        data (Tensor): Asset returns data of shape (num_timesteps, num_assets).\n",
        "        seq_len (int): Length of input sequences.\n",
        "    \"\"\"\n",
        "    def __init__(self, data, seq_len):\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.data[idx:idx + self.seq_len]\n",
        "        y = self.data[idx + self.seq_len]\n",
        "        return X, y\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(returns_data) * train_ratio)\n",
        "train_data = returns_data[:train_size]\n",
        "test_data = returns_data[train_size:]\n",
        "\n",
        "train_dataset = ReturnsDataset(train_data, seq_len)\n",
        "test_dataset = ReturnsDataset(test_data, seq_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Loss function: Negative Sharpe Ratio\n",
        "def sharpe_loss(portfolio_returns, portfolio_weights, prev_weights, transaction_cost=0.0002):\n",
        "    \"\"\"\n",
        "    Computes the negative Sharpe ratio as the loss function, including transaction costs.\n",
        "\n",
        "    Args:\n",
        "        portfolio_returns (Tensor): Portfolio returns of shape (batch_size,).\n",
        "        portfolio_weights (Tensor): Current portfolio weights of shape (batch_size, num_assets).\n",
        "        prev_weights (Tensor): Previous portfolio weights of shape (batch_size, num_assets).\n",
        "        transaction_cost (float): Transaction cost rate per unit weight change.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Loss value (negative Sharpe ratio).\n",
        "    \"\"\"\n",
        "    # Compute transaction costs based on weight changes\n",
        "    tc = transaction_cost * torch.sum(torch.abs(portfolio_weights - prev_weights), dim=1)\n",
        "    # Net returns after subtracting transaction costs\n",
        "    net_returns = portfolio_returns - tc\n",
        "    # Compute mean and standard deviation of returns\n",
        "    mean_return = torch.mean(net_returns)\n",
        "    std_return = torch.std(net_returns)\n",
        "    # Compute Sharpe ratio\n",
        "    sharpe_ratio = mean_return / (std_return + 1e-6)\n",
        "    # Return negative Sharpe ratio for minimization\n",
        "    return -sharpe_ratio\n",
        "\n",
        "# Base class for models\n",
        "class BaseModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Base class for asset allocation models.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets in the portfolio.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.num_assets = num_assets\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor of shape (batch_size, seq_len, num_assets).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Portfolio weights of shape (batch_size, num_assets).\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Logistic Regression Model\n",
        "class LogisticRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of input features (seq_len * num_assets).\n",
        "        num_assets (int): Number of assets.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_assets):\n",
        "        super(LogisticRegressionModel, self).__init__(num_assets)\n",
        "        self.linear = nn.Linear(input_size, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        out = self.linear(x)\n",
        "        weights = torch.tanh(out)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# LSTM Model\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"\n",
        "    LSTM Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets.\n",
        "        hidden_size (int): Size of hidden state.\n",
        "        num_layers (int): Number of LSTM layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets, hidden_size=64, num_layers=2):\n",
        "        super(LSTMModel, self).__init__(num_assets)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size=num_assets, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        weights = torch.tanh(out)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# CNN Model\n",
        "class CNNModel(BaseModel):\n",
        "    \"\"\"\n",
        "    CNN Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets):\n",
        "        super(CNNModel, self).__init__(num_assets)\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_assets, out_channels=32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.fc = nn.Linear(64, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_assets, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        weights = torch.tanh(x)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Transformer Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets.\n",
        "        d_model (int): Dimension of the model.\n",
        "        nhead (int): Number of attention heads.\n",
        "        num_layers (int): Number of transformer encoder layers.\n",
        "        seq_len (int): Length of the input sequences.\n",
        "        dropout (float): Dropout probability.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets, d_model=64, nhead=4, num_layers=2, seq_len=20, dropout=0.1):\n",
        "        super(TransformerModel, self).__init__(num_assets)\n",
        "        self.d_model = d_model\n",
        "        self.input_proj = nn.Linear(num_assets, d_model)\n",
        "        self.pos_encoder = LearnablePositionalEncoding(seq_len, d_model)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, num_assets)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.input_proj.weight.data.uniform_(-initrange, initrange)\n",
        "        self.input_proj.bias.data.zero_()\n",
        "        self.fc_out.bias.data.zero_()\n",
        "        self.fc_out.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x) * np.sqrt(self.d_model)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x[:, -1, :]  # Last time step\n",
        "        x = self.fc_out(x)\n",
        "        weights = torch.tanh(x)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# Learnable Positional Encoding\n",
        "class LearnablePositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements learnable positional encoding for sequences.\n",
        "\n",
        "    Args:\n",
        "        seq_len (int): The maximum length of the input sequences.\n",
        "        d_model (int): The dimension of the model.\n",
        "    \"\"\"\n",
        "    def __init__(self, seq_len, d_model):\n",
        "        super(LearnablePositionalEncoding, self).__init__()\n",
        "        self.position_embeddings = nn.Embedding(seq_len, d_model)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        positions = torch.arange(0, self.seq_len, device=x.device).unsqueeze(0)\n",
        "        pos_embed = self.position_embeddings(positions)\n",
        "        x = x + pos_embed\n",
        "        return x\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
        "    \"\"\"\n",
        "    Training loop for the model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to train.\n",
        "        train_loader (DataLoader): DataLoader for training data.\n",
        "        criterion (function): Loss function.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer.\n",
        "        num_epochs (int): Number of epochs.\n",
        "        device (torch.device): Computation device.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    prev_weights = torch.zeros((batch_size, model.num_assets)).to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            portfolio_weights = model(X_batch)\n",
        "            # Compute portfolio returns\n",
        "            portfolio_returns = torch.sum(portfolio_weights * y_batch, dim=1)\n",
        "            # Compute loss\n",
        "            loss = criterion(portfolio_returns, portfolio_weights, prev_weights[:portfolio_weights.size(0)])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            # Update prev_weights\n",
        "            prev_weights[:portfolio_weights.size(0)] = portfolio_weights.detach()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}')\n",
        "\n",
        "# Backtesting function\n",
        "def backtest_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Backtesting the model on test data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model.\n",
        "        test_loader (DataLoader): DataLoader for test data.\n",
        "        device (torch.device): Computation device.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    portfolio_returns_history = []\n",
        "    prev_weights = torch.zeros((1, model.num_assets)).to(device)\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            portfolio_weights = model(X_batch)\n",
        "            portfolio_returns = torch.sum(portfolio_weights * y_batch, dim=1)\n",
        "            portfolio_returns_history.extend(portfolio_returns.cpu().numpy())\n",
        "            # Update prev_weights\n",
        "            prev_weights = portfolio_weights.detach()\n",
        "    portfolio_returns = np.array(portfolio_returns_history)\n",
        "    cumulative_returns = np.cumprod(1 + portfolio_returns) - 1\n",
        "    mean_return = np.mean(portfolio_returns)\n",
        "    std_return = np.std(portfolio_returns)\n",
        "    sharpe_ratio = mean_return / (std_return + 1e-6) * np.sqrt(252)\n",
        "    print(f\"Cumulative Return: {cumulative_returns[-1]:.6f}\")\n",
        "    print(f\"Annualized Sharpe Ratio: {sharpe_ratio:.6f}\")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Example usage with Logistic Regression Model\n",
        "print(\"\\nTraining Logistic Regression Model\")\n",
        "model = LogisticRegressionModel(input_size=seq_len * num_assets, num_assets=num_assets)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# Example usage with LSTM Model\n",
        "print(\"\\nTraining LSTM Model\")\n",
        "model = LSTMModel(num_assets=num_assets)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# Example usage with CNN Model\n",
        "print(\"\\nTraining CNN Model\")\n",
        "model = CNNModel(num_assets=num_assets)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# Example usage with Transformer Model\n",
        "print(\"\\nTraining Transformer Model\")\n",
        "model = TransformerModel(num_assets=num_assets, d_model=d_model, seq_len=seq_len)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# New Model provided by the user\n",
        "print(\"\\nTraining Portfolio Transformer Model\")\n",
        "model = PortfolioTransformer(num_assets=num_assets, d_model=d_model, nhead=4, num_layers=2, seq_len=seq_len)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7bsziDwk4_nQ",
        "outputId": "f6e16500-03a3-4970-d2b5-f8cd5b9382ec"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression Model\n",
            "Epoch [1/5], Loss: 0.009969\n",
            "Epoch [2/5], Loss: -0.013706\n",
            "Epoch [3/5], Loss: -0.030145\n",
            "Epoch [4/5], Loss: -0.055203\n",
            "Epoch [5/5], Loss: -0.082532\n",
            "Cumulative Return: -0.071690\n",
            "Annualized Sharpe Ratio: -0.277367\n",
            "\n",
            "Training LSTM Model\n",
            "Epoch [1/5], Loss: 0.015314\n",
            "Epoch [2/5], Loss: -0.019160\n",
            "Epoch [3/5], Loss: -0.023031\n",
            "Epoch [4/5], Loss: -0.035522\n",
            "Epoch [5/5], Loss: -0.023104\n",
            "Cumulative Return: -0.001735\n",
            "Annualized Sharpe Ratio: 0.024882\n",
            "\n",
            "Training CNN Model\n",
            "Epoch [1/5], Loss: 0.008797\n",
            "Epoch [2/5], Loss: -0.006740\n",
            "Epoch [3/5], Loss: -0.012274\n",
            "Epoch [4/5], Loss: -0.018750\n",
            "Epoch [5/5], Loss: -0.021238\n",
            "Cumulative Return: 0.168103\n",
            "Annualized Sharpe Ratio: 0.680245\n",
            "\n",
            "Training Transformer Model\n",
            "Epoch [1/5], Loss: 0.055456\n",
            "Epoch [2/5], Loss: 0.000523\n",
            "Epoch [3/5], Loss: -0.012663\n",
            "Epoch [4/5], Loss: -0.023768\n",
            "Epoch [5/5], Loss: -0.035341\n",
            "Cumulative Return: -0.019282\n",
            "Annualized Sharpe Ratio: -0.069464\n",
            "\n",
            "Training Portfolio Transformer Model\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (20) must match the size of tensor b (64) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0a32d9d195ad>\u001b[0m in \u001b[0;36m<cell line: 342>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPortfolioTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_assets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_assets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharpe_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0mbacktest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-0a32d9d195ad>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mportfolio_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;31m# Compute portfolio returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mportfolio_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mportfolio_weights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mportfolio_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mportfolio_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mportfolio_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (20) must match the size of tensor b (64) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "\n",
        "# Parameters\n",
        "num_timesteps = 5000  # Total number of time steps\n",
        "num_assets = 10       # Number of assets in the portfolio\n",
        "seq_len = 20          # Length of input sequences\n",
        "d_model = 64          # Model dimension for Transformer\n",
        "batch_size = 64       # Batch size for training\n",
        "num_epochs = 5        # Number of training epochs\n",
        "\n",
        "# Generate synthetic returns data\n",
        "np.random.seed(42)\n",
        "returns_data = np.random.normal(0, 0.01, size=(num_timesteps, num_assets)).astype(np.float32)\n",
        "returns_data = torch.tensor(returns_data)\n",
        "\n",
        "# Dataset and DataLoader for training\n",
        "class ReturnsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for asset returns.\n",
        "\n",
        "    Args:\n",
        "        data (Tensor): Asset returns data of shape (num_timesteps, num_assets).\n",
        "        seq_len (int): Length of input sequences.\n",
        "    \"\"\"\n",
        "    def __init__(self, data, seq_len):\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.data[idx:idx + self.seq_len]\n",
        "        y = self.data[idx + self.seq_len]\n",
        "        return X, y\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(returns_data) * train_ratio)\n",
        "train_data = returns_data[:train_size]\n",
        "test_data = returns_data[train_size:]\n",
        "\n",
        "train_dataset = ReturnsDataset(train_data, seq_len)\n",
        "test_dataset = ReturnsDataset(test_data, seq_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # Use batch_size=1 for backtesting\n",
        "\n",
        "# Loss function: Negative Sharpe Ratio\n",
        "def sharpe_loss(portfolio_returns, portfolio_weights, prev_weights, transaction_cost=0.0002):\n",
        "    \"\"\"\n",
        "    Computes the negative Sharpe ratio as the loss function, including transaction costs.\n",
        "\n",
        "    Args:\n",
        "        portfolio_returns (Tensor): Portfolio returns of shape (batch_size,).\n",
        "        portfolio_weights (Tensor): Current portfolio weights of shape (batch_size, num_assets).\n",
        "        prev_weights (Tensor): Previous portfolio weights of shape (batch_size, num_assets).\n",
        "        transaction_cost (float): Transaction cost rate per unit weight change.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Loss value (negative Sharpe ratio).\n",
        "    \"\"\"\n",
        "    # Compute transaction costs based on weight changes\n",
        "    tc = transaction_cost * torch.sum(torch.abs(portfolio_weights - prev_weights), dim=1)\n",
        "    # Net returns after subtracting transaction costs\n",
        "    net_returns = portfolio_returns - tc\n",
        "    # Compute mean and standard deviation of returns\n",
        "    mean_return = torch.mean(net_returns)\n",
        "    std_return = torch.std(net_returns)\n",
        "    # Compute Sharpe ratio\n",
        "    sharpe_ratio = mean_return / (std_return + 1e-6)\n",
        "    # Return negative Sharpe ratio for minimization\n",
        "    return -sharpe_ratio\n",
        "\n",
        "# Base class for models\n",
        "class BaseModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Base class for asset allocation models.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets in the portfolio.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.num_assets = num_assets\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor of shape (batch_size, seq_len, num_assets).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Portfolio weights of shape (batch_size, num_assets).\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Logistic Regression Model\n",
        "class LogisticRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of input features (seq_len * num_assets).\n",
        "        num_assets (int): Number of assets.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_assets):\n",
        "        super(LogisticRegressionModel, self).__init__(num_assets)\n",
        "        self.linear = nn.Linear(input_size, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        out = self.linear(x)\n",
        "        weights = torch.tanh(out)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# LSTM Model\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"\n",
        "    LSTM Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets.\n",
        "        hidden_size (int): Size of hidden state.\n",
        "        num_layers (int): Number of LSTM layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets, hidden_size=64, num_layers=2):\n",
        "        super(LSTMModel, self).__init__(num_assets)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size=num_assets, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]  # Last time step\n",
        "        out = self.fc(out)\n",
        "        weights = torch.tanh(out)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# CNN Model\n",
        "class CNNModel(BaseModel):\n",
        "    \"\"\"\n",
        "    CNN Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets):\n",
        "        super(CNNModel, self).__init__(num_assets)\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_assets, out_channels=32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.fc = nn.Linear(64, num_assets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_assets, seq_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        weights = torch.tanh(x)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Transformer Model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets.\n",
        "        d_model (int): Dimension of the model.\n",
        "        nhead (int): Number of attention heads.\n",
        "        num_layers (int): Number of transformer encoder layers.\n",
        "        seq_len (int): Length of the input sequences.\n",
        "        dropout (float): Dropout probability.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_assets, d_model=64, nhead=4, num_layers=2, seq_len=20, dropout=0.1):\n",
        "        super(TransformerModel, self).__init__(num_assets)\n",
        "        self.d_model = d_model\n",
        "        self.input_proj = nn.Linear(num_assets, d_model)\n",
        "        self.pos_encoder = LearnablePositionalEncoding(seq_len, d_model)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, num_assets)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.input_proj.weight.data.uniform_(-initrange, initrange)\n",
        "        self.input_proj.bias.data.zero_()\n",
        "        self.fc_out.bias.data.zero_()\n",
        "        self.fc_out.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x) * np.sqrt(self.d_model)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x.permute(1, 0, 2)  # (batch_size, seq_len, d_model)\n",
        "        x = x[:, -1, :]  # Last time step\n",
        "        x = self.fc_out(x)\n",
        "        weights = torch.tanh(x)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# Learnable Positional Encoding\n",
        "class LearnablePositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements learnable positional encoding for sequences.\n",
        "\n",
        "    Args:\n",
        "        seq_len (int): The maximum length of the input sequences.\n",
        "        d_model (int): The dimension of the model.\n",
        "    \"\"\"\n",
        "    def __init__(self, seq_len, d_model):\n",
        "        super(LearnablePositionalEncoding, self).__init__()\n",
        "        self.position_embeddings = nn.Embedding(seq_len, d_model)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0).long()\n",
        "        pos_embed = self.position_embeddings(positions)\n",
        "        x = x + pos_embed\n",
        "        return x\n",
        "\n",
        "# Portfolio Transformer Model\n",
        "class PortfolioTransformer(BaseModel):\n",
        "    \"\"\"\n",
        "    Portfolio Transformer model for asset allocation.\n",
        "\n",
        "    Args:\n",
        "        num_assets (int): Number of assets in the portfolio.\n",
        "        d_model (int): Dimension of the model.\n",
        "        nhead (int): Number of attention heads.\n",
        "        num_layers (int): Number of transformer encoder layers.\n",
        "        seq_len (int): Length of the input sequences.\n",
        "        dropout (float): Dropout probability.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, num_assets, d_model, nhead, num_layers, seq_len, dropout=0.1\n",
        "    ):\n",
        "        super(PortfolioTransformer, self).__init__(num_assets)\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Input projection layer to map asset returns to model dimension\n",
        "        self.input_proj = nn.Linear(num_assets, d_model)\n",
        "\n",
        "        # Learnable positional encoding\n",
        "        self.pos_encoder = LearnablePositionalEncoding(seq_len, d_model)\n",
        "\n",
        "        # Transformer encoder layers\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead, dropout=dropout\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layers, num_layers=num_layers\n",
        "        )\n",
        "\n",
        "        # Output layer to map back to asset space\n",
        "        self.fc_out = nn.Linear(d_model, num_assets)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"\n",
        "        Initializes weights for better convergence.\n",
        "        \"\"\"\n",
        "        initrange = 0.1\n",
        "        self.input_proj.weight.data.uniform_(-initrange, initrange)\n",
        "        self.input_proj.bias.data.zero_()\n",
        "        self.fc_out.bias.data.zero_()\n",
        "        self.fc_out.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor of shape (batch_size, seq_len, num_assets).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Portfolio weights of shape (batch_size, num_assets).\n",
        "        \"\"\"\n",
        "        # Project input to model dimension and scale\n",
        "        x = self.input_proj(x) * np.sqrt(self.d_model)\n",
        "        # Add positional encoding\n",
        "        x = self.pos_encoder(x)\n",
        "        # Permute dimensions to match expected input of TransformerEncoder\n",
        "        x = x.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
        "        # Pass through transformer encoder\n",
        "        x = self.transformer_encoder(x)\n",
        "        # Permute back to (batch_size, seq_len, d_model)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        # Get the last time step\n",
        "        x = x[:, -1, :]  # (batch_size, d_model)\n",
        "        # Map back to asset space\n",
        "        s_i_t = self.fc_out(x)  # Shape: (batch_size, num_assets)\n",
        "        # Apply activation and normalize weights\n",
        "        weights = torch.tanh(s_i_t)\n",
        "        weights = weights / torch.sum(torch.abs(weights), dim=1, keepdim=True)\n",
        "        return weights\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
        "    \"\"\"\n",
        "    Training loop for the model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to train.\n",
        "        train_loader (DataLoader): DataLoader for training data.\n",
        "        criterion (function): Loss function.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer.\n",
        "        num_epochs (int): Number of epochs.\n",
        "        device (torch.device): Computation device.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    prev_weights = torch.zeros((batch_size, model.num_assets)).to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            portfolio_weights = model(X_batch)\n",
        "            # Compute portfolio returns\n",
        "            portfolio_returns = torch.sum(portfolio_weights * y_batch, dim=1)\n",
        "            # Compute loss\n",
        "            loss = criterion(portfolio_returns, portfolio_weights, prev_weights[:portfolio_weights.size(0)])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            # Update prev_weights\n",
        "            prev_weights[:portfolio_weights.size(0)] = portfolio_weights.detach()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}')\n",
        "\n",
        "# Backtesting function\n",
        "def backtest_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Backtesting the model on test data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model.\n",
        "        test_loader (DataLoader): DataLoader for test data.\n",
        "        device (torch.device): Computation device.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    portfolio_returns_history = []\n",
        "    prev_weights = torch.zeros((1, model.num_assets)).to(device)\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            portfolio_weights = model(X_batch)\n",
        "            portfolio_returns = torch.sum(portfolio_weights * y_batch, dim=1)\n",
        "            portfolio_returns_history.extend(portfolio_returns.cpu().numpy())\n",
        "            # Update prev_weights\n",
        "            prev_weights = portfolio_weights.detach()\n",
        "    portfolio_returns = np.array(portfolio_returns_history)\n",
        "    cumulative_returns = np.cumprod(1 + portfolio_returns) - 1\n",
        "    mean_return = np.mean(portfolio_returns)\n",
        "    std_return = np.std(portfolio_returns)\n",
        "    sharpe_ratio = mean_return / (std_return + 1e-6) * np.sqrt(252)\n",
        "    print(f\"Cumulative Return: {cumulative_returns[-1]:.6f}\")\n",
        "    print(f\"Annualized Sharpe Ratio: {sharpe_ratio:.6f}\")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Example usage with Logistic Regression Model\n",
        "print(\"\\nTraining Logistic Regression Model\")\n",
        "model = LogisticRegressionModel(input_size=seq_len * num_assets, num_assets=num_assets)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# Example usage with LSTM Model\n",
        "print(\"\\nTraining LSTM Model\")\n",
        "model = LSTMModel(num_assets=num_assets)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# Example usage with CNN Model\n",
        "print(\"\\nTraining CNN Model\")\n",
        "model = CNNModel(num_assets=num_assets)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# Example usage with Transformer Model\n",
        "print(\"\\nTraining Transformer Model\")\n",
        "model = TransformerModel(num_assets=num_assets, d_model=d_model, seq_len=seq_len)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)\n",
        "\n",
        "# New Model provided by the user\n",
        "print(\"\\nTraining Portfolio Transformer Model\")\n",
        "model = PortfolioTransformer(num_assets=num_assets, d_model=d_model, nhead=4, num_layers=2, seq_len=seq_len)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, sharpe_loss, optimizer, num_epochs, device)\n",
        "backtest_model(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsrS2ceu6OaZ",
        "outputId": "5945a4e9-1c55-4038-effd-a49611ec6812"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression Model\n",
            "Epoch [1/5], Loss: 0.032195\n",
            "Epoch [2/5], Loss: -0.005823\n",
            "Epoch [3/5], Loss: -0.027968\n",
            "Epoch [4/5], Loss: -0.059304\n",
            "Epoch [5/5], Loss: -0.124792\n",
            "Cumulative Return: 0.098651\n",
            "Annualized Sharpe Ratio: 0.424042\n",
            "\n",
            "Training LSTM Model\n",
            "Epoch [1/5], Loss: 0.000014\n",
            "Epoch [2/5], Loss: -0.012548\n",
            "Epoch [3/5], Loss: -0.020844\n",
            "Epoch [4/5], Loss: -0.017139\n",
            "Epoch [5/5], Loss: -0.019319\n",
            "Cumulative Return: -0.051313\n",
            "Annualized Sharpe Ratio: -0.166005\n",
            "\n",
            "Training CNN Model\n",
            "Epoch [1/5], Loss: 0.009937\n",
            "Epoch [2/5], Loss: 0.006323\n",
            "Epoch [3/5], Loss: 0.004441\n",
            "Epoch [4/5], Loss: -0.014695\n",
            "Epoch [5/5], Loss: -0.013243\n",
            "Cumulative Return: 0.122629\n",
            "Annualized Sharpe Ratio: 0.562786\n",
            "\n",
            "Training Transformer Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: -0.001458\n",
            "Epoch [2/5], Loss: -0.026020\n",
            "Epoch [3/5], Loss: -0.030113\n",
            "Epoch [4/5], Loss: -0.025826\n",
            "Epoch [5/5], Loss: -0.024897\n",
            "Cumulative Return: 0.040647\n",
            "Annualized Sharpe Ratio: 0.229768\n",
            "\n",
            "Training Portfolio Transformer Model\n",
            "Epoch [1/5], Loss: 0.006854\n",
            "Epoch [2/5], Loss: -0.027711\n",
            "Epoch [3/5], Loss: -0.010189\n",
            "Epoch [4/5], Loss: -0.016794\n",
            "Epoch [5/5], Loss: -0.026215\n",
            "Cumulative Return: -0.077065\n",
            "Annualized Sharpe Ratio: -0.370159\n"
          ]
        }
      ]
    }
  ]
}