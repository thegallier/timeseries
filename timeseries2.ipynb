{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXExWKjQkEG3rMS5ahuMwG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thegallier/timeseries/blob/main/timeseries2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the Dataset\n",
        "class MaskedOrderDataset(Dataset):\n",
        "    def __init__(self, num_samples, mask_prob=0.15, max_seq_len=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.N_sec_ids = 100  # Number of unique securities\n",
        "        self.N_distance_bins = 10  # Number of distance bins\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Generate synthetic data\n",
        "        self.timestamps = torch.randint(0, 1000, (num_samples,))\n",
        "        self.security_ids = torch.randint(0, self.N_sec_ids, (num_samples,))\n",
        "        self.buy_sell = torch.randint(0, 2, (num_samples,))  # 0: buy, 1: sell\n",
        "        self.add_modify_delete = torch.randint(0, 3, (num_samples,))  # 0: add, 1: modify, 2: delete\n",
        "        self.quantity = torch.randint(1, 1000, (num_samples,)).float()\n",
        "        self.price = torch.rand(num_samples) * 100  # Prices between 0 and 100\n",
        "        self.distance = torch.randint(0, self.N_distance_bins, (num_samples,))\n",
        "\n",
        "        # Sort the data by timestamps (ascending)\n",
        "        sorted_indices = torch.argsort(self.timestamps)\n",
        "        self.timestamps = self.timestamps[sorted_indices]\n",
        "        self.security_ids = self.security_ids[sorted_indices]\n",
        "        self.buy_sell = self.buy_sell[sorted_indices]\n",
        "        self.add_modify_delete = self.add_modify_delete[sorted_indices]\n",
        "        self.quantity = self.quantity[sorted_indices]\n",
        "        self.price = self.price[sorted_indices]\n",
        "        self.distance = self.distance[sorted_indices]\n",
        "\n",
        "        # Define mask indices\n",
        "        self.security_id_mask = self.N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = self.N_distance_bins\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence from idx to end, up to max_seq_len\n",
        "        end_idx = min(idx + self.max_seq_len, self.num_samples)\n",
        "        seq_len = end_idx - idx\n",
        "        sequence = {\n",
        "            'timestamp': self.timestamps[idx:end_idx],\n",
        "            'security_id': self.security_ids[idx:end_idx],\n",
        "            'buy_sell': self.buy_sell[idx:end_idx],\n",
        "            'add_modify_delete': self.add_modify_delete[idx:end_idx],\n",
        "            'quantity': self.quantity[idx:end_idx],\n",
        "            'price': self.price[idx:end_idx],\n",
        "            'distance': self.distance[idx:end_idx],\n",
        "        }\n",
        "\n",
        "        # Apply masking logic to the first element (idx)\n",
        "        sample = {key: sequence[key][0] for key in sequence}\n",
        "        masked_sample = sample.copy()\n",
        "        target = {}\n",
        "\n",
        "        for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "            if torch.rand(1).item() < self.mask_prob:\n",
        "                # Mask the feature\n",
        "                target[key] = sample[key]\n",
        "                if key == 'security_id':\n",
        "                    masked_sample[key] = self.security_id_mask\n",
        "                elif key == 'buy_sell':\n",
        "                    masked_sample[key] = self.buy_sell_mask\n",
        "                elif key == 'add_modify_delete':\n",
        "                    masked_sample[key] = self.add_modify_delete_mask\n",
        "                elif key == 'distance':\n",
        "                    masked_sample[key] = self.distance_mask\n",
        "                elif key in ['quantity', 'price']:\n",
        "                    masked_sample[key] = 0.0  # For continuous features, use 0.0 as masked value\n",
        "            else:\n",
        "                target[key] = None  # Not masked\n",
        "\n",
        "        # Return masked_sample, target, and the sequence starting from idx\n",
        "        return masked_sample, target, sequence\n",
        "\n",
        "# Define the Model\n",
        "class OrderModel(nn.Module):\n",
        "    def __init__(self, N_sec_ids, N_distance_bins, embedding_dim=32, hidden_dim=64):\n",
        "        super(OrderModel, self).__init__()\n",
        "\n",
        "        # Mask indices\n",
        "        self.security_id_mask = N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = N_distance_bins\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.security_id_embedding = nn.Embedding(N_sec_ids + 1, embedding_dim, padding_idx=self.security_id_mask)\n",
        "        self.buy_sell_embedding = nn.Embedding(3, embedding_dim, padding_idx=self.buy_sell_mask)  # 0,1,2(mask)\n",
        "        self.add_modify_delete_embedding = nn.Embedding(4, embedding_dim, padding_idx=self.add_modify_delete_mask)  # 0,1,2,3(mask)\n",
        "        self.distance_embedding = nn.Embedding(N_distance_bins + 1, embedding_dim, padding_idx=self.distance_mask)\n",
        "\n",
        "        # Linear layers for continuous features\n",
        "        self.quantity_linear = nn.Linear(1, embedding_dim)\n",
        "        self.price_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # For timestamp (we don't mask timestamp)\n",
        "        self.timestamp_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # LSTM for sequences\n",
        "        self.lstm_input_dim = embedding_dim * 7  # Number of features\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Final fully connected layers\n",
        "        self.fc1 = nn.Linear(embedding_dim * 7 + hidden_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output heads\n",
        "        self.security_id_head = nn.Linear(128, N_sec_ids)\n",
        "        self.buy_sell_head = nn.Linear(128, 2)\n",
        "        self.add_modify_delete_head = nn.Linear(128, 3)\n",
        "        self.distance_head = nn.Linear(128, N_distance_bins)\n",
        "        self.quantity_head = nn.Linear(128, 1)\n",
        "        self.price_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x is a dictionary of features for the masked sample\n",
        "        # seq_data is a dictionary of sequences\n",
        "        # seq_lengths is a list of sequence lengths\n",
        "\n",
        "        # Process the masked sample\n",
        "        timestamp = x['timestamp'].unsqueeze(1).float()\n",
        "        security_id = x['security_id']\n",
        "        buy_sell = x['buy_sell']\n",
        "        add_modify_delete = x['add_modify_delete']\n",
        "        quantity = x['quantity'].unsqueeze(1)\n",
        "        price = x['price'].unsqueeze(1)\n",
        "        distance = x['distance']\n",
        "\n",
        "        # Embeddings\n",
        "        timestamp_emb = self.timestamp_linear(timestamp)\n",
        "        security_id_emb = self.security_id_embedding(security_id)\n",
        "        buy_sell_emb = self.buy_sell_embedding(buy_sell)\n",
        "        add_modify_delete_emb = self.add_modify_delete_embedding(add_modify_delete)\n",
        "        quantity_emb = self.quantity_linear(quantity)\n",
        "        price_emb = self.price_linear(price)\n",
        "        distance_emb = self.distance_embedding(distance)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        sample_emb = torch.cat([timestamp_emb,\n",
        "                                security_id_emb,\n",
        "                                buy_sell_emb,\n",
        "                                add_modify_delete_emb,\n",
        "                                quantity_emb,\n",
        "                                price_emb,\n",
        "                                distance_emb], dim=1)  # Shape: (batch_size, embedding_dim * 7)\n",
        "\n",
        "        # Process the sequence data\n",
        "        # For each feature in seq_data, get embeddings\n",
        "        batch_size = timestamp.shape[0]\n",
        "\n",
        "        seq_timestamp = seq_data['timestamp'].float()\n",
        "        seq_security_id = seq_data['security_id']\n",
        "        seq_buy_sell = seq_data['buy_sell']\n",
        "        seq_add_modify_delete = seq_data['add_modify_delete']\n",
        "        seq_quantity = seq_data['quantity']\n",
        "        seq_price = seq_data['price']\n",
        "        seq_distance = seq_data['distance']\n",
        "\n",
        "        # Embeddings for sequence data\n",
        "        seq_timestamp_emb = self.timestamp_linear(seq_timestamp.unsqueeze(-1))  # (batch_size, seq_len, embedding_dim)\n",
        "        seq_security_id_emb = self.security_id_embedding(seq_security_id)\n",
        "        seq_buy_sell_emb = self.buy_sell_embedding(seq_buy_sell)\n",
        "        seq_add_modify_delete_emb = self.add_modify_delete_embedding(seq_add_modify_delete)\n",
        "        seq_quantity_emb = self.quantity_linear(seq_quantity.unsqueeze(-1))\n",
        "        seq_price_emb = self.price_linear(seq_price.unsqueeze(-1))\n",
        "        seq_distance_emb = self.distance_embedding(seq_distance)\n",
        "\n",
        "        # Concatenate sequence embeddings\n",
        "        seq_emb = torch.cat([seq_timestamp_emb,\n",
        "                             seq_security_id_emb,\n",
        "                             seq_buy_sell_emb,\n",
        "                             seq_add_modify_delete_emb,\n",
        "                             seq_quantity_emb,\n",
        "                             seq_price_emb,\n",
        "                             seq_distance_emb], dim=2)  # Shape: (batch_size, seq_len, embedding_dim * 7)\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = nn.utils.rnn.pack_padded_sequence(seq_emb, seq_lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb)\n",
        "\n",
        "        # Get the last hidden state for each sequence\n",
        "        seq_context = h_n.squeeze(0)  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Combine the sample embedding with the sequence context\n",
        "        combined = torch.cat([sample_emb, seq_context], dim=1)  # Shape: (batch_size, embedding_dim * 7 + hidden_dim)\n",
        "\n",
        "        # Forward pass\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Outputs\n",
        "        outputs = {\n",
        "            'security_id': self.security_id_head(x),\n",
        "            'buy_sell': self.buy_sell_head(x),\n",
        "            'add_modify_delete': self.add_modify_delete_head(x),\n",
        "            'distance': self.distance_head(x),\n",
        "            'quantity': self.quantity_head(x),\n",
        "            'price': self.price_head(x)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Collate function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    # batch is a list of (masked_sample, target, sequence)\n",
        "    batch_size = len(batch)\n",
        "    masked_samples = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    sequences = [item[2] for item in batch]\n",
        "\n",
        "    # Convert masked_samples to tensors\n",
        "    batch_data = {}\n",
        "    batch_target = {}\n",
        "    seq_data = {}\n",
        "    seq_lengths = []\n",
        "\n",
        "    # Process data\n",
        "    for key in ['timestamp', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_data[key] = torch.tensor([sample[key] for sample in masked_samples])\n",
        "\n",
        "    # Process sequences\n",
        "    # Sequences are variable-length\n",
        "    # For each key, we have a list of sequences\n",
        "    for key in ['timestamp', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        seq_list = [torch.tensor(seq[key]) for seq in sequences]\n",
        "        seq_padded = nn.utils.rnn.pad_sequence(seq_list, batch_first=True, padding_value=0)\n",
        "        seq_data[key] = seq_padded\n",
        "    # Record lengths\n",
        "    seq_lengths = [len(seq['timestamp']) for seq in sequences]\n",
        "\n",
        "    # Convert seq_lengths to tensor\n",
        "    seq_lengths = torch.tensor(seq_lengths, dtype=torch.long)\n",
        "\n",
        "    # Process target (exclude 'timestamp' as it's not in target)\n",
        "    for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_target[key] = []\n",
        "        for target in targets:\n",
        "            if target[key] is not None:\n",
        "                batch_target[key].append(target[key])\n",
        "            else:\n",
        "                batch_target[key].append(-100 if key not in ['quantity', 'price'] else 0.0)\n",
        "\n",
        "        # Convert to tensor and create mask\n",
        "        if key in ['quantity', 'price']:\n",
        "            # For continuous features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != 0.0 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.float)\n",
        "        else:\n",
        "            # For categorical features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != -100 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.long)\n",
        "\n",
        "    return batch_data, batch_target, seq_data, seq_lengths\n",
        "\n",
        "# Training and Testing Loop\n",
        "def train_model():\n",
        "    # Create Dataset and DataLoader\n",
        "    dataset = MaskedOrderDataset(num_samples=10000)\n",
        "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    # Create model\n",
        "    model = OrderModel(N_sec_ids=dataset.N_sec_ids, N_distance_bins=dataset.N_distance_bins)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_data, batch_target, seq_data, seq_lengths in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(batch_data, seq_data, seq_lengths)\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            # Compute loss for security_id\n",
        "            target = batch_target['security_id']\n",
        "            mask = batch_target['security_id_mask']\n",
        "            if mask.any():\n",
        "                loss_sec_id = criterion_ce(outputs['security_id'], target)\n",
        "                loss += loss_sec_id\n",
        "\n",
        "            # Compute loss for buy_sell\n",
        "            target = batch_target['buy_sell']\n",
        "            mask = batch_target['buy_sell_mask']\n",
        "            if mask.any():\n",
        "                loss_buy_sell = criterion_ce(outputs['buy_sell'], target)\n",
        "                loss += loss_buy_sell\n",
        "\n",
        "            # Compute loss for add_modify_delete\n",
        "            target = batch_target['add_modify_delete']\n",
        "            mask = batch_target['add_modify_delete_mask']\n",
        "            if mask.any():\n",
        "                loss_amd = criterion_ce(outputs['add_modify_delete'], target)\n",
        "                loss += loss_amd\n",
        "\n",
        "            # Compute loss for distance\n",
        "            target = batch_target['distance']\n",
        "            mask = batch_target['distance_mask']\n",
        "            if mask.any():\n",
        "                loss_distance = criterion_ce(outputs['distance'], target)\n",
        "                loss += loss_distance\n",
        "\n",
        "            # Compute loss for quantity\n",
        "            target = batch_target['quantity']\n",
        "            mask = batch_target['quantity_mask']\n",
        "            if mask.any():\n",
        "                output = outputs['quantity'].squeeze()\n",
        "                loss_quantity = criterion_l1(output[mask], target[mask])\n",
        "                loss += loss_quantity\n",
        "\n",
        "            # Compute loss for price\n",
        "            target = batch_target['price']\n",
        "            mask = batch_target['price_mask']\n",
        "            if mask.any():\n",
        "                output = outputs['price'].squeeze()\n",
        "                loss_price = criterion_l1(output[mask], target[mask])\n",
        "                loss += loss_price\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmEZwyPGCTJh",
        "outputId": "cd18dad6-1b2a-4178-d8c1-7e0410bc5d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-d57e3d80251b>:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 365.27560881596463\n",
            "Epoch 2, Loss: 327.6048114557934\n",
            "Epoch 3, Loss: 325.116089061567\n",
            "Epoch 4, Loss: 312.7274585893959\n",
            "Epoch 5, Loss: 312.8242979596375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# Define the Dataset\n",
        "class MaskedOrderDataset(Dataset):\n",
        "    def __init__(self, num_samples, mask_prob=0.15, max_seq_len=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.N_sec_ids = 100  # Number of unique securities\n",
        "        self.N_distance_bins = 10  # Number of distance bins\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Generate synthetic data\n",
        "        self.timestamps = torch.randint(0, 1000, (num_samples,))\n",
        "        self.security_ids = torch.randint(0, self.N_sec_ids, (num_samples,))\n",
        "        self.buy_sell = torch.randint(0, 2, (num_samples,))  # 0: buy, 1: sell\n",
        "        self.add_modify_delete = torch.randint(0, 3, (num_samples,))  # 0: add, 1: modify, 2: delete\n",
        "        self.quantity = torch.randint(1, 1000, (num_samples,)).float()\n",
        "        self.price = torch.rand(num_samples) * 100  # Prices between 0 and 100\n",
        "        self.distance = torch.randint(0, self.N_distance_bins, (num_samples,))\n",
        "\n",
        "        # Sort the data by timestamps (ascending)\n",
        "        sorted_indices = torch.argsort(self.timestamps)\n",
        "        self.timestamps = self.timestamps[sorted_indices]\n",
        "        self.security_ids = self.security_ids[sorted_indices]\n",
        "        self.buy_sell = self.buy_sell[sorted_indices]\n",
        "        self.add_modify_delete = self.add_modify_delete[sorted_indices]\n",
        "        self.quantity = self.quantity[sorted_indices]\n",
        "        self.price = self.price[sorted_indices]\n",
        "        self.distance = self.distance[sorted_indices]\n",
        "\n",
        "        # Define mask indices\n",
        "        self.security_id_mask = self.N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = self.N_distance_bins\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence from idx to end, up to max_seq_len\n",
        "        end_idx = min(idx + self.max_seq_len, self.num_samples)\n",
        "        seq_len = end_idx - idx\n",
        "        sequence = {\n",
        "            'timestamp': self.timestamps[idx:end_idx],\n",
        "            'security_id': self.security_ids[idx:end_idx],\n",
        "            'buy_sell': self.buy_sell[idx:end_idx],\n",
        "            'add_modify_delete': self.add_modify_delete[idx:end_idx],\n",
        "            'quantity': self.quantity[idx:end_idx],\n",
        "            'price': self.price[idx:end_idx],\n",
        "            'distance': self.distance[idx:end_idx],\n",
        "            'position': torch.arange(seq_len)  # Row number\n",
        "        }\n",
        "\n",
        "        # Apply masking logic to the first element (idx)\n",
        "        sample = {key: sequence[key][0] for key in sequence}\n",
        "        masked_sample = sample.copy()\n",
        "        target = {}\n",
        "\n",
        "        for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "            if torch.rand(1).item() < self.mask_prob:\n",
        "                # Mask the feature\n",
        "                target[key] = sample[key]\n",
        "                if key == 'security_id':\n",
        "                    masked_sample[key] = self.security_id_mask\n",
        "                elif key == 'buy_sell':\n",
        "                    masked_sample[key] = self.buy_sell_mask\n",
        "                elif key == 'add_modify_delete':\n",
        "                    masked_sample[key] = self.add_modify_delete_mask\n",
        "                elif key == 'distance':\n",
        "                    masked_sample[key] = self.distance_mask\n",
        "                elif key in ['quantity', 'price']:\n",
        "                    masked_sample[key] = 0.0  # For continuous features, use 0.0 as masked value\n",
        "            else:\n",
        "                target[key] = None  # Not masked\n",
        "\n",
        "        # Return masked_sample, target, and the sequence starting from idx\n",
        "        return masked_sample, target, sequence\n",
        "\n",
        "# Learnable Positional Encoder\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(PositionalEncoder, self).__init__()\n",
        "        self.timestamp_encoder = nn.Linear(1, embedding_dim)\n",
        "        self.position_encoder = nn.Embedding(1000, embedding_dim)  # Assume max 1000 positions\n",
        "\n",
        "    def forward(self, timestamps, positions):\n",
        "        timestamp_emb = self.timestamp_encoder(timestamps.unsqueeze(-1).float())\n",
        "        position_emb = self.position_encoder(positions)\n",
        "        return timestamp_emb + position_emb\n",
        "\n",
        "# Base Model Class\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Order Model with Positional Encoder\n",
        "class OrderModel(BaseModel):\n",
        "    def __init__(self, N_sec_ids, N_distance_bins, embedding_dim=32, hidden_dim=64):\n",
        "        super(OrderModel, self).__init__()\n",
        "\n",
        "        # Mask indices\n",
        "        self.security_id_mask = N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = N_distance_bins\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.security_id_embedding = nn.Embedding(N_sec_ids + 1, embedding_dim, padding_idx=self.security_id_mask)\n",
        "        self.buy_sell_embedding = nn.Embedding(3, embedding_dim, padding_idx=self.buy_sell_mask)  # 0,1,2(mask)\n",
        "        self.add_modify_delete_embedding = nn.Embedding(4, embedding_dim, padding_idx=self.add_modify_delete_mask)  # 0,1,2,3(mask)\n",
        "        self.distance_embedding = nn.Embedding(N_distance_bins + 1, embedding_dim, padding_idx=self.distance_mask)\n",
        "\n",
        "        # Linear layers for continuous features\n",
        "        self.quantity_linear = nn.Linear(1, embedding_dim)\n",
        "        self.price_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # Positional Encoder\n",
        "        self.positional_encoder = PositionalEncoder(embedding_dim)\n",
        "\n",
        "        # LSTM for sequences\n",
        "        self.lstm_input_dim = embedding_dim * 7  # Number of features\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Final fully connected layers\n",
        "        self.fc1 = nn.Linear(embedding_dim * 7 + hidden_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output heads\n",
        "        self.security_id_head = nn.Linear(128, N_sec_ids)\n",
        "        self.buy_sell_head = nn.Linear(128, 2)\n",
        "        self.add_modify_delete_head = nn.Linear(128, 3)\n",
        "        self.distance_head = nn.Linear(128, N_distance_bins)\n",
        "        self.quantity_head = nn.Linear(128, 1)\n",
        "        self.price_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x is a dictionary of features for the masked sample\n",
        "        # seq_data is a dictionary of sequences\n",
        "        # seq_lengths is a list of sequence lengths\n",
        "\n",
        "        batch_size = x['timestamp'].shape[0]\n",
        "\n",
        "        # Process the masked sample\n",
        "        timestamp = x['timestamp']\n",
        "        position = x['position']\n",
        "        security_id = x['security_id']\n",
        "        buy_sell = x['buy_sell']\n",
        "        add_modify_delete = x['add_modify_delete']\n",
        "        quantity = x['quantity'].unsqueeze(1)\n",
        "        price = x['price'].unsqueeze(1)\n",
        "        distance = x['distance']\n",
        "\n",
        "        # Embeddings\n",
        "        positional_emb = self.positional_encoder(timestamp, position)\n",
        "        security_id_emb = self.security_id_embedding(security_id)\n",
        "        buy_sell_emb = self.buy_sell_embedding(buy_sell)\n",
        "        add_modify_delete_emb = self.add_modify_delete_embedding(add_modify_delete)\n",
        "        quantity_emb = self.quantity_linear(quantity)\n",
        "        price_emb = self.price_linear(price)\n",
        "        distance_emb = self.distance_embedding(distance)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        sample_emb = torch.cat([positional_emb,\n",
        "                                security_id_emb,\n",
        "                                buy_sell_emb,\n",
        "                                add_modify_delete_emb,\n",
        "                                quantity_emb,\n",
        "                                price_emb,\n",
        "                                distance_emb], dim=1)  # Shape: (batch_size, embedding_dim * 7)\n",
        "\n",
        "        # Process the sequence data\n",
        "        # For each feature in seq_data, get embeddings\n",
        "\n",
        "        seq_timestamp = seq_data['timestamp']\n",
        "        seq_position = seq_data['position']\n",
        "        seq_security_id = seq_data['security_id']\n",
        "        seq_buy_sell = seq_data['buy_sell']\n",
        "        seq_add_modify_delete = seq_data['add_modify_delete']\n",
        "        seq_quantity = seq_data['quantity']\n",
        "        seq_price = seq_data['price']\n",
        "        seq_distance = seq_data['distance']\n",
        "\n",
        "        # Embeddings for sequence data\n",
        "        seq_positional_emb = self.positional_encoder(seq_timestamp, seq_position)\n",
        "        seq_security_id_emb = self.security_id_embedding(seq_security_id)\n",
        "        seq_buy_sell_emb = self.buy_sell_embedding(seq_buy_sell)\n",
        "        seq_add_modify_delete_emb = self.add_modify_delete_embedding(seq_add_modify_delete)\n",
        "        seq_quantity_emb = self.quantity_linear(seq_quantity.unsqueeze(-1))\n",
        "        seq_price_emb = self.price_linear(seq_price.unsqueeze(-1))\n",
        "        seq_distance_emb = self.distance_embedding(seq_distance)\n",
        "\n",
        "        # Concatenate sequence embeddings\n",
        "        seq_emb = torch.cat([seq_positional_emb,\n",
        "                             seq_security_id_emb,\n",
        "                             seq_buy_sell_emb,\n",
        "                             seq_add_modify_delete_emb,\n",
        "                             seq_quantity_emb,\n",
        "                             seq_price_emb,\n",
        "                             seq_distance_emb], dim=2)  # Shape: (batch_size, seq_len, embedding_dim * 7)\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = pack_padded_sequence(seq_emb, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb)\n",
        "\n",
        "        # Get the last hidden state for each sequence\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Combine the sample embedding with the sequence context\n",
        "        combined = torch.cat([sample_emb, seq_context], dim=1)  # Shape: (batch_size, embedding_dim * 7 + hidden_dim)\n",
        "\n",
        "        # Forward pass\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Outputs\n",
        "        outputs = {\n",
        "            'security_id': self.security_id_head(x),\n",
        "            'buy_sell': self.buy_sell_head(x),\n",
        "            'add_modify_delete': self.add_modify_delete_head(x),\n",
        "            'distance': self.distance_head(x),\n",
        "            'quantity': self.quantity_head(x),\n",
        "            'price': self.price_head(x)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Additional Models\n",
        "\n",
        "class MatrixRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, input_size, num_classes=1):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(1, num_securities))\n",
        "        self.B = nn.Parameter(torch.randn(input_size, num_classes))\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        # x: (batch_size, input_size)\n",
        "        x = x.view(x.size(0), -1)  # Flatten over time\n",
        "        out = self.A @ x @ self.B  # Shape: (batch_size, num_classes)\n",
        "        return {'price': out.squeeze(-1)}  # Adjust as needed\n",
        "\n",
        "class LogisticRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_classes=1):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.linear(x)\n",
        "        return {'price': out.squeeze(-1)}  # Adjust as needed\n",
        "\n",
        "class CNNModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_classes=1):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, seq_len)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        return {'price': x.squeeze(-1)}  # Adjust as needed\n",
        "\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes=1):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: Not used in this model\n",
        "        # seq_data: input sequences\n",
        "        # seq_lengths: lengths of sequences\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = pack_padded_sequence(seq_data, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        h0 = torch.zeros(self.lstm.num_layers, seq_data.size(0), self.lstm.hidden_size).to(seq_data.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, seq_data.size(0), self.lstm.hidden_size).to(seq_data.device)\n",
        "\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb, (h0, c0))\n",
        "\n",
        "        # Get the last hidden state\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        out = self.fc(seq_context)\n",
        "        return {'price': out.squeeze(-1)}  # Adjust as needed\n",
        "\n",
        "# Collate function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    # batch is a list of (masked_sample, target, sequence)\n",
        "    batch_size = len(batch)\n",
        "    masked_samples = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    sequences = [item[2] for item in batch]\n",
        "\n",
        "    # Convert masked_samples to tensors\n",
        "    batch_data = {}\n",
        "    batch_target = {}\n",
        "    seq_data = {}\n",
        "    seq_lengths = []\n",
        "\n",
        "    # Process data\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_data[key] = torch.tensor([sample[key] for sample in masked_samples])\n",
        "\n",
        "    # Process sequences\n",
        "    # Sequences are variable-length\n",
        "    # For each key, we have a list of sequences\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        seq_list = [torch.tensor(seq[key]) for seq in sequences]\n",
        "        seq_padded = nn.utils.rnn.pad_sequence(seq_list, batch_first=True, padding_value=0)\n",
        "        seq_data[key] = seq_padded\n",
        "    # Record lengths\n",
        "    seq_lengths = [len(seq['timestamp']) for seq in sequences]\n",
        "\n",
        "    # Convert seq_lengths to tensor\n",
        "    seq_lengths = torch.tensor(seq_lengths, dtype=torch.long)\n",
        "\n",
        "    # Process target (exclude 'timestamp' and 'position' as they're not in target)\n",
        "    for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_target[key] = []\n",
        "        for target in targets:\n",
        "            if target[key] is not None:\n",
        "                batch_target[key].append(target[key])\n",
        "            else:\n",
        "                batch_target[key].append(-100 if key not in ['quantity', 'price'] else 0.0)\n",
        "\n",
        "        # Convert to tensor and create mask\n",
        "        if key in ['quantity', 'price']:\n",
        "            # For continuous features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != 0.0 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.float)\n",
        "        else:\n",
        "            # For categorical features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != -100 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.long)\n",
        "\n",
        "    return batch_data, batch_target, seq_data, seq_lengths\n",
        "\n",
        "# Training and Testing Loop\n",
        "def train_model(model_class, model_params, dataset_params, training_params):\n",
        "    # Create Dataset and DataLoader\n",
        "    dataset = MaskedOrderDataset(**dataset_params)\n",
        "    dataloader = DataLoader(dataset, batch_size=training_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    # Create model\n",
        "    model = model_class(**model_params)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=training_params['learning_rate'])\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(training_params['num_epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_data, batch_target, seq_data, seq_lengths in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move data to device\n",
        "            device = training_params.get('device', 'cpu')\n",
        "            batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
        "            batch_target = {k: v.to(device) for k, v in batch_target.items()}\n",
        "            seq_data = {k: v.to(device) for k, v in seq_data.items()}\n",
        "            seq_lengths = seq_lengths.to(device)\n",
        "\n",
        "            outputs = model(batch_data, seq_data, seq_lengths)\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            # Compute loss for security_id\n",
        "            if 'security_id' in outputs:\n",
        "                target = batch_target['security_id']\n",
        "                mask = batch_target['security_id_mask']\n",
        "                if mask.any():\n",
        "                    loss_sec_id = criterion_ce(outputs['security_id'], target)\n",
        "                    loss += loss_sec_id\n",
        "\n",
        "            # Compute loss for buy_sell\n",
        "            if 'buy_sell' in outputs:\n",
        "                target = batch_target['buy_sell']\n",
        "                mask = batch_target['buy_sell_mask']\n",
        "                if mask.any():\n",
        "                    loss_buy_sell = criterion_ce(outputs['buy_sell'], target)\n",
        "                    loss += loss_buy_sell\n",
        "\n",
        "            # Compute loss for add_modify_delete\n",
        "            if 'add_modify_delete' in outputs:\n",
        "                target = batch_target['add_modify_delete']\n",
        "                mask = batch_target['add_modify_delete_mask']\n",
        "                if mask.any():\n",
        "                    loss_amd = criterion_ce(outputs['add_modify_delete'], target)\n",
        "                    loss += loss_amd\n",
        "\n",
        "            # Compute loss for distance\n",
        "            if 'distance' in outputs:\n",
        "                target = batch_target['distance']\n",
        "                mask = batch_target['distance_mask']\n",
        "                if mask.any():\n",
        "                    loss_distance = criterion_ce(outputs['distance'], target)\n",
        "                    loss += loss_distance\n",
        "\n",
        "            # Compute loss for quantity\n",
        "            if 'quantity' in outputs:\n",
        "                target = batch_target['quantity']\n",
        "                mask = batch_target['quantity_mask']\n",
        "                if mask.any():\n",
        "                    output = outputs['quantity'].squeeze()\n",
        "                    loss_quantity = criterion_l1(output[mask], target[mask])\n",
        "                    loss += loss_quantity\n",
        "\n",
        "            # Compute loss for price\n",
        "            if 'price' in outputs:\n",
        "                target = batch_target['price']\n",
        "                mask = batch_target['price_mask']\n",
        "                if mask.any():\n",
        "                    output = outputs['price'].squeeze()\n",
        "                    loss_price = criterion_l1(output[mask], target[mask])\n",
        "                    loss += loss_price\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Hyperparameter Optimization\n",
        "def hyperparameter_optimization():\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from skorch import NeuralNetRegressor, NeuralNetClassifier\n",
        "    import numpy as np\n",
        "\n",
        "    # Define parameter grid\n",
        "    param_grid = {\n",
        "        'module__embedding_dim': [16, 32],\n",
        "        'module__hidden_dim': [32, 64],\n",
        "        'optimizer__lr': [0.001, 0.0001],\n",
        "    }\n",
        "\n",
        "    # Wrap the model using skorch\n",
        "    net = NeuralNetRegressor(\n",
        "        OrderModel,\n",
        "        module__N_sec_ids=100,\n",
        "        module__N_distance_bins=10,\n",
        "        max_epochs=5,\n",
        "        lr=0.001,\n",
        "        iterator_train__collate_fn=collate_fn,\n",
        "        iterator_valid__collate_fn=collate_fn,\n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    )\n",
        "\n",
        "    # Create Dataset\n",
        "    dataset = MaskedOrderDataset(num_samples=1000)\n",
        "\n",
        "    # Prepare data for GridSearchCV (this is a simplified example)\n",
        "    X = [dataset[i][0] for i in range(len(dataset))]\n",
        "    y = [dataset[i][1]['price'] if dataset[i][1]['price'] is not None else 0.0 for i in range(len(dataset))]\n",
        "\n",
        "    # Convert X and y to numpy arrays (skorch expects numpy arrays)\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Perform Grid Search\n",
        "    gs = GridSearchCV(net, param_grid, refit=False, cv=3, scoring='neg_mean_absolute_error', verbose=2)\n",
        "    gs.fit(X, y)\n",
        "\n",
        "    print(\"Best parameters found:\")\n",
        "    print(gs.best_params_)\n",
        "\n",
        "    print(\"Best score:\")\n",
        "    print(gs.best_score_)\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Training parameters\n",
        "    training_params = {\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 0.001,\n",
        "        'num_epochs': 5,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    }\n",
        "\n",
        "    # Dataset parameters\n",
        "    dataset_params = {\n",
        "        'num_samples': 5000,\n",
        "        'mask_prob': 0.15,\n",
        "        'max_seq_len': 50\n",
        "    }\n",
        "\n",
        "    # Model parameters for OrderModel\n",
        "    model_params = {\n",
        "        'N_sec_ids': 100,\n",
        "        'N_distance_bins': 10,\n",
        "        'embedding_dim': 32,\n",
        "        'hidden_dim': 64\n",
        "    }\n",
        "\n",
        "    # Train OrderModel\n",
        "    print(\"Training OrderModel...\")\n",
        "    model = train_model(OrderModel, model_params, dataset_params, training_params)\n",
        "\n",
        "    # You can substitute different models by changing model_class and model_params\n",
        "    # For example, training LSTMModel\n",
        "    '''\n",
        "    print(\"Training LSTMModel...\")\n",
        "    model_params_lstm = {\n",
        "        'input_size': 7,  # Number of features in sequence data\n",
        "        'hidden_size': 64,\n",
        "        'num_layers': 2,\n",
        "        'num_classes': 1\n",
        "    }\n",
        "    model = train_model(LSTMModel, model_params_lstm, dataset_params, training_params)\n",
        "    '''\n",
        "\n",
        "    # Hyperparameter Optimization\n",
        "    '''\n",
        "    print(\"Starting Hyperparameter Optimization...\")\n",
        "    hyperparameter_optimization()\n",
        "    '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf6NO-ftGD1Y",
        "outputId": "3c6fab5d-5d31-4e27-ae98-62e9240f6244"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training OrderModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-15b0f17eec53>:371: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 381.8814974256382\n",
            "Epoch 2, Loss: 349.19875107297474\n",
            "Epoch 3, Loss: 338.50678306628186\n",
            "Epoch 4, Loss: 321.11537005187597\n",
            "Epoch 5, Loss: 339.4471651308096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Define the Dataset\n",
        "class MaskedOrderDataset(Dataset):\n",
        "    def __init__(self, num_samples, mask_prob=0.15, max_seq_len=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.N_sec_ids = 100  # Number of unique securities\n",
        "        self.N_distance_bins = 10  # Number of distance bins\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Generate synthetic data\n",
        "        self.timestamps = torch.randint(0, 1000, (num_samples,))\n",
        "        self.security_ids = torch.randint(0, self.N_sec_ids, (num_samples,))\n",
        "        self.buy_sell = torch.randint(0, 2, (num_samples,))  # 0: buy, 1: sell\n",
        "        self.add_modify_delete = torch.randint(0, 3, (num_samples,))  # 0: add, 1: modify, 2: delete\n",
        "        self.quantity = torch.randint(1, 1000, (num_samples,)).float()\n",
        "        self.price = torch.rand(num_samples) * 100  # Prices between 0 and 100\n",
        "        self.distance = torch.randint(0, self.N_distance_bins, (num_samples,))\n",
        "\n",
        "        # Sort the data by timestamps (ascending)\n",
        "        sorted_indices = torch.argsort(self.timestamps)\n",
        "        self.timestamps = self.timestamps[sorted_indices]\n",
        "        self.security_ids = self.security_ids[sorted_indices]\n",
        "        self.buy_sell = self.buy_sell[sorted_indices]\n",
        "        self.add_modify_delete = self.add_modify_delete[sorted_indices]\n",
        "        self.quantity = self.quantity[sorted_indices]\n",
        "        self.price = self.price[sorted_indices]\n",
        "        self.distance = self.distance[sorted_indices]\n",
        "\n",
        "        # Define mask indices\n",
        "        self.security_id_mask = self.N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = self.N_distance_bins\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence from idx to end, up to max_seq_len\n",
        "        end_idx = min(idx + self.max_seq_len, self.num_samples)\n",
        "        seq_len = end_idx - idx\n",
        "        sequence = {\n",
        "            'timestamp': self.timestamps[idx:end_idx],\n",
        "            'security_id': self.security_ids[idx:end_idx],\n",
        "            'buy_sell': self.buy_sell[idx:end_idx],\n",
        "            'add_modify_delete': self.add_modify_delete[idx:end_idx],\n",
        "            'quantity': self.quantity[idx:end_idx],\n",
        "            'price': self.price[idx:end_idx],\n",
        "            'distance': self.distance[idx:end_idx],\n",
        "            'position': torch.arange(seq_len)  # Row number\n",
        "        }\n",
        "\n",
        "        # Apply masking logic to the first element (idx)\n",
        "        sample = {key: sequence[key][0] for key in sequence}\n",
        "        masked_sample = sample.copy()\n",
        "        target = {}\n",
        "\n",
        "        # List of features to potentially mask\n",
        "        maskable_keys = ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']\n",
        "\n",
        "        # Decide how many features to mask (at least one)\n",
        "        num_features_to_mask = random.randint(1, len(maskable_keys))\n",
        "\n",
        "        # Randomly select features to mask\n",
        "        features_to_mask = random.sample(maskable_keys, num_features_to_mask)\n",
        "\n",
        "        for key in maskable_keys:\n",
        "            if key in features_to_mask:\n",
        "                # Mask the feature\n",
        "                target[key] = sample[key]\n",
        "                if key == 'security_id':\n",
        "                    masked_sample[key] = self.security_id_mask\n",
        "                elif key == 'buy_sell':\n",
        "                    masked_sample[key] = self.buy_sell_mask\n",
        "                elif key == 'add_modify_delete':\n",
        "                    masked_sample[key] = self.add_modify_delete_mask\n",
        "                elif key == 'distance':\n",
        "                    masked_sample[key] = self.distance_mask\n",
        "                elif key in ['quantity', 'price']:\n",
        "                    masked_sample[key] = 0.0  # For continuous features, use 0.0 as masked value\n",
        "            else:\n",
        "                target[key] = None  # Not masked\n",
        "\n",
        "        # Return masked_sample, target, and the sequence starting from idx\n",
        "        return masked_sample, target, sequence\n",
        "\n",
        "# Learnable Positional Encoder\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(PositionalEncoder, self).__init__()\n",
        "        self.timestamp_encoder = nn.Linear(1, embedding_dim)\n",
        "        self.position_encoder = nn.Embedding(1000, embedding_dim)  # Assume max 1000 positions\n",
        "\n",
        "    def forward(self, timestamps, positions):\n",
        "        timestamp_emb = self.timestamp_encoder(timestamps.unsqueeze(-1).float())\n",
        "        position_emb = self.position_encoder(positions)\n",
        "        return timestamp_emb + position_emb\n",
        "\n",
        "# Base Model Class\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Order Model with Positional Encoder\n",
        "class OrderModel(BaseModel):\n",
        "    def __init__(self, N_sec_ids, N_distance_bins, embedding_dim=32, hidden_dim=64):\n",
        "        super(OrderModel, self).__init__()\n",
        "\n",
        "        # Mask indices\n",
        "        self.security_id_mask = N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = N_distance_bins\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.security_id_embedding = nn.Embedding(N_sec_ids + 1, embedding_dim, padding_idx=self.security_id_mask)\n",
        "        self.buy_sell_embedding = nn.Embedding(3, embedding_dim, padding_idx=self.buy_sell_mask)  # 0,1,2(mask)\n",
        "        self.add_modify_delete_embedding = nn.Embedding(4, embedding_dim, padding_idx=self.add_modify_delete_mask)  # 0,1,2,3(mask)\n",
        "        self.distance_embedding = nn.Embedding(N_distance_bins + 1, embedding_dim, padding_idx=self.distance_mask)\n",
        "\n",
        "        # Linear layers for continuous features\n",
        "        self.quantity_linear = nn.Linear(1, embedding_dim)\n",
        "        self.price_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # Positional Encoder\n",
        "        self.positional_encoder = PositionalEncoder(embedding_dim)\n",
        "\n",
        "        # LSTM for sequences\n",
        "        self.lstm_input_dim = embedding_dim * 7  # Number of features\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Final fully connected layers\n",
        "        self.fc1 = nn.Linear(embedding_dim * 7 + hidden_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output heads\n",
        "        self.security_id_head = nn.Linear(128, N_sec_ids)\n",
        "        self.buy_sell_head = nn.Linear(128, 2)\n",
        "        self.add_modify_delete_head = nn.Linear(128, 3)\n",
        "        self.distance_head = nn.Linear(128, N_distance_bins)\n",
        "        self.quantity_head = nn.Linear(128, 1)\n",
        "        self.price_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x is a dictionary of features for the masked sample\n",
        "        # seq_data is a dictionary of sequences\n",
        "        # seq_lengths is a list of sequence lengths\n",
        "\n",
        "        batch_size = x['timestamp'].shape[0]\n",
        "\n",
        "        # Process the masked sample\n",
        "        timestamp = x['timestamp']\n",
        "        position = x['position']\n",
        "        security_id = x['security_id']\n",
        "        buy_sell = x['buy_sell']\n",
        "        add_modify_delete = x['add_modify_delete']\n",
        "        quantity = x['quantity'].unsqueeze(1)\n",
        "        price = x['price'].unsqueeze(1)\n",
        "        distance = x['distance']\n",
        "\n",
        "        # Embeddings\n",
        "        positional_emb = self.positional_encoder(timestamp, position)\n",
        "        security_id_emb = self.security_id_embedding(security_id)\n",
        "        buy_sell_emb = self.buy_sell_embedding(buy_sell)\n",
        "        add_modify_delete_emb = self.add_modify_delete_embedding(add_modify_delete)\n",
        "        quantity_emb = self.quantity_linear(quantity)\n",
        "        price_emb = self.price_linear(price)\n",
        "        distance_emb = self.distance_embedding(distance)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        sample_emb = torch.cat([positional_emb,\n",
        "                                security_id_emb,\n",
        "                                buy_sell_emb,\n",
        "                                add_modify_delete_emb,\n",
        "                                quantity_emb,\n",
        "                                price_emb,\n",
        "                                distance_emb], dim=1)  # Shape: (batch_size, embedding_dim * 7)\n",
        "\n",
        "        # Process the sequence data\n",
        "        # For each feature in seq_data, get embeddings\n",
        "\n",
        "        seq_timestamp = seq_data['timestamp']\n",
        "        seq_position = seq_data['position']\n",
        "        seq_security_id = seq_data['security_id']\n",
        "        seq_buy_sell = seq_data['buy_sell']\n",
        "        seq_add_modify_delete = seq_data['add_modify_delete']\n",
        "        seq_quantity = seq_data['quantity']\n",
        "        seq_price = seq_data['price']\n",
        "        seq_distance = seq_data['distance']\n",
        "\n",
        "        # Embeddings for sequence data\n",
        "        seq_positional_emb = self.positional_encoder(seq_timestamp, seq_position)\n",
        "        seq_security_id_emb = self.security_id_embedding(seq_security_id)\n",
        "        seq_buy_sell_emb = self.buy_sell_embedding(seq_buy_sell)\n",
        "        seq_add_modify_delete_emb = self.add_modify_delete_embedding(seq_add_modify_delete)\n",
        "        seq_quantity_emb = self.quantity_linear(seq_quantity.unsqueeze(-1))\n",
        "        seq_price_emb = self.price_linear(seq_price.unsqueeze(-1))\n",
        "        seq_distance_emb = self.distance_embedding(seq_distance)\n",
        "\n",
        "        # Concatenate sequence embeddings\n",
        "        seq_emb = torch.cat([seq_positional_emb,\n",
        "                             seq_security_id_emb,\n",
        "                             seq_buy_sell_emb,\n",
        "                             seq_add_modify_delete_emb,\n",
        "                             seq_quantity_emb,\n",
        "                             seq_price_emb,\n",
        "                             seq_distance_emb], dim=2)  # Shape: (batch_size, seq_len, embedding_dim * 7)\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = pack_padded_sequence(seq_emb, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb)\n",
        "\n",
        "        # Get the last hidden state for each sequence\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Combine the sample embedding with the sequence context\n",
        "        combined = torch.cat([sample_emb, seq_context], dim=1)  # Shape: (batch_size, embedding_dim * 7 + hidden_dim)\n",
        "\n",
        "        # Forward pass\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Outputs\n",
        "        outputs = {\n",
        "            'security_id': self.security_id_head(x),\n",
        "            'buy_sell': self.buy_sell_head(x),\n",
        "            'add_modify_delete': self.add_modify_delete_head(x),\n",
        "            'distance': self.distance_head(x),\n",
        "            'quantity': self.quantity_head(x),\n",
        "            'price': self.price_head(x)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Additional Models (Unchanged for brevity)\n",
        "# Assume the BaseModel class and other models are defined as before\n",
        "\n",
        "# Collate function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    # batch is a list of (masked_sample, target, sequence)\n",
        "    batch_size = len(batch)\n",
        "    masked_samples = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    sequences = [item[2] for item in batch]\n",
        "\n",
        "    # Convert masked_samples to tensors\n",
        "    batch_data = {}\n",
        "    batch_target = {}\n",
        "    seq_data = {}\n",
        "    seq_lengths = []\n",
        "\n",
        "    # Process data\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_data[key] = torch.tensor([sample[key] for sample in masked_samples])\n",
        "\n",
        "    # Process sequences\n",
        "    # Sequences are variable-length\n",
        "    # For each key, we have a list of sequences\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        seq_list = [torch.tensor(seq[key]) for seq in sequences]\n",
        "        seq_padded = nn.utils.rnn.pad_sequence(seq_list, batch_first=True, padding_value=0)\n",
        "        seq_data[key] = seq_padded\n",
        "    # Record lengths\n",
        "    seq_lengths = [len(seq['timestamp']) for seq in sequences]\n",
        "\n",
        "    # Convert seq_lengths to tensor\n",
        "    seq_lengths = torch.tensor(seq_lengths, dtype=torch.long)\n",
        "\n",
        "    # Process target (exclude 'timestamp' and 'position' as they're not in target)\n",
        "    for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_target[key] = []\n",
        "        for target in targets:\n",
        "            if target[key] is not None:\n",
        "                batch_target[key].append(target[key])\n",
        "            else:\n",
        "                batch_target[key].append(-100 if key not in ['quantity', 'price'] else 0.0)\n",
        "\n",
        "        # Convert to tensor and create mask\n",
        "        if key in ['quantity', 'price']:\n",
        "            # For continuous features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != 0.0 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.float)\n",
        "        else:\n",
        "            # For categorical features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != -100 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.long)\n",
        "\n",
        "    return batch_data, batch_target, seq_data, seq_lengths\n",
        "\n",
        "# Training and Testing Loop\n",
        "def train_model(model_class, model_params, dataset_params, training_params):\n",
        "    # Create Dataset and DataLoader\n",
        "    dataset = MaskedOrderDataset(**dataset_params)\n",
        "    dataloader = DataLoader(dataset, batch_size=training_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    # Create model\n",
        "    model = model_class(**model_params).to(training_params['device'])\n",
        "    optimizer = optim.Adam(model.parameters(), lr=training_params['learning_rate'])\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(training_params['num_epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_data, batch_target, seq_data, seq_lengths in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move data to device\n",
        "            device = training_params.get('device', 'cpu')\n",
        "            batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
        "            batch_target = {k: v.to(device) for k, v in batch_target.items()}\n",
        "            seq_data = {k: v.to(device) for k, v in seq_data.items()}\n",
        "            seq_lengths = seq_lengths.to(device)\n",
        "\n",
        "            outputs = model(batch_data, seq_data, seq_lengths)\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            # Compute loss for each feature\n",
        "            for key in ['security_id', 'buy_sell', 'add_modify_delete', 'distance']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        loss_feature = criterion_ce(outputs[key], target)\n",
        "                        loss += loss_feature\n",
        "\n",
        "            for key in ['quantity', 'price']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        output = outputs[key].squeeze()\n",
        "                        loss_feature = criterion_l1(output[mask], target[mask])\n",
        "                        loss += loss_feature\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Beam Search Generation Function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# [The code above remains unchanged until the generate_sequences function]\n",
        "\n",
        "# Beam Search Generation Function\n",
        "def generate_sequences(model, past_data, security_id, num_timesteps, beam_width, num_samples, device='cpu'):\n",
        "    \"\"\"\n",
        "    Generate sequences using beam search.\n",
        "\n",
        "    Args:\n",
        "        model: Trained model.\n",
        "        past_data: Dictionary containing past sequences.\n",
        "        security_id: The security ID to generate sequences for.\n",
        "        num_timesteps: Number of timesteps to generate.\n",
        "        beam_width: Beam width.\n",
        "        num_samples: Number of samples to generate.\n",
        "        device: Device to run the computations on.\n",
        "\n",
        "    Returns:\n",
        "        generated_sequences: A list of generated sequences.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Initialize the beam with the past_data\n",
        "        # Each beam entry is a tuple (sequence, cumulative_log_prob)\n",
        "        beam = [({'timestamp': past_data['timestamp'],\n",
        "                  'position': past_data['position'],\n",
        "                  'security_id': past_data['security_id'],\n",
        "                  'buy_sell': past_data['buy_sell'],\n",
        "                  'add_modify_delete': past_data['add_modify_delete'],\n",
        "                  'quantity': past_data['quantity'],\n",
        "                  'price': past_data['price'],\n",
        "                  'distance': past_data['distance']},\n",
        "                 0.0)]  # Start with log probability 0\n",
        "\n",
        "        for t in range(num_timesteps):\n",
        "            new_beam = []\n",
        "            for seq, cum_log_prob in beam:\n",
        "                # Prepare input data\n",
        "                # Use the last max_seq_len elements\n",
        "                seq_len = len(seq['timestamp'])\n",
        "                start_idx = max(0, seq_len - model.lstm_input_dim)\n",
        "                seq_data = {key: torch.tensor(seq[key][start_idx:]).unsqueeze(0).to(device) for key in seq}\n",
        "                seq_lengths = torch.tensor([seq_data['timestamp'].shape[1]]).to(device)\n",
        "\n",
        "                # Create a sample with masked features (except security_id and timestamp)\n",
        "                sample = {\n",
        "                    'timestamp': torch.tensor([seq['timestamp'][-1] + 1]).to(device),\n",
        "                    'position': torch.tensor([seq['position'][-1] + 1]).to(device),\n",
        "                    'security_id': torch.tensor([security_id]).to(device),\n",
        "                    'buy_sell': torch.tensor([model.buy_sell_mask]).to(device),\n",
        "                    'add_modify_delete': torch.tensor([model.add_modify_delete_mask]).to(device),\n",
        "                    'quantity': torch.tensor([0.0]).to(device),\n",
        "                    'price': torch.tensor([0.0]).to(device),\n",
        "                    'distance': torch.tensor([model.distance_mask]).to(device)\n",
        "                }\n",
        "\n",
        "                # Predict missing features\n",
        "                outputs = model(sample, seq_data, seq_lengths)\n",
        "\n",
        "                # For each categorical feature, get top N predictions\n",
        "                candidates = []\n",
        "\n",
        "                # Adjust topk for buy_sell\n",
        "                buy_sell_probs = F.softmax(outputs['buy_sell'], dim=-1)\n",
        "                num_buy_sell_classes = buy_sell_probs.size(-1)\n",
        "                buy_sell_topk_k = min(beam_width, num_buy_sell_classes)\n",
        "                buy_sell_topk = torch.topk(buy_sell_probs, buy_sell_topk_k)\n",
        "\n",
        "                # Adjust topk for add_modify_delete\n",
        "                add_modify_delete_probs = F.softmax(outputs['add_modify_delete'], dim=-1)\n",
        "                num_amd_classes = add_modify_delete_probs.size(-1)\n",
        "                amd_topk_k = min(beam_width, num_amd_classes)\n",
        "                amd_topk = torch.topk(add_modify_delete_probs, amd_topk_k)\n",
        "\n",
        "                # Adjust topk for distance\n",
        "                distance_probs = F.softmax(outputs['distance'], dim=-1)\n",
        "                num_distance_classes = distance_probs.size(-1)\n",
        "                distance_topk_k = min(beam_width, num_distance_classes)\n",
        "                distance_topk = torch.topk(distance_probs, distance_topk_k)\n",
        "\n",
        "                # For continuous features, we can use the predicted value directly\n",
        "                quantity_pred = outputs['quantity'].item()\n",
        "                price_pred = outputs['price'].item()\n",
        "\n",
        "                # Generate combinations of top predictions\n",
        "                for i in range(buy_sell_topk_k):\n",
        "                    for j in range(amd_topk_k):\n",
        "                        for k in range(distance_topk_k):\n",
        "                            new_seq = {key: seq[key] + [sample[key].item()] for key in seq}\n",
        "                            new_seq['buy_sell'][-1] = buy_sell_topk.indices[0][i].item()\n",
        "                            new_seq['add_modify_delete'][-1] = amd_topk.indices[0][j].item()\n",
        "                            new_seq['distance'][-1] = distance_topk.indices[0][k].item()\n",
        "                            new_seq['quantity'][-1] = quantity_pred\n",
        "                            new_seq['price'][-1] = price_pred\n",
        "\n",
        "                            # Compute new cumulative log probability\n",
        "                            log_prob = cum_log_prob + \\\n",
        "                                       torch.log(buy_sell_topk.values[0][i] + 1e-9).item() + \\\n",
        "                                       torch.log(amd_topk.values[0][j] + 1e-9).item() + \\\n",
        "                                       torch.log(distance_topk.values[0][k] + 1e-9).item()\n",
        "                            candidates.append((new_seq, log_prob))\n",
        "\n",
        "                # Keep top beam_width candidates\n",
        "                candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "                new_beam.extend(candidates[:beam_width])\n",
        "\n",
        "            # Keep top beam_width sequences\n",
        "            new_beam.sort(key=lambda x: x[1], reverse=True)\n",
        "            beam = new_beam[:beam_width]\n",
        "\n",
        "        # After generation, sample from the beam to get the required number of samples\n",
        "        generated_sequences = [seq for seq, _ in beam[:num_samples]]\n",
        "        return generated_sequences\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Training parameters\n",
        "    training_params = {\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 0.001,\n",
        "        'num_epochs': 5,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    }\n",
        "\n",
        "    # Dataset parameters\n",
        "    dataset_params = {\n",
        "        'num_samples': 5000,\n",
        "        'mask_prob': 0.15,\n",
        "        'max_seq_len': 50\n",
        "    }\n",
        "\n",
        "    # Model parameters for OrderModel\n",
        "    model_params = {\n",
        "        'N_sec_ids': 100,\n",
        "        'N_distance_bins': 10,\n",
        "        'embedding_dim': 32,\n",
        "        'hidden_dim': 64\n",
        "    }\n",
        "\n",
        "    # Train OrderModel\n",
        "    print(\"Training OrderModel...\")\n",
        "    model = train_model(OrderModel, model_params, dataset_params, training_params)\n",
        "\n",
        "    # Generate sequences using beam search\n",
        "    print(\"\\nGenerating sequences using beam search...\")\n",
        "    # Prepare past_data\n",
        "    past_data = {\n",
        "        'timestamp': [1000, 1001, 1002],\n",
        "        'position': [0, 1, 2],\n",
        "        'security_id': [5, 5, 5],\n",
        "        'buy_sell': [0, 1, 0],\n",
        "        'add_modify_delete': [0, 1, 2],\n",
        "        'quantity': [500.0, 600.0, 700.0],\n",
        "        'price': [50.0, 51.0, 52.0],\n",
        "        'distance': [3, 2, 1]\n",
        "    }\n",
        "\n",
        "    # Parameters for generation\n",
        "    security_id = 5\n",
        "    num_timesteps = 5\n",
        "    beam_width = 3\n",
        "    num_samples = 100\n",
        "\n",
        "    generated_sequences = generate_sequences(\n",
        "        model=model,\n",
        "        past_data=past_data,\n",
        "        security_id=security_id,\n",
        "        num_timesteps=num_timesteps,\n",
        "        beam_width=beam_width,\n",
        "        num_samples=num_samples,\n",
        "        device=training_params['device']\n",
        "    )\n",
        "\n",
        "    # Compute distribution of buys vs sells\n",
        "    total_buy = 0\n",
        "    total_sell = 0\n",
        "    total_actions = 0\n",
        "\n",
        "    for seq in generated_sequences:\n",
        "        buy_sell_seq = seq['buy_sell'][-num_timesteps:]  # Only consider generated timesteps\n",
        "        total_buy += buy_sell_seq.count(0)\n",
        "        total_sell += buy_sell_seq.count(1)\n",
        "        total_actions += len(buy_sell_seq)\n",
        "\n",
        "    buy_percentage = (total_buy / total_actions) * 100 if total_actions > 0 else 0\n",
        "    sell_percentage = (total_sell / total_actions) * 100 if total_actions > 0 else 0\n",
        "\n",
        "    print(f\"\\nGenerated {num_samples} sequences of {num_timesteps} timesteps each.\")\n",
        "    print(f\"Buy actions: {buy_percentage:.2f}%\")\n",
        "    print(f\"Sell actions: {sell_percentage:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsIUq3D9JxZo",
        "outputId": "bd5d6d2d-af53-4af9-a4c7-2d2052bf03c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training OrderModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-fa16ee2492a3>:279: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 375.6108235158738\n",
            "Epoch 2, Loss: 349.5281865794188\n",
            "Epoch 3, Loss: 321.91743964905953\n",
            "Epoch 4, Loss: 304.81262012651774\n",
            "Epoch 5, Loss: 295.27519867526496\n",
            "\n",
            "Generating sequences using beam search...\n",
            "\n",
            "Generated 3 sequences of 5 timesteps each.\n",
            "Buy actions: 40.00%\n",
            "Sell actions: 60.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Parameters for generation\n",
        "    security_id = 5\n",
        "    num_timesteps = 50\n",
        "    beam_width = 45\n",
        "    num_samples = 130\n",
        "\n",
        "    generated_sequences = generate_sequences(\n",
        "        model=model,\n",
        "        past_data=past_data,\n",
        "        security_id=security_id,\n",
        "        num_timesteps=num_timesteps,\n",
        "        beam_width=beam_width,\n",
        "        num_samples=num_samples,\n",
        "        device=training_params['device']\n",
        "    )\n",
        "\n",
        "    # Compute distribution of buys vs sells\n",
        "    total_buy = 0\n",
        "    total_sell = 0\n",
        "    total_actions = 0\n",
        "\n",
        "    for seq in generated_sequences:\n",
        "        buy_sell_seq = seq['buy_sell'][-num_timesteps:]  # Only consider generated timesteps\n",
        "        total_buy += buy_sell_seq.count(0)\n",
        "        total_sell += buy_sell_seq.count(1)\n",
        "        total_actions += len(buy_sell_seq)\n",
        "\n",
        "    buy_percentage = (total_buy / total_actions) * 100 if total_actions > 0 else 0\n",
        "    sell_percentage = (total_sell / total_actions) * 100 if total_actions > 0 else 0\n",
        "\n",
        "    print(f\"\\nGenerated {num_samples} sequences of {num_timesteps} timesteps each.\")\n",
        "    print(f\"Buy actions: {buy_percentage:.2f}%\")\n",
        "    print(f\"Sell actions: {sell_percentage:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB36GcVVLXMH",
        "outputId": "1dc5022b-1ff7-467a-ac51-b7d160fa387f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated 130 sequences of 50 timesteps each.\n",
            "Buy actions: 91.42%\n",
            "Sell actions: 8.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Define the Dataset\n",
        "class MaskedOrderDataset(Dataset):\n",
        "    def __init__(self, num_samples, mask_prob=0.15, max_seq_len=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.N_sec_ids = 100  # Number of unique securities\n",
        "        self.N_distance_bins = 10  # Number of distance bins\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Generate synthetic data\n",
        "        self.timestamps = torch.randint(0, 1000, (num_samples,))\n",
        "        self.security_ids = torch.randint(0, self.N_sec_ids, (num_samples,))\n",
        "        self.buy_sell = torch.randint(0, 2, (num_samples,))  # 0: buy, 1: sell\n",
        "        self.add_modify_delete = torch.randint(0, 3, (num_samples,))  # 0: add, 1: modify, 2: delete\n",
        "        self.quantity = torch.randint(1, 1000, (num_samples,)).float()\n",
        "        self.price = torch.rand(num_samples) * 100  # Prices between 0 and 100\n",
        "        self.distance = torch.randint(0, self.N_distance_bins, (num_samples,))\n",
        "\n",
        "        # Sort the data by timestamps (ascending)\n",
        "        sorted_indices = torch.argsort(self.timestamps)\n",
        "        self.timestamps = self.timestamps[sorted_indices]\n",
        "        self.security_ids = self.security_ids[sorted_indices]\n",
        "        self.buy_sell = self.buy_sell[sorted_indices]\n",
        "        self.add_modify_delete = self.add_modify_delete[sorted_indices]\n",
        "        self.quantity = self.quantity[sorted_indices]\n",
        "        self.price = self.price[sorted_indices]\n",
        "        self.distance = self.distance[sorted_indices]\n",
        "\n",
        "        # Define mask indices\n",
        "        self.security_id_mask = self.N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = self.N_distance_bins\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence from idx to end, up to max_seq_len\n",
        "        end_idx = min(idx + self.max_seq_len, self.num_samples)\n",
        "        seq_len = end_idx - idx\n",
        "        sequence = {\n",
        "            'timestamp': self.timestamps[idx:end_idx],\n",
        "            'security_id': self.security_ids[idx:end_idx],\n",
        "            'buy_sell': self.buy_sell[idx:end_idx],\n",
        "            'add_modify_delete': self.add_modify_delete[idx:end_idx],\n",
        "            'quantity': self.quantity[idx:end_idx],\n",
        "            'price': self.price[idx:end_idx],\n",
        "            'distance': self.distance[idx:end_idx],\n",
        "            'position': torch.arange(seq_len)  # Row number\n",
        "        }\n",
        "\n",
        "        # Apply masking logic to the first element (idx)\n",
        "        sample = {key: sequence[key][0] for key in sequence}\n",
        "        masked_sample = sample.copy()\n",
        "        target = {}\n",
        "\n",
        "        # List of features to potentially mask\n",
        "        maskable_keys = ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']\n",
        "\n",
        "        # Decide how many features to mask (at least one)\n",
        "        num_features_to_mask = random.randint(1, len(maskable_keys))\n",
        "\n",
        "        # Randomly select features to mask\n",
        "        features_to_mask = random.sample(maskable_keys, num_features_to_mask)\n",
        "\n",
        "        for key in maskable_keys:\n",
        "            if key in features_to_mask:\n",
        "                # Mask the feature\n",
        "                target[key] = sample[key]\n",
        "                if key == 'security_id':\n",
        "                    masked_sample[key] = self.security_id_mask\n",
        "                elif key == 'buy_sell':\n",
        "                    masked_sample[key] = self.buy_sell_mask\n",
        "                elif key == 'add_modify_delete':\n",
        "                    masked_sample[key] = self.add_modify_delete_mask\n",
        "                elif key == 'distance':\n",
        "                    masked_sample[key] = self.distance_mask\n",
        "                elif key in ['quantity', 'price']:\n",
        "                    masked_sample[key] = 0.0  # For continuous features, use 0.0 as masked value\n",
        "            else:\n",
        "                target[key] = None  # Not masked\n",
        "\n",
        "        # Return masked_sample, target, and the sequence starting from idx\n",
        "        return masked_sample, target, sequence\n",
        "\n",
        "# Learnable Positional Encoder\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(PositionalEncoder, self).__init__()\n",
        "        self.timestamp_encoder = nn.Linear(1, embedding_dim)\n",
        "        self.position_encoder = nn.Embedding(1000, embedding_dim)  # Assume max 1000 positions\n",
        "\n",
        "    def forward(self, timestamps, positions):\n",
        "        timestamp_emb = self.timestamp_encoder(timestamps.unsqueeze(-1).float())\n",
        "        position_emb = self.position_encoder(positions)\n",
        "        return timestamp_emb + position_emb\n",
        "\n",
        "# Base Model Class\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Order Model with Positional Encoder\n",
        "class OrderModel(BaseModel):\n",
        "    def __init__(self, N_sec_ids, N_distance_bins, embedding_dim=32, hidden_dim=64):\n",
        "        super(OrderModel, self).__init__()\n",
        "\n",
        "        # Mask indices\n",
        "        self.security_id_mask = N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = N_distance_bins\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.security_id_embedding = nn.Embedding(N_sec_ids + 1, embedding_dim, padding_idx=self.security_id_mask)\n",
        "        self.buy_sell_embedding = nn.Embedding(3, embedding_dim, padding_idx=self.buy_sell_mask)  # 0,1,2(mask)\n",
        "        self.add_modify_delete_embedding = nn.Embedding(4, embedding_dim, padding_idx=self.add_modify_delete_mask)  # 0,1,2,3(mask)\n",
        "        self.distance_embedding = nn.Embedding(N_distance_bins + 1, embedding_dim, padding_idx=self.distance_mask)\n",
        "\n",
        "        # Linear layers for continuous features\n",
        "        self.quantity_linear = nn.Linear(1, embedding_dim)\n",
        "        self.price_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # Positional Encoder\n",
        "        self.positional_encoder = PositionalEncoder(embedding_dim)\n",
        "\n",
        "        # LSTM for sequences\n",
        "        self.lstm_input_dim = embedding_dim * 7  # Number of features\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Final fully connected layers\n",
        "        self.fc1 = nn.Linear(embedding_dim * 7 + hidden_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output heads\n",
        "        self.security_id_head = nn.Linear(128, N_sec_ids)\n",
        "        self.buy_sell_head = nn.Linear(128, 2)\n",
        "        self.add_modify_delete_head = nn.Linear(128, 3)\n",
        "        self.distance_head = nn.Linear(128, N_distance_bins)\n",
        "        self.quantity_head = nn.Linear(128, 1)\n",
        "        self.price_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x is a dictionary of features for the masked sample\n",
        "        # seq_data is a dictionary of sequences\n",
        "        # seq_lengths is a list of sequence lengths\n",
        "\n",
        "        batch_size = x['timestamp'].shape[0]\n",
        "\n",
        "        # Process the masked sample\n",
        "        timestamp = x['timestamp']\n",
        "        position = x['position']\n",
        "        security_id = x['security_id']\n",
        "        buy_sell = x['buy_sell']\n",
        "        add_modify_delete = x['add_modify_delete']\n",
        "        quantity = x['quantity'].unsqueeze(1)\n",
        "        price = x['price'].unsqueeze(1)\n",
        "        distance = x['distance']\n",
        "\n",
        "        # Embeddings\n",
        "        positional_emb = self.positional_encoder(timestamp, position)\n",
        "        security_id_emb = self.security_id_embedding(security_id)\n",
        "        buy_sell_emb = self.buy_sell_embedding(buy_sell)\n",
        "        add_modify_delete_emb = self.add_modify_delete_embedding(add_modify_delete)\n",
        "        quantity_emb = self.quantity_linear(quantity)\n",
        "        price_emb = self.price_linear(price)\n",
        "        distance_emb = self.distance_embedding(distance)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        sample_emb = torch.cat([positional_emb,\n",
        "                                security_id_emb,\n",
        "                                buy_sell_emb,\n",
        "                                add_modify_delete_emb,\n",
        "                                quantity_emb,\n",
        "                                price_emb,\n",
        "                                distance_emb], dim=1)  # Shape: (batch_size, embedding_dim * 7)\n",
        "\n",
        "        # Process the sequence data\n",
        "        # For each feature in seq_data, get embeddings\n",
        "\n",
        "        seq_timestamp = seq_data['timestamp']\n",
        "        seq_position = seq_data['position']\n",
        "        seq_security_id = seq_data['security_id']\n",
        "        seq_buy_sell = seq_data['buy_sell']\n",
        "        seq_add_modify_delete = seq_data['add_modify_delete']\n",
        "        seq_quantity = seq_data['quantity']\n",
        "        seq_price = seq_data['price']\n",
        "        seq_distance = seq_data['distance']\n",
        "\n",
        "        # Embeddings for sequence data\n",
        "        seq_positional_emb = self.positional_encoder(seq_timestamp, seq_position)\n",
        "        seq_security_id_emb = self.security_id_embedding(seq_security_id)\n",
        "        seq_buy_sell_emb = self.buy_sell_embedding(seq_buy_sell)\n",
        "        seq_add_modify_delete_emb = self.add_modify_delete_embedding(seq_add_modify_delete)\n",
        "        seq_quantity_emb = self.quantity_linear(seq_quantity.unsqueeze(-1))\n",
        "        seq_price_emb = self.price_linear(seq_price.unsqueeze(-1))\n",
        "        seq_distance_emb = self.distance_embedding(seq_distance)\n",
        "\n",
        "        # Concatenate sequence embeddings\n",
        "        seq_emb = torch.cat([seq_positional_emb,\n",
        "                             seq_security_id_emb,\n",
        "                             seq_buy_sell_emb,\n",
        "                             seq_add_modify_delete_emb,\n",
        "                             seq_quantity_emb,\n",
        "                             seq_price_emb,\n",
        "                             seq_distance_emb], dim=2)  # Shape: (batch_size, seq_len, embedding_dim * 7)\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = pack_padded_sequence(seq_emb, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb)\n",
        "\n",
        "        # Get the last hidden state for each sequence\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Combine the sample embedding with the sequence context\n",
        "        combined = torch.cat([sample_emb, seq_context], dim=1)  # Shape: (batch_size, embedding_dim * 7 + hidden_dim)\n",
        "\n",
        "        # Forward pass\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Outputs\n",
        "        outputs = {\n",
        "            'security_id': self.security_id_head(x),\n",
        "            'buy_sell': self.buy_sell_head(x),\n",
        "            'add_modify_delete': self.add_modify_delete_head(x),\n",
        "            'distance': self.distance_head(x),\n",
        "            'quantity': self.quantity_head(x),\n",
        "            'price': self.price_head(x)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Additional Models\n",
        "\n",
        "class MatrixRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(input_size, input_size))\n",
        "        self.B = nn.Parameter(torch.randn(input_size, len(output_keys)))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: batch_data concatenated into a single vector\n",
        "        x_vector = torch.cat([x[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else x[key].unsqueeze(-1).float() for key in x], dim=1)\n",
        "        x_vector = x_vector.view(x_vector.size(0), -1)\n",
        "        out = x_vector @ self.A @ self.B  # Shape: (batch_size, num_outputs)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = out[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class LogisticRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: batch_data concatenated into a single vector\n",
        "        x_vector = torch.cat([x[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else x[key].unsqueeze(-1).float() for key in x], dim=1)\n",
        "        x_vector = x_vector.view(x_vector.size(0), -1)\n",
        "        out = self.linear(x_vector)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = out[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class CNNModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        seq_vector = seq_vector.permute(0, 2, 1)  # (batch_size, num_features, seq_len)\n",
        "        x = self.relu(self.conv1(seq_vector))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = x[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_keys):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        packed_seq_emb = pack_padded_sequence(seq_vector, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        h0 = torch.zeros(self.lstm.num_layers, seq_vector.size(0), self.lstm.hidden_size).to(seq_vector.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, seq_vector.size(0), self.lstm.hidden_size).to(seq_vector.device)\n",
        "\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb, (h0, c0))\n",
        "\n",
        "        # Get the last hidden state\n",
        "        seq_context = h_n[-1​⬤"
      ],
      "metadata": {
        "id": "559vmJQKWopg",
        "outputId": "b1db5664-9e62-47c1-fa64-a512a4420d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (<ipython-input-7-9eb5d33bcc7f>, line 377)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-9eb5d33bcc7f>\"\u001b[0;36m, line \u001b[0;32m377\u001b[0m\n\u001b[0;31m    seq_context = h_n[-1​⬤\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Define the Dataset\n",
        "class MaskedOrderDataset(Dataset):\n",
        "    def __init__(self, num_samples, mask_prob=0.15, max_seq_len=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.N_sec_ids = 100  # Number of unique securities\n",
        "        self.N_distance_bins = 10  # Number of distance bins\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Generate synthetic data\n",
        "        self.timestamps = torch.randint(0, 1000, (num_samples,))\n",
        "        self.security_ids = torch.randint(0, self.N_sec_ids, (num_samples,))\n",
        "        self.buy_sell = torch.randint(0, 2, (num_samples,))  # 0: buy, 1: sell\n",
        "        self.add_modify_delete = torch.randint(0, 3, (num_samples,))  # 0: add, 1: modify, 2: delete\n",
        "        self.quantity = torch.randint(1, 1000, (num_samples,)).float()\n",
        "        self.price = torch.rand(num_samples) * 100  # Prices between 0 and 100\n",
        "        self.distance = torch.randint(0, self.N_distance_bins, (num_samples,))\n",
        "\n",
        "        # Sort the data by timestamps (ascending)\n",
        "        sorted_indices = torch.argsort(self.timestamps)\n",
        "        self.timestamps = self.timestamps[sorted_indices]\n",
        "        self.security_ids = self.security_ids[sorted_indices]\n",
        "        self.buy_sell = self.buy_sell[sorted_indices]\n",
        "        self.add_modify_delete = self.add_modify_delete[sorted_indices]\n",
        "        self.quantity = self.quantity[sorted_indices]\n",
        "        self.price = self.price[sorted_indices]\n",
        "        self.distance = self.distance[sorted_indices]\n",
        "\n",
        "        # Define mask indices\n",
        "        self.security_id_mask = self.N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = self.N_distance_bins\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence from idx to end, up to max_seq_len\n",
        "        end_idx = min(idx + self.max_seq_len, self.num_samples)\n",
        "        seq_len = end_idx - idx\n",
        "        sequence = {\n",
        "            'timestamp': self.timestamps[idx:end_idx],\n",
        "            'security_id': self.security_ids[idx:end_idx],\n",
        "            'buy_sell': self.buy_sell[idx:end_idx],\n",
        "            'add_modify_delete': self.add_modify_delete[idx:end_idx],\n",
        "            'quantity': self.quantity[idx:end_idx],\n",
        "            'price': self.price[idx:end_idx],\n",
        "            'distance': self.distance[idx:end_idx],\n",
        "            'position': torch.arange(seq_len)  # Row number\n",
        "        }\n",
        "\n",
        "        # Apply masking logic to the first element (idx)\n",
        "        sample = {key: sequence[key][0] for key in sequence}\n",
        "        masked_sample = sample.copy()\n",
        "        target = {}\n",
        "\n",
        "        # List of features to potentially mask\n",
        "        maskable_keys = ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']\n",
        "\n",
        "        # Decide how many features to mask (at least one)\n",
        "        num_features_to_mask = random.randint(1, len(maskable_keys))\n",
        "\n",
        "        # Randomly select features to mask\n",
        "        features_to_mask = random.sample(maskable_keys, num_features_to_mask)\n",
        "\n",
        "        for key in maskable_keys:\n",
        "            if key in features_to_mask:\n",
        "                # Mask the feature\n",
        "                target[key] = sample[key]\n",
        "                if key == 'security_id':\n",
        "                    masked_sample[key] = self.security_id_mask\n",
        "                elif key == 'buy_sell':\n",
        "                    masked_sample[key] = self.buy_sell_mask\n",
        "                elif key == 'add_modify_delete':\n",
        "                    masked_sample[key] = self.add_modify_delete_mask\n",
        "                elif key == 'distance':\n",
        "                    masked_sample[key] = self.distance_mask\n",
        "                elif key in ['quantity', 'price']:\n",
        "                    masked_sample[key] = 0.0  # For continuous features, use 0.0 as masked value\n",
        "            else:\n",
        "                target[key] = None  # Not masked\n",
        "\n",
        "        # Return masked_sample, target, and the sequence starting from idx\n",
        "        return masked_sample, target, sequence\n",
        "\n",
        "# Learnable Positional Encoder\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(PositionalEncoder, self).__init__()\n",
        "        self.timestamp_encoder = nn.Linear(1, embedding_dim)\n",
        "        self.position_encoder = nn.Embedding(1000, embedding_dim)  # Assume max 1000 positions\n",
        "\n",
        "    def forward(self, timestamps, positions):\n",
        "        timestamp_emb = self.timestamp_encoder(timestamps.unsqueeze(-1).float())\n",
        "        position_emb = self.position_encoder(positions)\n",
        "        return timestamp_emb + position_emb\n",
        "\n",
        "# Base Model Class\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Order Model with Positional Encoder\n",
        "class OrderModel(BaseModel):\n",
        "    def __init__(self, N_sec_ids, N_distance_bins, embedding_dim=32, hidden_dim=64):\n",
        "        super(OrderModel, self).__init__()\n",
        "\n",
        "        # Mask indices\n",
        "        self.security_id_mask = N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = N_distance_bins\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.security_id_embedding = nn.Embedding(N_sec_ids + 1, embedding_dim, padding_idx=self.security_id_mask)\n",
        "        self.buy_sell_embedding = nn.Embedding(3, embedding_dim, padding_idx=self.buy_sell_mask)  # 0,1,2(mask)\n",
        "        self.add_modify_delete_embedding = nn.Embedding(4, embedding_dim, padding_idx=self.add_modify_delete_mask)  # 0,1,2,3(mask)\n",
        "        self.distance_embedding = nn.Embedding(N_distance_bins + 1, embedding_dim, padding_idx=self.distance_mask)\n",
        "\n",
        "        # Linear layers for continuous features\n",
        "        self.quantity_linear = nn.Linear(1, embedding_dim)\n",
        "        self.price_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # Positional Encoder\n",
        "        self.positional_encoder = PositionalEncoder(embedding_dim)\n",
        "\n",
        "        # LSTM for sequences\n",
        "        self.lstm_input_dim = embedding_dim * 7  # Number of features\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Final fully connected layers\n",
        "        self.fc1 = nn.Linear(embedding_dim * 7 + hidden_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output heads\n",
        "        self.security_id_head = nn.Linear(128, N_sec_ids)\n",
        "        self.buy_sell_head = nn.Linear(128, 2)\n",
        "        self.add_modify_delete_head = nn.Linear(128, 3)\n",
        "        self.distance_head = nn.Linear(128, N_distance_bins)\n",
        "        self.quantity_head = nn.Linear(128, 1)\n",
        "        self.price_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x is a dictionary of features for the masked sample\n",
        "        # seq_data is a dictionary of sequences\n",
        "        # seq_lengths is a list of sequence lengths\n",
        "\n",
        "        batch_size = x['timestamp'].shape[0]\n",
        "\n",
        "        # Process the masked sample\n",
        "        timestamp = x['timestamp']\n",
        "        position = x['position']\n",
        "        security_id = x['security_id']\n",
        "        buy_sell = x['buy_sell']\n",
        "        add_modify_delete = x['add_modify_delete']\n",
        "        quantity = x['quantity'].unsqueeze(1)\n",
        "        price = x['price'].unsqueeze(1)\n",
        "        distance = x['distance']\n",
        "\n",
        "        # Embeddings\n",
        "        positional_emb = self.positional_encoder(timestamp, position)\n",
        "        security_id_emb = self.security_id_embedding(security_id)\n",
        "        buy_sell_emb = self.buy_sell_embedding(buy_sell)\n",
        "        add_modify_delete_emb = self.add_modify_delete_embedding(add_modify_delete)\n",
        "        quantity_emb = self.quantity_linear(quantity)\n",
        "        price_emb = self.price_linear(price)\n",
        "        distance_emb = self.distance_embedding(distance)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        sample_emb = torch.cat([positional_emb,\n",
        "                                security_id_emb,\n",
        "                                buy_sell_emb,\n",
        "                                add_modify_delete_emb,\n",
        "                                quantity_emb,\n",
        "                                price_emb,\n",
        "                                distance_emb], dim=1)  # Shape: (batch_size, embedding_dim * 7)\n",
        "\n",
        "        # Process the sequence data\n",
        "        # For each feature in seq_data, get embeddings\n",
        "\n",
        "        seq_timestamp = seq_data['timestamp']\n",
        "        seq_position = seq_data['position']\n",
        "        seq_security_id = seq_data['security_id']\n",
        "        seq_buy_sell = seq_data['buy_sell']\n",
        "        seq_add_modify_delete = seq_data['add_modify_delete']\n",
        "        seq_quantity = seq_data['quantity']\n",
        "        seq_price = seq_data['price']\n",
        "        seq_distance = seq_data['distance']\n",
        "\n",
        "        # Embeddings for sequence data\n",
        "        seq_positional_emb = self.positional_encoder(seq_timestamp, seq_position)\n",
        "        seq_security_id_emb = self.security_id_embedding(seq_security_id)\n",
        "        seq_buy_sell_emb = self.buy_sell_embedding(seq_buy_sell)\n",
        "        seq_add_modify_delete_emb = self.add_modify_delete_embedding(seq_add_modify_delete)\n",
        "        seq_quantity_emb = self.quantity_linear(seq_quantity.unsqueeze(-1))\n",
        "        seq_price_emb = self.price_linear(seq_price.unsqueeze(-1))\n",
        "        seq_distance_emb = self.distance_embedding(seq_distance)\n",
        "\n",
        "        # Concatenate sequence embeddings\n",
        "        seq_emb = torch.cat([seq_positional_emb,\n",
        "                             seq_security_id_emb,\n",
        "                             seq_buy_sell_emb,\n",
        "                             seq_add_modify_delete_emb,\n",
        "                             seq_quantity_emb,\n",
        "                             seq_price_emb,\n",
        "                             seq_distance_emb], dim=2)  # Shape: (batch_size, seq_len, embedding_dim * 7)\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = pack_padded_sequence(seq_emb, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb)\n",
        "\n",
        "        # Get the last hidden state for each sequence\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Combine the sample embedding with the sequence context\n",
        "        combined = torch.cat([sample_emb, seq_context], dim=1)  # Shape: (batch_size, embedding_dim * 7 + hidden_dim)\n",
        "\n",
        "        # Forward pass\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Outputs\n",
        "        outputs = {\n",
        "            'security_id': self.security_id_head(x),\n",
        "            'buy_sell': self.buy_sell_head(x),\n",
        "            'add_modify_delete': self.add_modify_delete_head(x),\n",
        "            'distance': self.distance_head(x),\n",
        "            'quantity': self.quantity_head(x),\n",
        "            'price': self.price_head(x)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Additional Models\n",
        "\n",
        "class MatrixRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(input_size, input_size))\n",
        "        self.B = nn.Parameter(torch.randn(input_size, len(output_keys)))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: batch_data concatenated into a single vector\n",
        "        x_vector = torch.cat([x[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else x[key].unsqueeze(-1).float() for key in x], dim=1)\n",
        "        x_vector = x_vector.view(x_vector.size(0), -1)\n",
        "        out = x_vector @ self.A @ self.B  # Shape: (batch_size, num_outputs)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = out[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class LogisticRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: batch_data concatenated into a single vector\n",
        "        x_vector = torch.cat([x[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else x[key].unsqueeze(-1).float() for key in x], dim=1)\n",
        "        x_vector = x_vector.view(x_vector.size(0), -1)\n",
        "        out = self.linear(x_vector)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = out[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class CNNModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        seq_vector = seq_vector.permute(0, 2, 1)  # (batch_size, num_features, seq_len)\n",
        "        x = self.relu(self.conv1(seq_vector))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = x[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_keys):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        packed_seq_emb = pack_padded_sequence(seq_vector, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        h0 = torch.zeros(self.lstm.num_layers, seq_vector.size(0), self.lstm.hidden_size).to(seq_vector.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, seq_vector.size(0), self.lstm.hidden_size).to(seq_vector.device)\n",
        "\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb, (h0, c0))\n",
        "\n",
        "        # Get the last hidden state\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        x = self.fc(seq_context)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = x[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class TransformerModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Transformer Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures global dependencies.\n",
        "    - Parallelizable.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Requires large datasets.\n",
        "    - Computationally intensive.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_heads, num_layers, output_keys):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.positional_encoder = PositionalEncoder(input_size)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=num_heads)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(input_size, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        # Add positional encoding\n",
        "        positions = torch.arange(0, seq_vector.size(1), device=seq_vector.device).unsqueeze(0).repeat(seq_vector.size(0), 1)\n",
        "        seq_vector = seq_vector + self.positional_encoder(positions, positions)\n",
        "\n",
        "        # Transformer expects input shape (seq_len, batch_size, feature_dim)\n",
        "        seq_vector = seq_vector.permute(1, 0, 2)\n",
        "        transformer_output = self.transformer_encoder(seq_vector)\n",
        "        # Take the output corresponding to the last position\n",
        "        x = transformer_output[-1, :, :]\n",
        "        x = self.fc(x)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = x[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Collate function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    # batch is a list of (masked_sample, target, sequence)\n",
        "    batch_size = len(batch)\n",
        "    masked_samples = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    sequences = [item[2] for item in batch]\n",
        "\n",
        "    # Convert masked_samples to tensors\n",
        "    batch_data = {}\n",
        "    batch_target = {}\n",
        "    seq_data = {}\n",
        "    seq_lengths = []\n",
        "\n",
        "    # Process data\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_data[key] = torch.tensor([sample[key] for sample in masked_samples])\n",
        "\n",
        "    # Process sequences\n",
        "    # Sequences are variable-length\n",
        "    # For each key, we have a list of sequences\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        seq_list = [torch.tensor(seq[key]) for seq in sequences]\n",
        "        seq_padded = nn.utils.rnn.pad_sequence(seq_list, batch_first=True, padding_value=0)\n",
        "        seq_data[key] = seq_padded\n",
        "    # Record lengths\n",
        "    seq_lengths = [len(seq['timestamp']) for seq in sequences]\n",
        "\n",
        "    # Convert seq_lengths to tensor\n",
        "    seq_lengths = torch.tensor(seq_lengths, dtype=torch.long)\n",
        "\n",
        "    # Process target (exclude 'timestamp' and 'position' as they're not in target)\n",
        "    for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_target[key] = []\n",
        "        for target in targets:\n",
        "            if target[key] is not None:\n",
        "                batch_target[key].append(target[key])\n",
        "            else:\n",
        "                batch_target[key].append(-100 if key not in ['quantity', 'price'] else 0.0)\n",
        "\n",
        "        # Convert to tensor and create mask\n",
        "        if key in ['quantity', 'price']:\n",
        "            # For continuous features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != 0.0 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.float)\n",
        "        else:\n",
        "            # For categorical features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != -100 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.long)\n",
        "\n",
        "    return batch_data, batch_target, seq_data, seq_lengths\n",
        "\n",
        "# Training and Testing Loop\n",
        "def train_model(model_class, model_params, dataset_params, training_params):\n",
        "    # Create Dataset and DataLoader\n",
        "    dataset = MaskedOrderDataset(**dataset_params)\n",
        "    dataloader = DataLoader(dataset, batch_size=training_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    # Create model\n",
        "    model = model_class(**model_params).to(training_params['device'])\n",
        "    optimizer = optim.Adam(model.parameters(), lr=training_params['learning_rate'])\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(training_params['num_epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_data, batch_target, seq_data, seq_lengths in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move data to device\n",
        "            device = training_params.get('device', 'cpu')\n",
        "            batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
        "            batch_target = {k: v.to(device) for k, v in batch_target.items()}\n",
        "            seq_data = {k: v.to(device) for k, v in seq_data.items()}\n",
        "            seq_lengths = seq_lengths.to(device)\n",
        "\n",
        "            outputs = model(batch_data, seq_data, seq_lengths)\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            # Compute loss for each feature\n",
        "            for key in ['security_id', 'buy_sell', 'add_modify_delete', 'distance']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        loss_feature = criterion_ce(outputs[key], target)\n",
        "                        loss += loss_feature\n",
        "\n",
        "            for key in ['quantity', 'price']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        output = outputs[key].squeeze()\n",
        "                        loss_feature = criterion_l1(output[mask], target[mask])\n",
        "                        loss += loss_feature\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Beam Search Generation Function\n",
        "def generate_sequences(model, past_data, security_id, num_timesteps, beam_width, num_samples, device='cpu'):\n",
        "    \"\"\"\n",
        "    Generate sequences using beam search.\n",
        "\n",
        "    Args:\n",
        "        model: Trained model.\n",
        "        past_data: Dictionary containing past sequences.\n",
        "        security_id: The security ID to generate sequences for.\n",
        "        num_timesteps: Number of timesteps to generate.\n",
        "        beam_width: Beam width.\n",
        "        num_samples: Number of samples to generate.\n",
        "        device: Device to run the computations on.\n",
        "\n",
        "    Returns:\n",
        "        generated_sequences: A list of generated sequences.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Initialize the beam with the past_data\n",
        "        # Each beam entry is a tuple (sequence, cumulative_log_prob)\n",
        "        beam = [({'timestamp': past_data['timestamp'],\n",
        "                  'position': past_data['position'],\n",
        "                  'security_id': past_data['security_id'],\n",
        "                  'buy_sell': past_data['buy_sell'],\n",
        "                  'add_modify_delete': past_data['add_modify_delete'],\n",
        "                  'quantity': past_data['quantity'],\n",
        "                  'price': past_data['price'],\n",
        "                  'distance': past_data['distance']},\n",
        "                 0.0)]  # Start with log probability 0\n",
        "\n",
        "        for t in range(num_timesteps):\n",
        "            new_beam = []\n",
        "            for seq, cum_log_prob in beam:\n",
        "                # Prepare input data\n",
        "                # Use the last max_seq_len elements\n",
        "                seq_len = len(seq['timestamp'])\n",
        "                start_idx = max(0, seq_len - model.lstm_input_dim) if hasattr(model, 'lstm_input_dim') else 0\n",
        "                seq_data = {key: torch.tensor(seq[key][start_idx:]).unsqueeze(0).to(device) for key in seq}\n",
        "                seq_lengths = torch.tensor([seq_data['timestamp'].shape[1]]).to(device)\n",
        "\n",
        "                # Create a sample with masked features (except security_id and timestamp)\n",
        "                sample = {\n",
        "                    'timestamp': torch.tensor([seq['timestamp'][-1] + 1]).to(device),\n",
        "                    'position': torch.tensor([seq['position'][-1] + 1]).to(device),\n",
        "                    'security_id': torch.tensor([security_id]).to(device),\n",
        "                    'buy_sell': torch.tensor([model.buy_sell_mask if hasattr(model, 'buy_sell_mask') else 2]).to(device),\n",
        "                    'add_modify_delete': torch.tensor([model.add_modify_delete_mask if hasattr(model, 'add_modify_delete_mask') else 3]).to(device),\n",
        "                    'quantity': torch.tensor([0.0]).to(device),\n",
        "                    'price': torch.tensor([0.0]).to(device),\n",
        "                    'distance': torch.tensor([model.distance_mask if hasattr(model, 'distance_mask') else 10]).to(device)\n",
        "                }\n",
        "\n",
        "                # Predict missing features\n",
        "                outputs = model(sample, seq_data, seq_lengths)\n",
        "\n",
        "                # For each categorical feature, get top N predictions\n",
        "                candidates = []\n",
        "\n",
        "                # Adjust topk for buy_sell\n",
        "                if 'buy_sell' in outputs:\n",
        "                    buy_sell_probs = F.softmax(outputs['buy_sell'], dim=-1)\n",
        "                    num_buy_sell_classes = buy_sell_probs.size(-1)\n",
        "                    buy_sell_topk_k = min(beam_width, num_buy_sell_classes)\n",
        "                    buy_sell_topk = torch.topk(buy_sell_probs, buy_sell_topk_k)\n",
        "                else:\n",
        "                    buy_sell_topk_k = 1\n",
        "                    buy_sell_topk = None\n",
        "\n",
        "                # Adjust topk for add_modify_delete\n",
        "                if 'add_modify_delete' in outputs:\n",
        "                    add_modify_delete_probs = F.softmax(outputs['add_modify_delete'], dim=-1)\n",
        "                    num_amd_classes = add_modify_delete_probs.size(-1)\n",
        "                    amd_topk_k = min(beam_width, num_amd_classes)\n",
        "                    amd_topk = torch.topk(add_modify_delete_probs, amd_topk_k)\n",
        "                else:\n",
        "                    amd_topk_k = 1\n",
        "                    amd_topk = None\n",
        "\n",
        "                # Adjust topk for distance\n",
        "                if 'distance' in outputs:\n",
        "                    distance_probs = F.softmax(outputs['distance'], dim=-1)\n",
        "                    num_distance_classes = distance_probs.size(-1)\n",
        "                    distance_topk_k = min(beam_width, num_distance_classes)\n",
        "                    distance_topk = torch.topk(distance_probs, distance_topk_k)\n",
        "                else:\n",
        "                    distance_topk_k = 1\n",
        "                    distance_topk = None\n",
        "\n",
        "                # For continuous features, we can use the predicted value directly\n",
        "                quantity_pred = outputs['quantity'].item() if 'quantity' in outputs else 0.0\n",
        "                price_pred = outputs['price'].item() if 'price' in outputs else 0.0\n",
        "\n",
        "                # Generate combinations of top predictions\n",
        "                for i in range(buy_sell_topk_k):\n",
        "                    for j in range(amd_topk_k):\n",
        "                        for k in range(distance_topk_k):\n",
        "                            new_seq = {key: seq[key] + [sample[key].item()] for key in seq}\n",
        "                            if buy_sell_topk is not None:\n",
        "                                new_seq['buy_sell'][-1] = buy_sell_topk.indices[0][i].item()\n",
        "                            else:\n",
        "                                new_seq['buy_sell'][-1] = seq['buy_sell'][-1]  # Use previous value\n",
        "\n",
        "                            if amd_topk is not None:\n",
        "                                new_seq['add_modify_delete'][-1] = amd_topk.indices[0][j].item()\n",
        "                            else:\n",
        "                                new_seq['add_modify_delete'][-1] = seq['add_modify_delete'][-1]  # Use previous value\n",
        "\n",
        "                            if distance_topk is not None:\n",
        "                                new_seq['distance'][-1] = distance_topk.indices[0][k].item()\n",
        "                            else:\n",
        "                                new_seq['distance'][-1] = seq['distance'][-1]  # Use previous value\n",
        "\n",
        "                            new_seq['quantity'][-1] = quantity_pred\n",
        "                            new_seq['price'][-1] = price_pred\n",
        "\n",
        "                            # Compute new cumulative log probability\n",
        "                            log_prob = cum_log_prob\n",
        "                            if buy_sell_topk is not None:\n",
        "                                log_prob += torch.log(buy_sell_topk.values[0][i] + 1e-9).item()\n",
        "                            if amd_topk is not None:\n",
        "                                log_prob += torch.log(amd_topk.values[0][j] + 1e-9).item()\n",
        "                            if distance_topk is not None:\n",
        "                                log_prob += torch.log(distance_topk.values[0][k] + 1e-9).item()\n",
        "\n",
        "                            candidates.append((new_seq, log_prob))\n",
        "\n",
        "                # Keep top beam_width candidates\n",
        "                candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "                new_beam.extend(candidates[:beam_width])\n",
        "\n",
        "            # Keep top beam_width sequences\n",
        "            new_beam.sort(key=lambda x: x[1], reverse=True)\n",
        "            beam = new_beam[:beam_width]\n",
        "\n",
        "        # After generation, sample from the beam to get the required number of samples\n",
        "        generated_sequences = [seq for seq, _ in beam[:num_samples]]\n",
        "        return generated_sequences\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Training parameters\n",
        "    training_params = {\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 0.001,\n",
        "        'num_epochs': 5,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    }\n",
        "\n",
        "    # Dataset parameters\n",
        "    dataset_params = {\n",
        "        'num_samples': 5000,\n",
        "        'mask_prob': 0.15,\n",
        "        'max_seq_len': 50\n",
        "    }\n",
        "\n",
        "    # Model parameters for OrderModel\n",
        "    model_params = {\n",
        "        'N_sec_ids': 100,\n",
        "        'N_distance_bins': 10,\n",
        "        'embedding_dim': 32,\n",
        "        'hidden_dim': 64\n",
        "    }\n",
        "\n",
        "    # Train OrderModel\n",
        "    print(\"Training OrderModel...\")\n",
        "    model = train_model(OrderModel, model_params, dataset_params, training_params)\n",
        "\n",
        "    # Example of training another model, e.g., LSTMModel\n",
        "    '''\n",
        "    print(\"Training LSTMModel...\")\n",
        "    model_params_lstm = {\n",
        "        'input_size': 8,  # Number of features in seq_data\n",
        "        'hidden_size': 64,\n",
        "        'num_layers': 2,\n",
        "        'output_keys': ['security_id', 'buy_sell', 'add_modify_delete', 'distance', 'quantity', 'price']\n",
        "    }\n",
        "    model = train_model(LSTMModel, model_params_lstm, dataset_params, training_params)\n",
        "    '''\n",
        "\n",
        "    # Generate sequences using beam search\n",
        "    print(\"\\nGenerating sequences using beam search...\")\n",
        "    # Prepare past_data\n",
        "    past_data = {\n",
        "        'timestamp': [1000, 1001, 1002],\n",
        "        'position': [0, 1, 2],\n",
        "        'security_id': [5, 5, 5],\n",
        "        'buy_sell': [0, 1, 0],\n",
        "        'add_modify_delete': [0, 1, 2],\n",
        "        'quantity': [500.0, 600.0, 700.0],\n",
        "        'price': [50.0, 51.0, 52.0],\n",
        "        'distance': [3, 2, 1]\n",
        "    }\n",
        "\n",
        "    # Parameters for generation\n",
        "    security_id = 5\n",
        "    num_timesteps = 5\n",
        "    beam_width = 3\n",
        "    num_samples = 3\n",
        "\n",
        "    generated_sequences = generate_sequences(\n",
        "        model=model,\n",
        "        past_data=past_data,\n",
        "        security_id=security_id,\n",
        "        num_timesteps=num_timesteps,\n",
        "        beam_width=beam_width,\n",
        "        num_samples=num_samples,\n",
        "        device=training_params['device']\n",
        "    )\n",
        "\n",
        "    # Compute distribution of buys vs sells\n",
        "    total_buy = 0\n",
        "    total_sell = 0\n",
        "    total_actions = 0\n",
        "\n",
        "    for seq in generated_sequences:\n",
        "        buy_sell_seq = seq['buy_sell'][-num_timesteps:]  # Only consider generated timesteps\n",
        "        total_buy += buy_sell_seq.count(0)\n",
        "        total_sell += buy_sell_seq.count(1)\n",
        "        total_actions += len(buy_sell_seq)\n",
        "\n",
        "    buy_percentage = (total_buy / total_actions) * 100 if total_actions > 0 else 0\n",
        "    sell_percentage = (total_sell / total_actions) * 100 if total_actions > 0 else 0\n",
        "\n",
        "    print(f\"\\nGenerated {num_samples} sequences of {num_timesteps} timesteps each.\")\n",
        "    print(f\"Buy actions: {buy_percentage:.2f}%\")\n",
        "    print(f\"Sell actions: {sell_percentage:.2f}%\")"
      ],
      "metadata": {
        "id": "1MQcCvHeYySn",
        "outputId": "d50ae7ff-cba9-409d-b3f6-09d1418715d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training OrderModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-eb71e37320fd>:449: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 378.3656631761296\n",
            "Epoch 2, Loss: 338.79601671741267\n",
            "Epoch 3, Loss: 309.9995547738045\n"
          ]
        }
      ]
    }
  ]
}