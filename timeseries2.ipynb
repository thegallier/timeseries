{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeBflDRNCEQN+t2c2rFB/m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thegallier/timeseries/blob/main/timeseries2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the Dataset\n",
        "class MaskedOrderDataset(Dataset):\n",
        "    def __init__(self, num_samples, mask_prob=0.15, max_seq_len=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.N_sec_ids = 100  # Number of unique securities\n",
        "        self.N_distance_bins = 10  # Number of distance bins\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Generate synthetic data\n",
        "        self.timestamps = torch.randint(0, 1000, (num_samples,))\n",
        "        self.security_ids = torch.randint(0, self.N_sec_ids, (num_samples,))\n",
        "        self.buy_sell = torch.randint(0, 2, (num_samples,))  # 0: buy, 1: sell\n",
        "        self.add_modify_delete = torch.randint(0, 3, (num_samples,))  # 0: add, 1: modify, 2: delete\n",
        "        self.quantity = torch.randint(1, 1000, (num_samples,)).float()\n",
        "        self.price = torch.rand(num_samples) * 100  # Prices between 0 and 100\n",
        "        self.distance = torch.randint(0, self.N_distance_bins, (num_samples,))\n",
        "\n",
        "        # Sort the data by timestamps (ascending)\n",
        "        sorted_indices = torch.argsort(self.timestamps)\n",
        "        self.timestamps = self.timestamps[sorted_indices]\n",
        "        self.security_ids = self.security_ids[sorted_indices]\n",
        "        self.buy_sell = self.buy_sell[sorted_indices]\n",
        "        self.add_modify_delete = self.add_modify_delete[sorted_indices]\n",
        "        self.quantity = self.quantity[sorted_indices]\n",
        "        self.price = self.price[sorted_indices]\n",
        "        self.distance = self.distance[sorted_indices]\n",
        "\n",
        "        # Define mask indices\n",
        "        self.security_id_mask = self.N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = self.N_distance_bins\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence from idx to end, up to max_seq_len\n",
        "        end_idx = min(idx + self.max_seq_len, self.num_samples)\n",
        "        seq_len = end_idx - idx\n",
        "        sequence = {\n",
        "            'timestamp': self.timestamps[idx:end_idx],\n",
        "            'security_id': self.security_ids[idx:end_idx],\n",
        "            'buy_sell': self.buy_sell[idx:end_idx],\n",
        "            'add_modify_delete': self.add_modify_delete[idx:end_idx],\n",
        "            'quantity': self.quantity[idx:end_idx],\n",
        "            'price': self.price[idx:end_idx],\n",
        "            'distance': self.distance[idx:end_idx],\n",
        "        }\n",
        "\n",
        "        # Apply masking logic to the first element (idx)\n",
        "        sample = {key: sequence[key][0] for key in sequence}\n",
        "        masked_sample = sample.copy()\n",
        "        target = {}\n",
        "\n",
        "        for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "            if torch.rand(1).item() < self.mask_prob:\n",
        "                # Mask the feature\n",
        "                target[key] = sample[key]\n",
        "                if key == 'security_id':\n",
        "                    masked_sample[key] = self.security_id_mask\n",
        "                elif key == 'buy_sell':\n",
        "                    masked_sample[key] = self.buy_sell_mask\n",
        "                elif key == 'add_modify_delete':\n",
        "                    masked_sample[key] = self.add_modify_delete_mask\n",
        "                elif key == 'distance':\n",
        "                    masked_sample[key] = self.distance_mask\n",
        "                elif key in ['quantity', 'price']:\n",
        "                    masked_sample[key] = 0.0  # For continuous features, use 0.0 as masked value\n",
        "            else:\n",
        "                target[key] = None  # Not masked\n",
        "\n",
        "        # Return masked_sample, target, and the sequence starting from idx\n",
        "        return masked_sample, target, sequence\n",
        "\n",
        "# Define the Model\n",
        "class OrderModel(nn.Module):\n",
        "    def __init__(self, N_sec_ids, N_distance_bins, embedding_dim=32, hidden_dim=64):\n",
        "        super(OrderModel, self).__init__()\n",
        "\n",
        "        # Mask indices\n",
        "        self.security_id_mask = N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = N_distance_bins\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.security_id_embedding = nn.Embedding(N_sec_ids + 1, embedding_dim, padding_idx=self.security_id_mask)\n",
        "        self.buy_sell_embedding = nn.Embedding(3, embedding_dim, padding_idx=self.buy_sell_mask)  # 0,1,2(mask)\n",
        "        self.add_modify_delete_embedding = nn.Embedding(4, embedding_dim, padding_idx=self.add_modify_delete_mask)  # 0,1,2,3(mask)\n",
        "        self.distance_embedding = nn.Embedding(N_distance_bins + 1, embedding_dim, padding_idx=self.distance_mask)\n",
        "\n",
        "        # Linear layers for continuous features\n",
        "        self.quantity_linear = nn.Linear(1, embedding_dim)\n",
        "        self.price_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # For timestamp (we don't mask timestamp)\n",
        "        self.timestamp_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # LSTM for sequences\n",
        "        self.lstm_input_dim = embedding_dim * 7  # Number of features\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Final fully connected layers\n",
        "        self.fc1 = nn.Linear(embedding_dim * 7 + hidden_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output heads\n",
        "        self.security_id_head = nn.Linear(128, N_sec_ids)\n",
        "        self.buy_sell_head = nn.Linear(128, 2)\n",
        "        self.add_modify_delete_head = nn.Linear(128, 3)\n",
        "        self.distance_head = nn.Linear(128, N_distance_bins)\n",
        "        self.quantity_head = nn.Linear(128, 1)\n",
        "        self.price_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x is a dictionary of features for the masked sample\n",
        "        # seq_data is a dictionary of sequences\n",
        "        # seq_lengths is a list of sequence lengths\n",
        "\n",
        "        # Process the masked sample\n",
        "        timestamp = x['timestamp'].unsqueeze(1).float()\n",
        "        security_id = x['security_id']\n",
        "        buy_sell = x['buy_sell']\n",
        "        add_modify_delete = x['add_modify_delete']\n",
        "        quantity = x['quantity'].unsqueeze(1)\n",
        "        price = x['price'].unsqueeze(1)\n",
        "        distance = x['distance']\n",
        "\n",
        "        # Embeddings\n",
        "        timestamp_emb = self.timestamp_linear(timestamp)\n",
        "        security_id_emb = self.security_id_embedding(security_id)\n",
        "        buy_sell_emb = self.buy_sell_embedding(buy_sell)\n",
        "        add_modify_delete_emb = self.add_modify_delete_embedding(add_modify_delete)\n",
        "        quantity_emb = self.quantity_linear(quantity)\n",
        "        price_emb = self.price_linear(price)\n",
        "        distance_emb = self.distance_embedding(distance)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        sample_emb = torch.cat([timestamp_emb,\n",
        "                                security_id_emb,\n",
        "                                buy_sell_emb,\n",
        "                                add_modify_delete_emb,\n",
        "                                quantity_emb,\n",
        "                                price_emb,\n",
        "                                distance_emb], dim=1)  # Shape: (batch_size, embedding_dim * 7)\n",
        "\n",
        "        # Process the sequence data\n",
        "        # For each feature in seq_data, get embeddings\n",
        "        batch_size = timestamp.shape[0]\n",
        "\n",
        "        seq_timestamp = seq_data['timestamp'].float()\n",
        "        seq_security_id = seq_data['security_id']\n",
        "        seq_buy_sell = seq_data['buy_sell']\n",
        "        seq_add_modify_delete = seq_data['add_modify_delete']\n",
        "        seq_quantity = seq_data['quantity']\n",
        "        seq_price = seq_data['price']\n",
        "        seq_distance = seq_data['distance']\n",
        "\n",
        "        # Embeddings for sequence data\n",
        "        seq_timestamp_emb = self.timestamp_linear(seq_timestamp.unsqueeze(-1))  # (batch_size, seq_len, embedding_dim)\n",
        "        seq_security_id_emb = self.security_id_embedding(seq_security_id)\n",
        "        seq_buy_sell_emb = self.buy_sell_embedding(seq_buy_sell)\n",
        "        seq_add_modify_delete_emb = self.add_modify_delete_embedding(seq_add_modify_delete)\n",
        "        seq_quantity_emb = self.quantity_linear(seq_quantity.unsqueeze(-1))\n",
        "        seq_price_emb = self.price_linear(seq_price.unsqueeze(-1))\n",
        "        seq_distance_emb = self.distance_embedding(seq_distance)\n",
        "\n",
        "        # Concatenate sequence embeddings\n",
        "        seq_emb = torch.cat([seq_timestamp_emb,\n",
        "                             seq_security_id_emb,\n",
        "                             seq_buy_sell_emb,\n",
        "                             seq_add_modify_delete_emb,\n",
        "                             seq_quantity_emb,\n",
        "                             seq_price_emb,\n",
        "                             seq_distance_emb], dim=2)  # Shape: (batch_size, seq_len, embedding_dim * 7)\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = nn.utils.rnn.pack_padded_sequence(seq_emb, seq_lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb)\n",
        "\n",
        "        # Get the last hidden state for each sequence\n",
        "        seq_context = h_n.squeeze(0)  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Combine the sample embedding with the sequence context\n",
        "        combined = torch.cat([sample_emb, seq_context], dim=1)  # Shape: (batch_size, embedding_dim * 7 + hidden_dim)\n",
        "\n",
        "        # Forward pass\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Outputs\n",
        "        outputs = {\n",
        "            'security_id': self.security_id_head(x),\n",
        "            'buy_sell': self.buy_sell_head(x),\n",
        "            'add_modify_delete': self.add_modify_delete_head(x),\n",
        "            'distance': self.distance_head(x),\n",
        "            'quantity': self.quantity_head(x),\n",
        "            'price': self.price_head(x)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Collate function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    # batch is a list of (masked_sample, target, sequence)\n",
        "    batch_size = len(batch)\n",
        "    masked_samples = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    sequences = [item[2] for item in batch]\n",
        "\n",
        "    # Convert masked_samples to tensors\n",
        "    batch_data = {}\n",
        "    batch_target = {}\n",
        "    seq_data = {}\n",
        "    seq_lengths = []\n",
        "\n",
        "    # Process data\n",
        "    for key in ['timestamp', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_data[key] = torch.tensor([sample[key] for sample in masked_samples])\n",
        "\n",
        "    # Process sequences\n",
        "    # Sequences are variable-length\n",
        "    # For each key, we have a list of sequences\n",
        "    for key in ['timestamp', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        seq_list = [torch.tensor(seq[key]) for seq in sequences]\n",
        "        seq_padded = nn.utils.rnn.pad_sequence(seq_list, batch_first=True, padding_value=0)\n",
        "        seq_data[key] = seq_padded\n",
        "    # Record lengths\n",
        "    seq_lengths = [len(seq['timestamp']) for seq in sequences]\n",
        "\n",
        "    # Convert seq_lengths to tensor\n",
        "    seq_lengths = torch.tensor(seq_lengths, dtype=torch.long)\n",
        "\n",
        "    # Process target (exclude 'timestamp' as it's not in target)\n",
        "    for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_target[key] = []\n",
        "        for target in targets:\n",
        "            if target[key] is not None:\n",
        "                batch_target[key].append(target[key])\n",
        "            else:\n",
        "                batch_target[key].append(-100 if key not in ['quantity', 'price'] else 0.0)\n",
        "\n",
        "        # Convert to tensor and create mask\n",
        "        if key in ['quantity', 'price']:\n",
        "            # For continuous features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != 0.0 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.float)\n",
        "        else:\n",
        "            # For categorical features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != -100 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.long)\n",
        "\n",
        "    return batch_data, batch_target, seq_data, seq_lengths\n",
        "\n",
        "# Training and Testing Loop\n",
        "def train_model():\n",
        "    # Create Dataset and DataLoader\n",
        "    dataset = MaskedOrderDataset(num_samples=10000)\n",
        "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    # Create model\n",
        "    model = OrderModel(N_sec_ids=dataset.N_sec_ids, N_distance_bins=dataset.N_distance_bins)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_data, batch_target, seq_data, seq_lengths in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(batch_data, seq_data, seq_lengths)\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            # Compute loss for security_id\n",
        "            target = batch_target['security_id']\n",
        "            mask = batch_target['security_id_mask']\n",
        "            if mask.any():\n",
        "                loss_sec_id = criterion_ce(outputs['security_id'], target)\n",
        "                loss += loss_sec_id\n",
        "\n",
        "            # Compute loss for buy_sell\n",
        "            target = batch_target['buy_sell']\n",
        "            mask = batch_target['buy_sell_mask']\n",
        "            if mask.any():\n",
        "                loss_buy_sell = criterion_ce(outputs['buy_sell'], target)\n",
        "                loss += loss_buy_sell\n",
        "\n",
        "            # Compute loss for add_modify_delete\n",
        "            target = batch_target['add_modify_delete']\n",
        "            mask = batch_target['add_modify_delete_mask']\n",
        "            if mask.any():\n",
        "                loss_amd = criterion_ce(outputs['add_modify_delete'], target)\n",
        "                loss += loss_amd\n",
        "\n",
        "            # Compute loss for distance\n",
        "            target = batch_target['distance']\n",
        "            mask = batch_target['distance_mask']\n",
        "            if mask.any():\n",
        "                loss_distance = criterion_ce(outputs['distance'], target)\n",
        "                loss += loss_distance\n",
        "\n",
        "            # Compute loss for quantity\n",
        "            target = batch_target['quantity']\n",
        "            mask = batch_target['quantity_mask']\n",
        "            if mask.any():\n",
        "                output = outputs['quantity'].squeeze()\n",
        "                loss_quantity = criterion_l1(output[mask], target[mask])\n",
        "                loss += loss_quantity\n",
        "\n",
        "            # Compute loss for price\n",
        "            target = batch_target['price']\n",
        "            mask = batch_target['price_mask']\n",
        "            if mask.any():\n",
        "                output = outputs['price'].squeeze()\n",
        "                loss_price = criterion_l1(output[mask], target[mask])\n",
        "                loss += loss_price\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmEZwyPGCTJh",
        "outputId": "cd18dad6-1b2a-4178-d8c1-7e0410bc5d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-d57e3d80251b>:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 365.27560881596463\n",
            "Epoch 2, Loss: 327.6048114557934\n",
            "Epoch 3, Loss: 325.116089061567\n",
            "Epoch 4, Loss: 312.7274585893959\n",
            "Epoch 5, Loss: 312.8242979596375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# Define the Dataset\n",
        "class MaskedOrderDataset(Dataset):\n",
        "    def __init__(self, num_samples, mask_prob=0.15, max_seq_len=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.N_sec_ids = 100  # Number of unique securities\n",
        "        self.N_distance_bins = 10  # Number of distance bins\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Generate synthetic data\n",
        "        self.timestamps = torch.randint(0, 1000, (num_samples,))\n",
        "        self.security_ids = torch.randint(0, self.N_sec_ids, (num_samples,))\n",
        "        self.buy_sell = torch.randint(0, 2, (num_samples,))  # 0: buy, 1: sell\n",
        "        self.add_modify_delete = torch.randint(0, 3, (num_samples,))  # 0: add, 1: modify, 2: delete\n",
        "        self.quantity = torch.randint(1, 1000, (num_samples,)).float()\n",
        "        self.price = torch.rand(num_samples) * 100  # Prices between 0 and 100\n",
        "        self.distance = torch.randint(0, self.N_distance_bins, (num_samples,))\n",
        "\n",
        "        # Sort the data by timestamps (ascending)\n",
        "        sorted_indices = torch.argsort(self.timestamps)\n",
        "        self.timestamps = self.timestamps[sorted_indices]\n",
        "        self.security_ids = self.security_ids[sorted_indices]\n",
        "        self.buy_sell = self.buy_sell[sorted_indices]\n",
        "        self.add_modify_delete = self.add_modify_delete[sorted_indices]\n",
        "        self.quantity = self.quantity[sorted_indices]\n",
        "        self.price = self.price[sorted_indices]\n",
        "        self.distance = self.distance[sorted_indices]\n",
        "\n",
        "        # Define mask indices\n",
        "        self.security_id_mask = self.N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = self.N_distance_bins\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence from idx to end, up to max_seq_len\n",
        "        end_idx = min(idx + self.max_seq_len, self.num_samples)\n",
        "        seq_len = end_idx - idx\n",
        "        sequence = {\n",
        "            'timestamp': self.timestamps[idx:end_idx],\n",
        "            'security_id': self.security_ids[idx:end_idx],\n",
        "            'buy_sell': self.buy_sell[idx:end_idx],\n",
        "            'add_modify_delete': self.add_modify_delete[idx:end_idx],\n",
        "            'quantity': self.quantity[idx:end_idx],\n",
        "            'price': self.price[idx:end_idx],\n",
        "            'distance': self.distance[idx:end_idx],\n",
        "            'position': torch.arange(seq_len)  # Row number\n",
        "        }\n",
        "\n",
        "        # Apply masking logic to the first element (idx)\n",
        "        sample = {key: sequence[key][0] for key in sequence}\n",
        "        masked_sample = sample.copy()\n",
        "        target = {}\n",
        "\n",
        "        for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "            if torch.rand(1).item() < self.mask_prob:\n",
        "                # Mask the feature\n",
        "                target[key] = sample[key]\n",
        "                if key == 'security_id':\n",
        "                    masked_sample[key] = self.security_id_mask\n",
        "                elif key == 'buy_sell':\n",
        "                    masked_sample[key] = self.buy_sell_mask\n",
        "                elif key == 'add_modify_delete':\n",
        "                    masked_sample[key] = self.add_modify_delete_mask\n",
        "                elif key == 'distance':\n",
        "                    masked_sample[key] = self.distance_mask\n",
        "                elif key in ['quantity', 'price']:\n",
        "                    masked_sample[key] = 0.0  # For continuous features, use 0.0 as masked value\n",
        "            else:\n",
        "                target[key] = None  # Not masked\n",
        "\n",
        "        # Return masked_sample, target, and the sequence starting from idx\n",
        "        return masked_sample, target, sequence\n",
        "\n",
        "# Learnable Positional Encoder\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(PositionalEncoder, self).__init__()\n",
        "        self.timestamp_encoder = nn.Linear(1, embedding_dim)\n",
        "        self.position_encoder = nn.Embedding(1000, embedding_dim)  # Assume max 1000 positions\n",
        "\n",
        "    def forward(self, timestamps, positions):\n",
        "        timestamp_emb = self.timestamp_encoder(timestamps.unsqueeze(-1).float())\n",
        "        position_emb = self.position_encoder(positions)\n",
        "        return timestamp_emb + position_emb\n",
        "\n",
        "# Base Model Class\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Order Model with Positional Encoder\n",
        "class OrderModel(BaseModel):\n",
        "    def __init__(self, N_sec_ids, N_distance_bins, embedding_dim=32, hidden_dim=64):\n",
        "        super(OrderModel, self).__init__()\n",
        "\n",
        "        # Mask indices\n",
        "        self.security_id_mask = N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = N_distance_bins\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.security_id_embedding = nn.Embedding(N_sec_ids + 1, embedding_dim, padding_idx=self.security_id_mask)\n",
        "        self.buy_sell_embedding = nn.Embedding(3, embedding_dim, padding_idx=self.buy_sell_mask)  # 0,1,2(mask)\n",
        "        self.add_modify_delete_embedding = nn.Embedding(4, embedding_dim, padding_idx=self.add_modify_delete_mask)  # 0,1,2,3(mask)\n",
        "        self.distance_embedding = nn.Embedding(N_distance_bins + 1, embedding_dim, padding_idx=self.distance_mask)\n",
        "\n",
        "        # Linear layers for continuous features\n",
        "        self.quantity_linear = nn.Linear(1, embedding_dim)\n",
        "        self.price_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # Positional Encoder\n",
        "        self.positional_encoder = PositionalEncoder(embedding_dim)\n",
        "\n",
        "        # LSTM for sequences\n",
        "        self.lstm_input_dim = embedding_dim * 7  # Number of features\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Final fully connected layers\n",
        "        self.fc1 = nn.Linear(embedding_dim * 7 + hidden_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output heads\n",
        "        self.security_id_head = nn.Linear(128, N_sec_ids)\n",
        "        self.buy_sell_head = nn.Linear(128, 2)\n",
        "        self.add_modify_delete_head = nn.Linear(128, 3)\n",
        "        self.distance_head = nn.Linear(128, N_distance_bins)\n",
        "        self.quantity_head = nn.Linear(128, 1)\n",
        "        self.price_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x is a dictionary of features for the masked sample\n",
        "        # seq_data is a dictionary of sequences\n",
        "        # seq_lengths is a list of sequence lengths\n",
        "\n",
        "        batch_size = x['timestamp'].shape[0]\n",
        "\n",
        "        # Process the masked sample\n",
        "        timestamp = x['timestamp']\n",
        "        position = x['position']\n",
        "        security_id = x['security_id']\n",
        "        buy_sell = x['buy_sell']\n",
        "        add_modify_delete = x['add_modify_delete']\n",
        "        quantity = x['quantity'].unsqueeze(1)\n",
        "        price = x['price'].unsqueeze(1)\n",
        "        distance = x['distance']\n",
        "\n",
        "        # Embeddings\n",
        "        positional_emb = self.positional_encoder(timestamp, position)\n",
        "        security_id_emb = self.security_id_embedding(security_id)\n",
        "        buy_sell_emb = self.buy_sell_embedding(buy_sell)\n",
        "        add_modify_delete_emb = self.add_modify_delete_embedding(add_modify_delete)\n",
        "        quantity_emb = self.quantity_linear(quantity)\n",
        "        price_emb = self.price_linear(price)\n",
        "        distance_emb = self.distance_embedding(distance)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        sample_emb = torch.cat([positional_emb,\n",
        "                                security_id_emb,\n",
        "                                buy_sell_emb,\n",
        "                                add_modify_delete_emb,\n",
        "                                quantity_emb,\n",
        "                                price_emb,\n",
        "                                distance_emb], dim=1)  # Shape: (batch_size, embedding_dim * 7)\n",
        "\n",
        "        # Process the sequence data\n",
        "        # For each feature in seq_data, get embeddings\n",
        "\n",
        "        seq_timestamp = seq_data['timestamp']\n",
        "        seq_position = seq_data['position']\n",
        "        seq_security_id = seq_data['security_id']\n",
        "        seq_buy_sell = seq_data['buy_sell']\n",
        "        seq_add_modify_delete = seq_data['add_modify_delete']\n",
        "        seq_quantity = seq_data['quantity']\n",
        "        seq_price = seq_data['price']\n",
        "        seq_distance = seq_data['distance']\n",
        "\n",
        "        # Embeddings for sequence data\n",
        "        seq_positional_emb = self.positional_encoder(seq_timestamp, seq_position)\n",
        "        seq_security_id_emb = self.security_id_embedding(seq_security_id)\n",
        "        seq_buy_sell_emb = self.buy_sell_embedding(seq_buy_sell)\n",
        "        seq_add_modify_delete_emb = self.add_modify_delete_embedding(seq_add_modify_delete)\n",
        "        seq_quantity_emb = self.quantity_linear(seq_quantity.unsqueeze(-1))\n",
        "        seq_price_emb = self.price_linear(seq_price.unsqueeze(-1))\n",
        "        seq_distance_emb = self.distance_embedding(seq_distance)\n",
        "\n",
        "        # Concatenate sequence embeddings\n",
        "        seq_emb = torch.cat([seq_positional_emb,\n",
        "                             seq_security_id_emb,\n",
        "                             seq_buy_sell_emb,\n",
        "                             seq_add_modify_delete_emb,\n",
        "                             seq_quantity_emb,\n",
        "                             seq_price_emb,\n",
        "                             seq_distance_emb], dim=2)  # Shape: (batch_size, seq_len, embedding_dim * 7)\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = pack_padded_sequence(seq_emb, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb)\n",
        "\n",
        "        # Get the last hidden state for each sequence\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Combine the sample embedding with the sequence context\n",
        "        combined = torch.cat([sample_emb, seq_context], dim=1)  # Shape: (batch_size, embedding_dim * 7 + hidden_dim)\n",
        "\n",
        "        # Forward pass\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Outputs\n",
        "        outputs = {\n",
        "            'security_id': self.security_id_head(x),\n",
        "            'buy_sell': self.buy_sell_head(x),\n",
        "            'add_modify_delete': self.add_modify_delete_head(x),\n",
        "            'distance': self.distance_head(x),\n",
        "            'quantity': self.quantity_head(x),\n",
        "            'price': self.price_head(x)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Additional Models\n",
        "\n",
        "class MatrixRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_securities, input_size, num_classes=1):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(1, num_securities))\n",
        "        self.B = nn.Parameter(torch.randn(input_size, num_classes))\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        # x: (batch_size, input_size)\n",
        "        x = x.view(x.size(0), -1)  # Flatten over time\n",
        "        out = self.A @ x @ self.B  # Shape: (batch_size, num_classes)\n",
        "        return {'price': out.squeeze(-1)}  # Adjust as needed\n",
        "\n",
        "class LogisticRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_classes=1):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.linear(x)\n",
        "        return {'price': out.squeeze(-1)}  # Adjust as needed\n",
        "\n",
        "class CNNModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, num_classes=1):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, num_features, seq_len)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "        return {'price': x.squeeze(-1)}  # Adjust as needed\n",
        "\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes=1):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: Not used in this model\n",
        "        # seq_data: input sequences\n",
        "        # seq_lengths: lengths of sequences\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = pack_padded_sequence(seq_data, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        h0 = torch.zeros(self.lstm.num_layers, seq_data.size(0), self.lstm.hidden_size).to(seq_data.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, seq_data.size(0), self.lstm.hidden_size).to(seq_data.device)\n",
        "\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb, (h0, c0))\n",
        "\n",
        "        # Get the last hidden state\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        out = self.fc(seq_context)\n",
        "        return {'price': out.squeeze(-1)}  # Adjust as needed\n",
        "\n",
        "# Collate function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    # batch is a list of (masked_sample, target, sequence)\n",
        "    batch_size = len(batch)\n",
        "    masked_samples = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    sequences = [item[2] for item in batch]\n",
        "\n",
        "    # Convert masked_samples to tensors\n",
        "    batch_data = {}\n",
        "    batch_target = {}\n",
        "    seq_data = {}\n",
        "    seq_lengths = []\n",
        "\n",
        "    # Process data\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_data[key] = torch.tensor([sample[key] for sample in masked_samples])\n",
        "\n",
        "    # Process sequences\n",
        "    # Sequences are variable-length\n",
        "    # For each key, we have a list of sequences\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        seq_list = [torch.tensor(seq[key]) for seq in sequences]\n",
        "        seq_padded = nn.utils.rnn.pad_sequence(seq_list, batch_first=True, padding_value=0)\n",
        "        seq_data[key] = seq_padded\n",
        "    # Record lengths\n",
        "    seq_lengths = [len(seq['timestamp']) for seq in sequences]\n",
        "\n",
        "    # Convert seq_lengths to tensor\n",
        "    seq_lengths = torch.tensor(seq_lengths, dtype=torch.long)\n",
        "\n",
        "    # Process target (exclude 'timestamp' and 'position' as they're not in target)\n",
        "    for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_target[key] = []\n",
        "        for target in targets:\n",
        "            if target[key] is not None:\n",
        "                batch_target[key].append(target[key])\n",
        "            else:\n",
        "                batch_target[key].append(-100 if key not in ['quantity', 'price'] else 0.0)\n",
        "\n",
        "        # Convert to tensor and create mask\n",
        "        if key in ['quantity', 'price']:\n",
        "            # For continuous features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != 0.0 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.float)\n",
        "        else:\n",
        "            # For categorical features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != -100 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.long)\n",
        "\n",
        "    return batch_data, batch_target, seq_data, seq_lengths\n",
        "\n",
        "# Training and Testing Loop\n",
        "def train_model(model_class, model_params, dataset_params, training_params):\n",
        "    # Create Dataset and DataLoader\n",
        "    dataset = MaskedOrderDataset(**dataset_params)\n",
        "    dataloader = DataLoader(dataset, batch_size=training_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    # Create model\n",
        "    model = model_class(**model_params)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=training_params['learning_rate'])\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(training_params['num_epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_data, batch_target, seq_data, seq_lengths in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move data to device\n",
        "            device = training_params.get('device', 'cpu')\n",
        "            batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
        "            batch_target = {k: v.to(device) for k, v in batch_target.items()}\n",
        "            seq_data = {k: v.to(device) for k, v in seq_data.items()}\n",
        "            seq_lengths = seq_lengths.to(device)\n",
        "\n",
        "            outputs = model(batch_data, seq_data, seq_lengths)\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            # Compute loss for security_id\n",
        "            if 'security_id' in outputs:\n",
        "                target = batch_target['security_id']\n",
        "                mask = batch_target['security_id_mask']\n",
        "                if mask.any():\n",
        "                    loss_sec_id = criterion_ce(outputs['security_id'], target)\n",
        "                    loss += loss_sec_id\n",
        "\n",
        "            # Compute loss for buy_sell\n",
        "            if 'buy_sell' in outputs:\n",
        "                target = batch_target['buy_sell']\n",
        "                mask = batch_target['buy_sell_mask']\n",
        "                if mask.any():\n",
        "                    loss_buy_sell = criterion_ce(outputs['buy_sell'], target)\n",
        "                    loss += loss_buy_sell\n",
        "\n",
        "            # Compute loss for add_modify_delete\n",
        "            if 'add_modify_delete' in outputs:\n",
        "                target = batch_target['add_modify_delete']\n",
        "                mask = batch_target['add_modify_delete_mask']\n",
        "                if mask.any():\n",
        "                    loss_amd = criterion_ce(outputs['add_modify_delete'], target)\n",
        "                    loss += loss_amd\n",
        "\n",
        "            # Compute loss for distance\n",
        "            if 'distance' in outputs:\n",
        "                target = batch_target['distance']\n",
        "                mask = batch_target['distance_mask']\n",
        "                if mask.any():\n",
        "                    loss_distance = criterion_ce(outputs['distance'], target)\n",
        "                    loss += loss_distance\n",
        "\n",
        "            # Compute loss for quantity\n",
        "            if 'quantity' in outputs:\n",
        "                target = batch_target['quantity']\n",
        "                mask = batch_target['quantity_mask']\n",
        "                if mask.any():\n",
        "                    output = outputs['quantity'].squeeze()\n",
        "                    loss_quantity = criterion_l1(output[mask], target[mask])\n",
        "                    loss += loss_quantity\n",
        "\n",
        "            # Compute loss for price\n",
        "            if 'price' in outputs:\n",
        "                target = batch_target['price']\n",
        "                mask = batch_target['price_mask']\n",
        "                if mask.any():\n",
        "                    output = outputs['price'].squeeze()\n",
        "                    loss_price = criterion_l1(output[mask], target[mask])\n",
        "                    loss += loss_price\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Hyperparameter Optimization\n",
        "def hyperparameter_optimization():\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from skorch import NeuralNetRegressor, NeuralNetClassifier\n",
        "    import numpy as np\n",
        "\n",
        "    # Define parameter grid\n",
        "    param_grid = {\n",
        "        'module__embedding_dim': [16, 32],\n",
        "        'module__hidden_dim': [32, 64],\n",
        "        'optimizer__lr': [0.001, 0.0001],\n",
        "    }\n",
        "\n",
        "    # Wrap the model using skorch\n",
        "    net = NeuralNetRegressor(\n",
        "        OrderModel,\n",
        "        module__N_sec_ids=100,\n",
        "        module__N_distance_bins=10,\n",
        "        max_epochs=5,\n",
        "        lr=0.001,\n",
        "        iterator_train__collate_fn=collate_fn,\n",
        "        iterator_valid__collate_fn=collate_fn,\n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    )\n",
        "\n",
        "    # Create Dataset\n",
        "    dataset = MaskedOrderDataset(num_samples=1000)\n",
        "\n",
        "    # Prepare data for GridSearchCV (this is a simplified example)\n",
        "    X = [dataset[i][0] for i in range(len(dataset))]\n",
        "    y = [dataset[i][1]['price'] if dataset[i][1]['price'] is not None else 0.0 for i in range(len(dataset))]\n",
        "\n",
        "    # Convert X and y to numpy arrays (skorch expects numpy arrays)\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Perform Grid Search\n",
        "    gs = GridSearchCV(net, param_grid, refit=False, cv=3, scoring='neg_mean_absolute_error', verbose=2)\n",
        "    gs.fit(X, y)\n",
        "\n",
        "    print(\"Best parameters found:\")\n",
        "    print(gs.best_params_)\n",
        "\n",
        "    print(\"Best score:\")\n",
        "    print(gs.best_score_)\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Training parameters\n",
        "    training_params = {\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 0.001,\n",
        "        'num_epochs': 5,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    }\n",
        "\n",
        "    # Dataset parameters\n",
        "    dataset_params = {\n",
        "        'num_samples': 5000,\n",
        "        'mask_prob': 0.15,\n",
        "        'max_seq_len': 50\n",
        "    }\n",
        "\n",
        "    # Model parameters for OrderModel\n",
        "    model_params = {\n",
        "        'N_sec_ids': 100,\n",
        "        'N_distance_bins': 10,\n",
        "        'embedding_dim': 32,\n",
        "        'hidden_dim': 64\n",
        "    }\n",
        "\n",
        "    # Train OrderModel\n",
        "    print(\"Training OrderModel...\")\n",
        "    model = train_model(OrderModel, model_params, dataset_params, training_params)\n",
        "\n",
        "    # You can substitute different models by changing model_class and model_params\n",
        "    # For example, training LSTMModel\n",
        "    '''\n",
        "    print(\"Training LSTMModel...\")\n",
        "    model_params_lstm = {\n",
        "        'input_size': 7,  # Number of features in sequence data\n",
        "        'hidden_size': 64,\n",
        "        'num_layers': 2,\n",
        "        'num_classes': 1\n",
        "    }\n",
        "    model = train_model(LSTMModel, model_params_lstm, dataset_params, training_params)\n",
        "    '''\n",
        "\n",
        "    # Hyperparameter Optimization\n",
        "    '''\n",
        "    print(\"Starting Hyperparameter Optimization...\")\n",
        "    hyperparameter_optimization()\n",
        "    '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf6NO-ftGD1Y",
        "outputId": "3c6fab5d-5d31-4e27-ae98-62e9240f6244"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training OrderModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-15b0f17eec53>:371: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 381.8814974256382\n",
            "Epoch 2, Loss: 349.19875107297474\n",
            "Epoch 3, Loss: 338.50678306628186\n",
            "Epoch 4, Loss: 321.11537005187597\n",
            "Epoch 5, Loss: 339.4471651308096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Define the Dataset\n",
        "class MaskedOrderDataset(Dataset):\n",
        "    def __init__(self, num_samples, mask_prob=0.15, max_seq_len=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.N_sec_ids = 100  # Number of unique securities\n",
        "        self.N_distance_bins = 10  # Number of distance bins\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Generate synthetic data\n",
        "        self.timestamps = torch.randint(0, 1000, (num_samples,))\n",
        "        self.security_ids = torch.randint(0, self.N_sec_ids, (num_samples,))\n",
        "        self.buy_sell = torch.randint(0, 2, (num_samples,))  # 0: buy, 1: sell\n",
        "        self.add_modify_delete = torch.randint(0, 3, (num_samples,))  # 0: add, 1: modify, 2: delete\n",
        "        self.quantity = torch.randint(1, 1000, (num_samples,)).float()\n",
        "        self.price = torch.rand(num_samples) * 100  # Prices between 0 and 100\n",
        "        self.distance = torch.randint(0, self.N_distance_bins, (num_samples,))\n",
        "\n",
        "        # Sort the data by timestamps (ascending)\n",
        "        sorted_indices = torch.argsort(self.timestamps)\n",
        "        self.timestamps = self.timestamps[sorted_indices]\n",
        "        self.security_ids = self.security_ids[sorted_indices]\n",
        "        self.buy_sell = self.buy_sell[sorted_indices]\n",
        "        self.add_modify_delete = self.add_modify_delete[sorted_indices]\n",
        "        self.quantity = self.quantity[sorted_indices]\n",
        "        self.price = self.price[sorted_indices]\n",
        "        self.distance = self.distance[sorted_indices]\n",
        "\n",
        "        # Define mask indices\n",
        "        self.security_id_mask = self.N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = self.N_distance_bins\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence from idx to end, up to max_seq_len\n",
        "        end_idx = min(idx + self.max_seq_len, self.num_samples)\n",
        "        seq_len = end_idx - idx\n",
        "        sequence = {\n",
        "            'timestamp': self.timestamps[idx:end_idx],\n",
        "            'security_id': self.security_ids[idx:end_idx],\n",
        "            'buy_sell': self.buy_sell[idx:end_idx],\n",
        "            'add_modify_delete': self.add_modify_delete[idx:end_idx],\n",
        "            'quantity': self.quantity[idx:end_idx],\n",
        "            'price': self.price[idx:end_idx],\n",
        "            'distance': self.distance[idx:end_idx],\n",
        "            'position': torch.arange(seq_len)  # Row number\n",
        "        }\n",
        "\n",
        "        # Apply masking logic to the first element (idx)\n",
        "        sample = {key: sequence[key][0] for key in sequence}\n",
        "        masked_sample = sample.copy()\n",
        "        target = {}\n",
        "\n",
        "        # List of features to potentially mask\n",
        "        maskable_keys = ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']\n",
        "\n",
        "        # Decide how many features to mask (at least one)\n",
        "        num_features_to_mask = random.randint(1, len(maskable_keys))\n",
        "\n",
        "        # Randomly select features to mask\n",
        "        features_to_mask = random.sample(maskable_keys, num_features_to_mask)\n",
        "\n",
        "        for key in maskable_keys:\n",
        "            if key in features_to_mask:\n",
        "                # Mask the feature\n",
        "                target[key] = sample[key]\n",
        "                if key == 'security_id':\n",
        "                    masked_sample[key] = self.security_id_mask\n",
        "                elif key == 'buy_sell':\n",
        "                    masked_sample[key] = self.buy_sell_mask\n",
        "                elif key == 'add_modify_delete':\n",
        "                    masked_sample[key] = self.add_modify_delete_mask\n",
        "                elif key == 'distance':\n",
        "                    masked_sample[key] = self.distance_mask\n",
        "                elif key in ['quantity', 'price']:\n",
        "                    masked_sample[key] = 0.0  # For continuous features, use 0.0 as masked value\n",
        "            else:\n",
        "                target[key] = None  # Not masked\n",
        "\n",
        "        # Return masked_sample, target, and the sequence starting from idx\n",
        "        return masked_sample, target, sequence\n",
        "\n",
        "# Learnable Positional Encoder\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(PositionalEncoder, self).__init__()\n",
        "        self.timestamp_encoder = nn.Linear(1, embedding_dim)\n",
        "        self.position_encoder = nn.Embedding(1000, embedding_dim)  # Assume max 1000 positions\n",
        "\n",
        "    def forward(self, timestamps, positions):\n",
        "        timestamp_emb = self.timestamp_encoder(timestamps.unsqueeze(-1).float())\n",
        "        position_emb = self.position_encoder(positions)\n",
        "        return timestamp_emb + position_emb\n",
        "\n",
        "# Base Model Class\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Order Model with Positional Encoder\n",
        "class OrderModel(BaseModel):\n",
        "    def __init__(self, N_sec_ids, N_distance_bins, embedding_dim=32, hidden_dim=64):\n",
        "        super(OrderModel, self).__init__()\n",
        "\n",
        "        # Mask indices\n",
        "        self.security_id_mask = N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = N_distance_bins\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.security_id_embedding = nn.Embedding(N_sec_ids + 1, embedding_dim, padding_idx=self.security_id_mask)\n",
        "        self.buy_sell_embedding = nn.Embedding(3, embedding_dim, padding_idx=self.buy_sell_mask)  # 0,1,2(mask)\n",
        "        self.add_modify_delete_embedding = nn.Embedding(4, embedding_dim, padding_idx=self.add_modify_delete_mask)  # 0,1,2,3(mask)\n",
        "        self.distance_embedding = nn.Embedding(N_distance_bins + 1, embedding_dim, padding_idx=self.distance_mask)\n",
        "\n",
        "        # Linear layers for continuous features\n",
        "        self.quantity_linear = nn.Linear(1, embedding_dim)\n",
        "        self.price_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # Positional Encoder\n",
        "        self.positional_encoder = PositionalEncoder(embedding_dim)\n",
        "\n",
        "        # LSTM for sequences\n",
        "        self.lstm_input_dim = embedding_dim * 7  # Number of features\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Final fully connected layers\n",
        "        self.fc1 = nn.Linear(embedding_dim * 7 + hidden_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output heads\n",
        "        self.security_id_head = nn.Linear(128, N_sec_ids)\n",
        "        self.buy_sell_head = nn.Linear(128, 2)\n",
        "        self.add_modify_delete_head = nn.Linear(128, 3)\n",
        "        self.distance_head = nn.Linear(128, N_distance_bins)\n",
        "        self.quantity_head = nn.Linear(128, 1)\n",
        "        self.price_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x is a dictionary of features for the masked sample\n",
        "        # seq_data is a dictionary of sequences\n",
        "        # seq_lengths is a list of sequence lengths\n",
        "\n",
        "        batch_size = x['timestamp'].shape[0]\n",
        "\n",
        "        # Process the masked sample\n",
        "        timestamp = x['timestamp']\n",
        "        position = x['position']\n",
        "        security_id = x['security_id']\n",
        "        buy_sell = x['buy_sell']\n",
        "        add_modify_delete = x['add_modify_delete']\n",
        "        quantity = x['quantity'].unsqueeze(1)\n",
        "        price = x['price'].unsqueeze(1)\n",
        "        distance = x['distance']\n",
        "\n",
        "        # Embeddings\n",
        "        positional_emb = self.positional_encoder(timestamp, position)\n",
        "        security_id_emb = self.security_id_embedding(security_id)\n",
        "        buy_sell_emb = self.buy_sell_embedding(buy_sell)\n",
        "        add_modify_delete_emb = self.add_modify_delete_embedding(add_modify_delete)\n",
        "        quantity_emb = self.quantity_linear(quantity)\n",
        "        price_emb = self.price_linear(price)\n",
        "        distance_emb = self.distance_embedding(distance)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        sample_emb = torch.cat([positional_emb,\n",
        "                                security_id_emb,\n",
        "                                buy_sell_emb,\n",
        "                                add_modify_delete_emb,\n",
        "                                quantity_emb,\n",
        "                                price_emb,\n",
        "                                distance_emb], dim=1)  # Shape: (batch_size, embedding_dim * 7)\n",
        "\n",
        "        # Process the sequence data\n",
        "        # For each feature in seq_data, get embeddings\n",
        "\n",
        "        seq_timestamp = seq_data['timestamp']\n",
        "        seq_position = seq_data['position']\n",
        "        seq_security_id = seq_data['security_id']\n",
        "        seq_buy_sell = seq_data['buy_sell']\n",
        "        seq_add_modify_delete = seq_data['add_modify_delete']\n",
        "        seq_quantity = seq_data['quantity']\n",
        "        seq_price = seq_data['price']\n",
        "        seq_distance = seq_data['distance']\n",
        "\n",
        "        # Embeddings for sequence data\n",
        "        seq_positional_emb = self.positional_encoder(seq_timestamp, seq_position)\n",
        "        seq_security_id_emb = self.security_id_embedding(seq_security_id)\n",
        "        seq_buy_sell_emb = self.buy_sell_embedding(seq_buy_sell)\n",
        "        seq_add_modify_delete_emb = self.add_modify_delete_embedding(seq_add_modify_delete)\n",
        "        seq_quantity_emb = self.quantity_linear(seq_quantity.unsqueeze(-1))\n",
        "        seq_price_emb = self.price_linear(seq_price.unsqueeze(-1))\n",
        "        seq_distance_emb = self.distance_embedding(seq_distance)\n",
        "\n",
        "        # Concatenate sequence embeddings\n",
        "        seq_emb = torch.cat([seq_positional_emb,\n",
        "                             seq_security_id_emb,\n",
        "                             seq_buy_sell_emb,\n",
        "                             seq_add_modify_delete_emb,\n",
        "                             seq_quantity_emb,\n",
        "                             seq_price_emb,\n",
        "                             seq_distance_emb], dim=2)  # Shape: (batch_size, seq_len, embedding_dim * 7)\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = pack_padded_sequence(seq_emb, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb)\n",
        "\n",
        "        # Get the last hidden state for each sequence\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Combine the sample embedding with the sequence context\n",
        "        combined = torch.cat([sample_emb, seq_context], dim=1)  # Shape: (batch_size, embedding_dim * 7 + hidden_dim)\n",
        "\n",
        "        # Forward pass\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Outputs\n",
        "        outputs = {\n",
        "            'security_id': self.security_id_head(x),\n",
        "            'buy_sell': self.buy_sell_head(x),\n",
        "            'add_modify_delete': self.add_modify_delete_head(x),\n",
        "            'distance': self.distance_head(x),\n",
        "            'quantity': self.quantity_head(x),\n",
        "            'price': self.price_head(x)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Additional Models (Unchanged for brevity)\n",
        "# Assume the BaseModel class and other models are defined as before\n",
        "\n",
        "# Collate function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    # batch is a list of (masked_sample, target, sequence)\n",
        "    batch_size = len(batch)\n",
        "    masked_samples = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    sequences = [item[2] for item in batch]\n",
        "\n",
        "    # Convert masked_samples to tensors\n",
        "    batch_data = {}\n",
        "    batch_target = {}\n",
        "    seq_data = {}\n",
        "    seq_lengths = []\n",
        "\n",
        "    # Process data\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_data[key] = torch.tensor([sample[key] for sample in masked_samples])\n",
        "\n",
        "    # Process sequences\n",
        "    # Sequences are variable-length\n",
        "    # For each key, we have a list of sequences\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        seq_list = [torch.tensor(seq[key]) for seq in sequences]\n",
        "        seq_padded = nn.utils.rnn.pad_sequence(seq_list, batch_first=True, padding_value=0)\n",
        "        seq_data[key] = seq_padded\n",
        "    # Record lengths\n",
        "    seq_lengths = [len(seq['timestamp']) for seq in sequences]\n",
        "\n",
        "    # Convert seq_lengths to tensor\n",
        "    seq_lengths = torch.tensor(seq_lengths, dtype=torch.long)\n",
        "\n",
        "    # Process target (exclude 'timestamp' and 'position' as they're not in target)\n",
        "    for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_target[key] = []\n",
        "        for target in targets:\n",
        "            if target[key] is not None:\n",
        "                batch_target[key].append(target[key])\n",
        "            else:\n",
        "                batch_target[key].append(-100 if key not in ['quantity', 'price'] else 0.0)\n",
        "\n",
        "        # Convert to tensor and create mask\n",
        "        if key in ['quantity', 'price']:\n",
        "            # For continuous features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != 0.0 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.float)\n",
        "        else:\n",
        "            # For categorical features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != -100 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.long)\n",
        "\n",
        "    return batch_data, batch_target, seq_data, seq_lengths\n",
        "\n",
        "# Training and Testing Loop\n",
        "def train_model(model_class, model_params, dataset_params, training_params):\n",
        "    # Create Dataset and DataLoader\n",
        "    dataset = MaskedOrderDataset(**dataset_params)\n",
        "    dataloader = DataLoader(dataset, batch_size=training_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    # Create model\n",
        "    model = model_class(**model_params).to(training_params['device'])\n",
        "    optimizer = optim.Adam(model.parameters(), lr=training_params['learning_rate'])\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(training_params['num_epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_data, batch_target, seq_data, seq_lengths in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move data to device\n",
        "            device = training_params.get('device', 'cpu')\n",
        "            batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
        "            batch_target = {k: v.to(device) for k, v in batch_target.items()}\n",
        "            seq_data = {k: v.to(device) for k, v in seq_data.items()}\n",
        "            seq_lengths = seq_lengths.to(device)\n",
        "\n",
        "            outputs = model(batch_data, seq_data, seq_lengths)\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            # Compute loss for each feature\n",
        "            for key in ['security_id', 'buy_sell', 'add_modify_delete', 'distance']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        loss_feature = criterion_ce(outputs[key], target)\n",
        "                        loss += loss_feature\n",
        "\n",
        "            for key in ['quantity', 'price']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        output = outputs[key].squeeze()\n",
        "                        loss_feature = criterion_l1(output[mask], target[mask])\n",
        "                        loss += loss_feature\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Beam Search Generation Function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# [The code above remains unchanged until the generate_sequences function]\n",
        "\n",
        "# Beam Search Generation Function\n",
        "def generate_sequences(model, past_data, security_id, num_timesteps, beam_width, num_samples, device='cpu'):\n",
        "    \"\"\"\n",
        "    Generate sequences using beam search.\n",
        "\n",
        "    Args:\n",
        "        model: Trained model.\n",
        "        past_data: Dictionary containing past sequences.\n",
        "        security_id: The security ID to generate sequences for.\n",
        "        num_timesteps: Number of timesteps to generate.\n",
        "        beam_width: Beam width.\n",
        "        num_samples: Number of samples to generate.\n",
        "        device: Device to run the computations on.\n",
        "\n",
        "    Returns:\n",
        "        generated_sequences: A list of generated sequences.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Initialize the beam with the past_data\n",
        "        # Each beam entry is a tuple (sequence, cumulative_log_prob)\n",
        "        beam = [({'timestamp': past_data['timestamp'],\n",
        "                  'position': past_data['position'],\n",
        "                  'security_id': past_data['security_id'],\n",
        "                  'buy_sell': past_data['buy_sell'],\n",
        "                  'add_modify_delete': past_data['add_modify_delete'],\n",
        "                  'quantity': past_data['quantity'],\n",
        "                  'price': past_data['price'],\n",
        "                  'distance': past_data['distance']},\n",
        "                 0.0)]  # Start with log probability 0\n",
        "\n",
        "        for t in range(num_timesteps):\n",
        "            new_beam = []\n",
        "            for seq, cum_log_prob in beam:\n",
        "                # Prepare input data\n",
        "                # Use the last max_seq_len elements\n",
        "                seq_len = len(seq['timestamp'])\n",
        "                start_idx = max(0, seq_len - model.lstm_input_dim)\n",
        "                seq_data = {key: torch.tensor(seq[key][start_idx:]).unsqueeze(0).to(device) for key in seq}\n",
        "                seq_lengths = torch.tensor([seq_data['timestamp'].shape[1]]).to(device)\n",
        "\n",
        "                # Create a sample with masked features (except security_id and timestamp)\n",
        "                sample = {\n",
        "                    'timestamp': torch.tensor([seq['timestamp'][-1] + 1]).to(device),\n",
        "                    'position': torch.tensor([seq['position'][-1] + 1]).to(device),\n",
        "                    'security_id': torch.tensor([security_id]).to(device),\n",
        "                    'buy_sell': torch.tensor([model.buy_sell_mask]).to(device),\n",
        "                    'add_modify_delete': torch.tensor([model.add_modify_delete_mask]).to(device),\n",
        "                    'quantity': torch.tensor([0.0]).to(device),\n",
        "                    'price': torch.tensor([0.0]).to(device),\n",
        "                    'distance': torch.tensor([model.distance_mask]).to(device)\n",
        "                }\n",
        "\n",
        "                # Predict missing features\n",
        "                outputs = model(sample, seq_data, seq_lengths)\n",
        "\n",
        "                # For each categorical feature, get top N predictions\n",
        "                candidates = []\n",
        "\n",
        "                # Adjust topk for buy_sell\n",
        "                buy_sell_probs = F.softmax(outputs['buy_sell'], dim=-1)\n",
        "                num_buy_sell_classes = buy_sell_probs.size(-1)\n",
        "                buy_sell_topk_k = min(beam_width, num_buy_sell_classes)\n",
        "                buy_sell_topk = torch.topk(buy_sell_probs, buy_sell_topk_k)\n",
        "\n",
        "                # Adjust topk for add_modify_delete\n",
        "                add_modify_delete_probs = F.softmax(outputs['add_modify_delete'], dim=-1)\n",
        "                num_amd_classes = add_modify_delete_probs.size(-1)\n",
        "                amd_topk_k = min(beam_width, num_amd_classes)\n",
        "                amd_topk = torch.topk(add_modify_delete_probs, amd_topk_k)\n",
        "\n",
        "                # Adjust topk for distance\n",
        "                distance_probs = F.softmax(outputs['distance'], dim=-1)\n",
        "                num_distance_classes = distance_probs.size(-1)\n",
        "                distance_topk_k = min(beam_width, num_distance_classes)\n",
        "                distance_topk = torch.topk(distance_probs, distance_topk_k)\n",
        "\n",
        "                # For continuous features, we can use the predicted value directly\n",
        "                quantity_pred = outputs['quantity'].item()\n",
        "                price_pred = outputs['price'].item()\n",
        "\n",
        "                # Generate combinations of top predictions\n",
        "                for i in range(buy_sell_topk_k):\n",
        "                    for j in range(amd_topk_k):\n",
        "                        for k in range(distance_topk_k):\n",
        "                            new_seq = {key: seq[key] + [sample[key].item()] for key in seq}\n",
        "                            new_seq['buy_sell'][-1] = buy_sell_topk.indices[0][i].item()\n",
        "                            new_seq['add_modify_delete'][-1] = amd_topk.indices[0][j].item()\n",
        "                            new_seq['distance'][-1] = distance_topk.indices[0][k].item()\n",
        "                            new_seq['quantity'][-1] = quantity_pred\n",
        "                            new_seq['price'][-1] = price_pred\n",
        "\n",
        "                            # Compute new cumulative log probability\n",
        "                            log_prob = cum_log_prob + \\\n",
        "                                       torch.log(buy_sell_topk.values[0][i] + 1e-9).item() + \\\n",
        "                                       torch.log(amd_topk.values[0][j] + 1e-9).item() + \\\n",
        "                                       torch.log(distance_topk.values[0][k] + 1e-9).item()\n",
        "                            candidates.append((new_seq, log_prob))\n",
        "\n",
        "                # Keep top beam_width candidates\n",
        "                candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "                new_beam.extend(candidates[:beam_width])\n",
        "\n",
        "            # Keep top beam_width sequences\n",
        "            new_beam.sort(key=lambda x: x[1], reverse=True)\n",
        "            beam = new_beam[:beam_width]\n",
        "\n",
        "        # After generation, sample from the beam to get the required number of samples\n",
        "        generated_sequences = [seq for seq, _ in beam[:num_samples]]\n",
        "        return generated_sequences\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Training parameters\n",
        "    training_params = {\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 0.001,\n",
        "        'num_epochs': 5,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    }\n",
        "\n",
        "    # Dataset parameters\n",
        "    dataset_params = {\n",
        "        'num_samples': 5000,\n",
        "        'mask_prob': 0.15,\n",
        "        'max_seq_len': 50\n",
        "    }\n",
        "\n",
        "    # Model parameters for OrderModel\n",
        "    model_params = {\n",
        "        'N_sec_ids': 100,\n",
        "        'N_distance_bins': 10,\n",
        "        'embedding_dim': 32,\n",
        "        'hidden_dim': 64\n",
        "    }\n",
        "\n",
        "    # Train OrderModel\n",
        "    print(\"Training OrderModel...\")\n",
        "    model = train_model(OrderModel, model_params, dataset_params, training_params)\n",
        "\n",
        "    # Generate sequences using beam search\n",
        "    print(\"\\nGenerating sequences using beam search...\")\n",
        "    # Prepare past_data\n",
        "    past_data = {\n",
        "        'timestamp': [1000, 1001, 1002],\n",
        "        'position': [0, 1, 2],\n",
        "        'security_id': [5, 5, 5],\n",
        "        'buy_sell': [0, 1, 0],\n",
        "        'add_modify_delete': [0, 1, 2],\n",
        "        'quantity': [500.0, 600.0, 700.0],\n",
        "        'price': [50.0, 51.0, 52.0],\n",
        "        'distance': [3, 2, 1]\n",
        "    }\n",
        "\n",
        "    # Parameters for generation\n",
        "    security_id = 5\n",
        "    num_timesteps = 5\n",
        "    beam_width = 3\n",
        "    num_samples = 100\n",
        "\n",
        "    generated_sequences = generate_sequences(\n",
        "        model=model,\n",
        "        past_data=past_data,\n",
        "        security_id=security_id,\n",
        "        num_timesteps=num_timesteps,\n",
        "        beam_width=beam_width,\n",
        "        num_samples=num_samples,\n",
        "        device=training_params['device']\n",
        "    )\n",
        "\n",
        "    # Compute distribution of buys vs sells\n",
        "    total_buy = 0\n",
        "    total_sell = 0\n",
        "    total_actions = 0\n",
        "\n",
        "    for seq in generated_sequences:\n",
        "        buy_sell_seq = seq['buy_sell'][-num_timesteps:]  # Only consider generated timesteps\n",
        "        total_buy += buy_sell_seq.count(0)\n",
        "        total_sell += buy_sell_seq.count(1)\n",
        "        total_actions += len(buy_sell_seq)\n",
        "\n",
        "    buy_percentage = (total_buy / total_actions) * 100 if total_actions > 0 else 0\n",
        "    sell_percentage = (total_sell / total_actions) * 100 if total_actions > 0 else 0\n",
        "\n",
        "    print(f\"\\nGenerated {num_samples} sequences of {num_timesteps} timesteps each.\")\n",
        "    print(f\"Buy actions: {buy_percentage:.2f}%\")\n",
        "    print(f\"Sell actions: {sell_percentage:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsIUq3D9JxZo",
        "outputId": "bd5d6d2d-af53-4af9-a4c7-2d2052bf03c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training OrderModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-fa16ee2492a3>:279: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 375.6108235158738\n",
            "Epoch 2, Loss: 349.5281865794188\n",
            "Epoch 3, Loss: 321.91743964905953\n",
            "Epoch 4, Loss: 304.81262012651774\n",
            "Epoch 5, Loss: 295.27519867526496\n",
            "\n",
            "Generating sequences using beam search...\n",
            "\n",
            "Generated 3 sequences of 5 timesteps each.\n",
            "Buy actions: 40.00%\n",
            "Sell actions: 60.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Parameters for generation\n",
        "    security_id = 5\n",
        "    num_timesteps = 50\n",
        "    beam_width = 45\n",
        "    num_samples = 130\n",
        "\n",
        "    generated_sequences = generate_sequences(\n",
        "        model=model,\n",
        "        past_data=past_data,\n",
        "        security_id=security_id,\n",
        "        num_timesteps=num_timesteps,\n",
        "        beam_width=beam_width,\n",
        "        num_samples=num_samples,\n",
        "        device=training_params['device']\n",
        "    )\n",
        "\n",
        "    # Compute distribution of buys vs sells\n",
        "    total_buy = 0\n",
        "    total_sell = 0\n",
        "    total_actions = 0\n",
        "\n",
        "    for seq in generated_sequences:\n",
        "        buy_sell_seq = seq['buy_sell'][-num_timesteps:]  # Only consider generated timesteps\n",
        "        total_buy += buy_sell_seq.count(0)\n",
        "        total_sell += buy_sell_seq.count(1)\n",
        "        total_actions += len(buy_sell_seq)\n",
        "\n",
        "    buy_percentage = (total_buy / total_actions) * 100 if total_actions > 0 else 0\n",
        "    sell_percentage = (total_sell / total_actions) * 100 if total_actions > 0 else 0\n",
        "\n",
        "    print(f\"\\nGenerated {num_samples} sequences of {num_timesteps} timesteps each.\")\n",
        "    print(f\"Buy actions: {buy_percentage:.2f}%\")\n",
        "    print(f\"Sell actions: {sell_percentage:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB36GcVVLXMH",
        "outputId": "1dc5022b-1ff7-467a-ac51-b7d160fa387f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated 130 sequences of 50 timesteps each.\n",
            "Buy actions: 91.42%\n",
            "Sell actions: 8.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Define the Dataset\n",
        "class MaskedOrderDataset(Dataset):\n",
        "    def __init__(self, num_samples, mask_prob=0.15, max_seq_len=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.N_sec_ids = 100  # Number of unique securities\n",
        "        self.N_distance_bins = 10  # Number of distance bins\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Generate synthetic data\n",
        "        self.timestamps = torch.randint(0, 1000, (num_samples,))\n",
        "        self.security_ids = torch.randint(0, self.N_sec_ids, (num_samples,))\n",
        "        self.buy_sell = torch.randint(0, 2, (num_samples,))  # 0: buy, 1: sell\n",
        "        self.add_modify_delete = torch.randint(0, 3, (num_samples,))  # 0: add, 1: modify, 2: delete\n",
        "        self.quantity = torch.randint(1, 1000, (num_samples,)).float()\n",
        "        self.price = torch.rand(num_samples) * 100  # Prices between 0 and 100\n",
        "        self.distance = torch.randint(0, self.N_distance_bins, (num_samples,))\n",
        "\n",
        "        # Sort the data by timestamps (ascending)\n",
        "        sorted_indices = torch.argsort(self.timestamps)\n",
        "        self.timestamps = self.timestamps[sorted_indices]\n",
        "        self.security_ids = self.security_ids[sorted_indices]\n",
        "        self.buy_sell = self.buy_sell[sorted_indices]\n",
        "        self.add_modify_delete = self.add_modify_delete[sorted_indices]\n",
        "        self.quantity = self.quantity[sorted_indices]\n",
        "        self.price = self.price[sorted_indices]\n",
        "        self.distance = self.distance[sorted_indices]\n",
        "\n",
        "        # Define mask indices\n",
        "        self.security_id_mask = self.N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = self.N_distance_bins\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence from idx to end, up to max_seq_len\n",
        "        end_idx = min(idx + self.max_seq_len, self.num_samples)\n",
        "        seq_len = end_idx - idx\n",
        "        sequence = {\n",
        "            'timestamp': self.timestamps[idx:end_idx],\n",
        "            'security_id': self.security_ids[idx:end_idx],\n",
        "            'buy_sell': self.buy_sell[idx:end_idx],\n",
        "            'add_modify_delete': self.add_modify_delete[idx:end_idx],\n",
        "            'quantity': self.quantity[idx:end_idx],\n",
        "            'price': self.price[idx:end_idx],\n",
        "            'distance': self.distance[idx:end_idx],\n",
        "            'position': torch.arange(seq_len)  # Row number\n",
        "        }\n",
        "\n",
        "        # Apply masking logic to the first element (idx)\n",
        "        sample = {key: sequence[key][0] for key in sequence}\n",
        "        masked_sample = sample.copy()\n",
        "        target = {}\n",
        "\n",
        "        # List of features to potentially mask\n",
        "        maskable_keys = ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']\n",
        "\n",
        "        # Decide how many features to mask (at least one)\n",
        "        num_features_to_mask = random.randint(1, len(maskable_keys))\n",
        "\n",
        "        # Randomly select features to mask\n",
        "        features_to_mask = random.sample(maskable_keys, num_features_to_mask)\n",
        "\n",
        "        for key in maskable_keys:\n",
        "            if key in features_to_mask:\n",
        "                # Mask the feature\n",
        "                target[key] = sample[key]\n",
        "                if key == 'security_id':\n",
        "                    masked_sample[key] = self.security_id_mask\n",
        "                elif key == 'buy_sell':\n",
        "                    masked_sample[key] = self.buy_sell_mask\n",
        "                elif key == 'add_modify_delete':\n",
        "                    masked_sample[key] = self.add_modify_delete_mask\n",
        "                elif key == 'distance':\n",
        "                    masked_sample[key] = self.distance_mask\n",
        "                elif key in ['quantity', 'price']:\n",
        "                    masked_sample[key] = 0.0  # For continuous features, use 0.0 as masked value\n",
        "            else:\n",
        "                target[key] = None  # Not masked\n",
        "\n",
        "        # Return masked_sample, target, and the sequence starting from idx\n",
        "        return masked_sample, target, sequence\n",
        "\n",
        "# Learnable Positional Encoder\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(PositionalEncoder, self).__init__()\n",
        "        self.timestamp_encoder = nn.Linear(1, embedding_dim)\n",
        "        self.position_encoder = nn.Embedding(1000, embedding_dim)  # Assume max 1000 positions\n",
        "\n",
        "    def forward(self, timestamps, positions):\n",
        "        timestamp_emb = self.timestamp_encoder(timestamps.unsqueeze(-1).float())\n",
        "        position_emb = self.position_encoder(positions)\n",
        "        return timestamp_emb + position_emb\n",
        "\n",
        "# Base Model Class\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Order Model with Positional Encoder\n",
        "class OrderModel(BaseModel):\n",
        "    def __init__(self, N_sec_ids, N_distance_bins, embedding_dim=32, hidden_dim=64):\n",
        "        super(OrderModel, self).__init__()\n",
        "\n",
        "        # Mask indices\n",
        "        self.security_id_mask = N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = N_distance_bins\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.security_id_embedding = nn.Embedding(N_sec_ids + 1, embedding_dim, padding_idx=self.security_id_mask)\n",
        "        self.buy_sell_embedding = nn.Embedding(3, embedding_dim, padding_idx=self.buy_sell_mask)  # 0,1,2(mask)\n",
        "        self.add_modify_delete_embedding = nn.Embedding(4, embedding_dim, padding_idx=self.add_modify_delete_mask)  # 0,1,2,3(mask)\n",
        "        self.distance_embedding = nn.Embedding(N_distance_bins + 1, embedding_dim, padding_idx=self.distance_mask)\n",
        "\n",
        "        # Linear layers for continuous features\n",
        "        self.quantity_linear = nn.Linear(1, embedding_dim)\n",
        "        self.price_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # Positional Encoder\n",
        "        self.positional_encoder = PositionalEncoder(embedding_dim)\n",
        "\n",
        "        # LSTM for sequences\n",
        "        self.lstm_input_dim = embedding_dim * 7  # Number of features\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Final fully connected layers\n",
        "        self.fc1 = nn.Linear(embedding_dim * 7 + hidden_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output heads\n",
        "        self.security_id_head = nn.Linear(128, N_sec_ids)\n",
        "        self.buy_sell_head = nn.Linear(128, 2)\n",
        "        self.add_modify_delete_head = nn.Linear(128, 3)\n",
        "        self.distance_head = nn.Linear(128, N_distance_bins)\n",
        "        self.quantity_head = nn.Linear(128, 1)\n",
        "        self.price_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x is a dictionary of features for the masked sample\n",
        "        # seq_data is a dictionary of sequences\n",
        "        # seq_lengths is a list of sequence lengths\n",
        "\n",
        "        batch_size = x['timestamp'].shape[0]\n",
        "\n",
        "        # Process the masked sample\n",
        "        timestamp = x['timestamp']\n",
        "        position = x['position']\n",
        "        security_id = x['security_id']\n",
        "        buy_sell = x['buy_sell']\n",
        "        add_modify_delete = x['add_modify_delete']\n",
        "        quantity = x['quantity'].unsqueeze(1)\n",
        "        price = x['price'].unsqueeze(1)\n",
        "        distance = x['distance']\n",
        "\n",
        "        # Embeddings\n",
        "        positional_emb = self.positional_encoder(timestamp, position)\n",
        "        security_id_emb = self.security_id_embedding(security_id)\n",
        "        buy_sell_emb = self.buy_sell_embedding(buy_sell)\n",
        "        add_modify_delete_emb = self.add_modify_delete_embedding(add_modify_delete)\n",
        "        quantity_emb = self.quantity_linear(quantity)\n",
        "        price_emb = self.price_linear(price)\n",
        "        distance_emb = self.distance_embedding(distance)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        sample_emb = torch.cat([positional_emb,\n",
        "                                security_id_emb,\n",
        "                                buy_sell_emb,\n",
        "                                add_modify_delete_emb,\n",
        "                                quantity_emb,\n",
        "                                price_emb,\n",
        "                                distance_emb], dim=1)  # Shape: (batch_size, embedding_dim * 7)\n",
        "\n",
        "        # Process the sequence data\n",
        "        # For each feature in seq_data, get embeddings\n",
        "\n",
        "        seq_timestamp = seq_data['timestamp']\n",
        "        seq_position = seq_data['position']\n",
        "        seq_security_id = seq_data['security_id']\n",
        "        seq_buy_sell = seq_data['buy_sell']\n",
        "        seq_add_modify_delete = seq_data['add_modify_delete']\n",
        "        seq_quantity = seq_data['quantity']\n",
        "        seq_price = seq_data['price']\n",
        "        seq_distance = seq_data['distance']\n",
        "\n",
        "        # Embeddings for sequence data\n",
        "        seq_positional_emb = self.positional_encoder(seq_timestamp, seq_position)\n",
        "        seq_security_id_emb = self.security_id_embedding(seq_security_id)\n",
        "        seq_buy_sell_emb = self.buy_sell_embedding(seq_buy_sell)\n",
        "        seq_add_modify_delete_emb = self.add_modify_delete_embedding(seq_add_modify_delete)\n",
        "        seq_quantity_emb = self.quantity_linear(seq_quantity.unsqueeze(-1))\n",
        "        seq_price_emb = self.price_linear(seq_price.unsqueeze(-1))\n",
        "        seq_distance_emb = self.distance_embedding(seq_distance)\n",
        "\n",
        "        # Concatenate sequence embeddings\n",
        "        seq_emb = torch.cat([seq_positional_emb,\n",
        "                             seq_security_id_emb,\n",
        "                             seq_buy_sell_emb,\n",
        "                             seq_add_modify_delete_emb,\n",
        "                             seq_quantity_emb,\n",
        "                             seq_price_emb,\n",
        "                             seq_distance_emb], dim=2)  # Shape: (batch_size, seq_len, embedding_dim * 7)\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = pack_padded_sequence(seq_emb, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb)\n",
        "\n",
        "        # Get the last hidden state for each sequence\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Combine the sample embedding with the sequence context\n",
        "        combined = torch.cat([sample_emb, seq_context], dim=1)  # Shape: (batch_size, embedding_dim * 7 + hidden_dim)\n",
        "\n",
        "        # Forward pass\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Outputs\n",
        "        outputs = {\n",
        "            'security_id': self.security_id_head(x),\n",
        "            'buy_sell': self.buy_sell_head(x),\n",
        "            'add_modify_delete': self.add_modify_delete_head(x),\n",
        "            'distance': self.distance_head(x),\n",
        "            'quantity': self.quantity_head(x),\n",
        "            'price': self.price_head(x)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Additional Models\n",
        "\n",
        "class MatrixRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(input_size, input_size))\n",
        "        self.B = nn.Parameter(torch.randn(input_size, len(output_keys)))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: batch_data concatenated into a single vector\n",
        "        x_vector = torch.cat([x[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else x[key].unsqueeze(-1).float() for key in x], dim=1)\n",
        "        x_vector = x_vector.view(x_vector.size(0), -1)\n",
        "        out = x_vector @ self.A @ self.B  # Shape: (batch_size, num_outputs)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = out[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class LogisticRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: batch_data concatenated into a single vector\n",
        "        x_vector = torch.cat([x[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else x[key].unsqueeze(-1).float() for key in x], dim=1)\n",
        "        x_vector = x_vector.view(x_vector.size(0), -1)\n",
        "        out = self.linear(x_vector)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = out[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class CNNModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        seq_vector = seq_vector.permute(0, 2, 1)  # (batch_size, num_features, seq_len)\n",
        "        x = self.relu(self.conv1(seq_vector))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = x[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_keys):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        packed_seq_emb = pack_padded_sequence(seq_vector, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        h0 = torch.zeros(self.lstm.num_layers, seq_vector.size(0), self.lstm.hidden_size).to(seq_vector.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, seq_vector.size(0), self.lstm.hidden_size).to(seq_vector.device)\n",
        "\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb, (h0, c0))\n",
        "\n",
        "        # Get the last hidden state\n",
        "        seq_context = h_n[-1​⬤"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "559vmJQKWopg",
        "outputId": "b1db5664-9e62-47c1-fa64-a512a4420d00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (<ipython-input-7-9eb5d33bcc7f>, line 377)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-9eb5d33bcc7f>\"\u001b[0;36m, line \u001b[0;32m377\u001b[0m\n\u001b[0;31m    seq_context = h_n[-1​⬤\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Define the Dataset\n",
        "class MaskedOrderDataset(Dataset):\n",
        "    def __init__(self, num_samples, mask_prob=0.15, max_seq_len=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.N_sec_ids = 100  # Number of unique securities\n",
        "        self.N_distance_bins = 10  # Number of distance bins\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Generate synthetic data\n",
        "        self.timestamps = torch.randint(0, 1000, (num_samples,))\n",
        "        self.security_ids = torch.randint(0, self.N_sec_ids, (num_samples,))\n",
        "        self.buy_sell = torch.randint(0, 2, (num_samples,))  # 0: buy, 1: sell\n",
        "        self.add_modify_delete = torch.randint(0, 3, (num_samples,))  # 0: add, 1: modify, 2: delete\n",
        "        self.quantity = torch.randint(1, 1000, (num_samples,)).float()\n",
        "        self.price = torch.rand(num_samples) * 100  # Prices between 0 and 100\n",
        "        self.distance = torch.randint(0, self.N_distance_bins, (num_samples,))\n",
        "\n",
        "        # Sort the data by timestamps (ascending)\n",
        "        sorted_indices = torch.argsort(self.timestamps)\n",
        "        self.timestamps = self.timestamps[sorted_indices]\n",
        "        self.security_ids = self.security_ids[sorted_indices]\n",
        "        self.buy_sell = self.buy_sell[sorted_indices]\n",
        "        self.add_modify_delete = self.add_modify_delete[sorted_indices]\n",
        "        self.quantity = self.quantity[sorted_indices]\n",
        "        self.price = self.price[sorted_indices]\n",
        "        self.distance = self.distance[sorted_indices]\n",
        "\n",
        "        # Define mask indices\n",
        "        self.security_id_mask = self.N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = self.N_distance_bins\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence from idx to end, up to max_seq_len\n",
        "        end_idx = min(idx + self.max_seq_len, self.num_samples)\n",
        "        seq_len = end_idx - idx\n",
        "        sequence = {\n",
        "            'timestamp': self.timestamps[idx:end_idx],\n",
        "            'security_id': self.security_ids[idx:end_idx],\n",
        "            'buy_sell': self.buy_sell[idx:end_idx],\n",
        "            'add_modify_delete': self.add_modify_delete[idx:end_idx],\n",
        "            'quantity': self.quantity[idx:end_idx],\n",
        "            'price': self.price[idx:end_idx],\n",
        "            'distance': self.distance[idx:end_idx],\n",
        "            'position': torch.arange(seq_len)  # Row number\n",
        "        }\n",
        "\n",
        "        # Apply masking logic to the first element (idx)\n",
        "        sample = {key: sequence[key][0] for key in sequence}\n",
        "        masked_sample = sample.copy()\n",
        "        target = {}\n",
        "\n",
        "        # List of features to potentially mask\n",
        "        maskable_keys = ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']\n",
        "\n",
        "        # Decide how many features to mask (at least one)\n",
        "        num_features_to_mask = random.randint(1, len(maskable_keys))\n",
        "\n",
        "        # Randomly select features to mask\n",
        "        features_to_mask = random.sample(maskable_keys, num_features_to_mask)\n",
        "\n",
        "        for key in maskable_keys:\n",
        "            if key in features_to_mask:\n",
        "                # Mask the feature\n",
        "                target[key] = sample[key]\n",
        "                if key == 'security_id':\n",
        "                    masked_sample[key] = self.security_id_mask\n",
        "                elif key == 'buy_sell':\n",
        "                    masked_sample[key] = self.buy_sell_mask\n",
        "                elif key == 'add_modify_delete':\n",
        "                    masked_sample[key] = self.add_modify_delete_mask\n",
        "                elif key == 'distance':\n",
        "                    masked_sample[key] = self.distance_mask\n",
        "                elif key in ['quantity', 'price']:\n",
        "                    masked_sample[key] = 0.0  # For continuous features, use 0.0 as masked value\n",
        "            else:\n",
        "                target[key] = None  # Not masked\n",
        "\n",
        "        # Return masked_sample, target, and the sequence starting from idx\n",
        "        return masked_sample, target, sequence\n",
        "\n",
        "# Learnable Positional Encoder\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(PositionalEncoder, self).__init__()\n",
        "        self.timestamp_encoder = nn.Linear(1, embedding_dim)\n",
        "        self.position_encoder = nn.Embedding(1000, embedding_dim)  # Assume max 1000 positions\n",
        "\n",
        "    def forward(self, timestamps, positions):\n",
        "        timestamp_emb = self.timestamp_encoder(timestamps.unsqueeze(-1).float())\n",
        "        position_emb = self.position_encoder(positions)\n",
        "        return timestamp_emb + position_emb\n",
        "\n",
        "# Base Model Class\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Order Model with Positional Encoder\n",
        "class OrderModel(BaseModel):\n",
        "    def __init__(self, N_sec_ids, N_distance_bins, embedding_dim=32, hidden_dim=64):\n",
        "        super(OrderModel, self).__init__()\n",
        "\n",
        "        # Mask indices\n",
        "        self.security_id_mask = N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = N_distance_bins\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.security_id_embedding = nn.Embedding(N_sec_ids + 1, embedding_dim, padding_idx=self.security_id_mask)\n",
        "        self.buy_sell_embedding = nn.Embedding(3, embedding_dim, padding_idx=self.buy_sell_mask)  # 0,1,2(mask)\n",
        "        self.add_modify_delete_embedding = nn.Embedding(4, embedding_dim, padding_idx=self.add_modify_delete_mask)  # 0,1,2,3(mask)\n",
        "        self.distance_embedding = nn.Embedding(N_distance_bins + 1, embedding_dim, padding_idx=self.distance_mask)\n",
        "\n",
        "        # Linear layers for continuous features\n",
        "        self.quantity_linear = nn.Linear(1, embedding_dim)\n",
        "        self.price_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # Positional Encoder\n",
        "        self.positional_encoder = PositionalEncoder(embedding_dim)\n",
        "\n",
        "        # LSTM for sequences\n",
        "        self.lstm_input_dim = embedding_dim * 7  # Number of features\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Final fully connected layers\n",
        "        self.fc1 = nn.Linear(embedding_dim * 7 + hidden_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output heads\n",
        "        self.security_id_head = nn.Linear(128, N_sec_ids)\n",
        "        self.buy_sell_head = nn.Linear(128, 2)\n",
        "        self.add_modify_delete_head = nn.Linear(128, 3)\n",
        "        self.distance_head = nn.Linear(128, N_distance_bins)\n",
        "        self.quantity_head = nn.Linear(128, 1)\n",
        "        self.price_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x is a dictionary of features for the masked sample\n",
        "        # seq_data is a dictionary of sequences\n",
        "        # seq_lengths is a list of sequence lengths\n",
        "\n",
        "        batch_size = x['timestamp'].shape[0]\n",
        "\n",
        "        # Process the masked sample\n",
        "        timestamp = x['timestamp']\n",
        "        position = x['position']\n",
        "        security_id = x['security_id']\n",
        "        buy_sell = x['buy_sell']\n",
        "        add_modify_delete = x['add_modify_delete']\n",
        "        quantity = x['quantity'].unsqueeze(1)\n",
        "        price = x['price'].unsqueeze(1)\n",
        "        distance = x['distance']\n",
        "\n",
        "        # Embeddings\n",
        "        positional_emb = self.positional_encoder(timestamp, position)\n",
        "        security_id_emb = self.security_id_embedding(security_id)\n",
        "        buy_sell_emb = self.buy_sell_embedding(buy_sell)\n",
        "        add_modify_delete_emb = self.add_modify_delete_embedding(add_modify_delete)\n",
        "        quantity_emb = self.quantity_linear(quantity)\n",
        "        price_emb = self.price_linear(price)\n",
        "        distance_emb = self.distance_embedding(distance)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        sample_emb = torch.cat([positional_emb,\n",
        "                                security_id_emb,\n",
        "                                buy_sell_emb,\n",
        "                                add_modify_delete_emb,\n",
        "                                quantity_emb,\n",
        "                                price_emb,\n",
        "                                distance_emb], dim=1)  # Shape: (batch_size, embedding_dim * 7)\n",
        "\n",
        "        # Process the sequence data\n",
        "        # For each feature in seq_data, get embeddings\n",
        "\n",
        "        seq_timestamp = seq_data['timestamp']\n",
        "        seq_position = seq_data['position']\n",
        "        seq_security_id = seq_data['security_id']\n",
        "        seq_buy_sell = seq_data['buy_sell']\n",
        "        seq_add_modify_delete = seq_data['add_modify_delete']\n",
        "        seq_quantity = seq_data['quantity']\n",
        "        seq_price = seq_data['price']\n",
        "        seq_distance = seq_data['distance']\n",
        "\n",
        "        # Embeddings for sequence data\n",
        "        seq_positional_emb = self.positional_encoder(seq_timestamp, seq_position)\n",
        "        seq_security_id_emb = self.security_id_embedding(seq_security_id)\n",
        "        seq_buy_sell_emb = self.buy_sell_embedding(seq_buy_sell)\n",
        "        seq_add_modify_delete_emb = self.add_modify_delete_embedding(seq_add_modify_delete)\n",
        "        seq_quantity_emb = self.quantity_linear(seq_quantity.unsqueeze(-1))\n",
        "        seq_price_emb = self.price_linear(seq_price.unsqueeze(-1))\n",
        "        seq_distance_emb = self.distance_embedding(seq_distance)\n",
        "\n",
        "        # Concatenate sequence embeddings\n",
        "        seq_emb = torch.cat([seq_positional_emb,\n",
        "                             seq_security_id_emb,\n",
        "                             seq_buy_sell_emb,\n",
        "                             seq_add_modify_delete_emb,\n",
        "                             seq_quantity_emb,\n",
        "                             seq_price_emb,\n",
        "                             seq_distance_emb], dim=2)  # Shape: (batch_size, seq_len, embedding_dim * 7)\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = pack_padded_sequence(seq_emb, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb)\n",
        "\n",
        "        # Get the last hidden state for each sequence\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Combine the sample embedding with the sequence context\n",
        "        combined = torch.cat([sample_emb, seq_context], dim=1)  # Shape: (batch_size, embedding_dim * 7 + hidden_dim)\n",
        "\n",
        "        # Forward pass\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Outputs\n",
        "        outputs = {\n",
        "            'security_id': self.security_id_head(x),\n",
        "            'buy_sell': self.buy_sell_head(x),\n",
        "            'add_modify_delete': self.add_modify_delete_head(x),\n",
        "            'distance': self.distance_head(x),\n",
        "            'quantity': self.quantity_head(x),\n",
        "            'price': self.price_head(x)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Additional Models\n",
        "\n",
        "class MatrixRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(input_size, input_size))\n",
        "        self.B = nn.Parameter(torch.randn(input_size, len(output_keys)))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: batch_data concatenated into a single vector\n",
        "        x_vector = torch.cat([x[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else x[key].unsqueeze(-1).float() for key in x], dim=1)\n",
        "        x_vector = x_vector.view(x_vector.size(0), -1)\n",
        "        out = x_vector @ self.A @ self.B  # Shape: (batch_size, num_outputs)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = out[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class LogisticRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: batch_data concatenated into a single vector\n",
        "        x_vector = torch.cat([x[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else x[key].unsqueeze(-1).float() for key in x], dim=1)\n",
        "        x_vector = x_vector.view(x_vector.size(0), -1)\n",
        "        out = self.linear(x_vector)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = out[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class CNNModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(128, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        seq_vector = seq_vector.permute(0, 2, 1)  # (batch_size, num_features, seq_len)\n",
        "        x = self.relu(self.conv1(seq_vector))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "        x = self.fc(x)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = x[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_keys):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        packed_seq_emb = pack_padded_sequence(seq_vector, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        h0 = torch.zeros(self.lstm.num_layers, seq_vector.size(0), self.lstm.hidden_size).to(seq_vector.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, seq_vector.size(0), self.lstm.hidden_size).to(seq_vector.device)\n",
        "\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb, (h0, c0))\n",
        "\n",
        "        # Get the last hidden state\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        x = self.fc(seq_context)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = x[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class TransformerModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Transformer Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures global dependencies.\n",
        "    - Parallelizable.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Requires large datasets.\n",
        "    - Computationally intensive.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_heads, num_layers, output_keys):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.positional_encoder = PositionalEncoder(input_size)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=num_heads)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(input_size, len(output_keys))\n",
        "        self.output_keys = output_keys\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() if key in ['quantity', 'price'] else seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        # Add positional encoding\n",
        "        positions = torch.arange(0, seq_vector.size(1), device=seq_vector.device).unsqueeze(0).repeat(seq_vector.size(0), 1)\n",
        "        seq_vector = seq_vector + self.positional_encoder(positions, positions)\n",
        "\n",
        "        # Transformer expects input shape (seq_len, batch_size, feature_dim)\n",
        "        seq_vector = seq_vector.permute(1, 0, 2)\n",
        "        transformer_output = self.transformer_encoder(seq_vector)\n",
        "        # Take the output corresponding to the last position\n",
        "        x = transformer_output[-1, :, :]\n",
        "        x = self.fc(x)\n",
        "\n",
        "        outputs = {}\n",
        "        for i, key in enumerate(self.output_keys):\n",
        "            outputs[key] = x[:, i]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Collate function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    # batch is a list of (masked_sample, target, sequence)\n",
        "    batch_size = len(batch)\n",
        "    masked_samples = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    sequences = [item[2] for item in batch]\n",
        "\n",
        "    # Convert masked_samples to tensors\n",
        "    batch_data = {}\n",
        "    batch_target = {}\n",
        "    seq_data = {}\n",
        "    seq_lengths = []\n",
        "\n",
        "    # Process data\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_data[key] = torch.tensor([sample[key] for sample in masked_samples])\n",
        "\n",
        "    # Process sequences\n",
        "    # Sequences are variable-length\n",
        "    # For each key, we have a list of sequences\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        seq_list = [torch.tensor(seq[key]) for seq in sequences]\n",
        "        seq_padded = nn.utils.rnn.pad_sequence(seq_list, batch_first=True, padding_value=0)\n",
        "        seq_data[key] = seq_padded\n",
        "    # Record lengths\n",
        "    seq_lengths = [len(seq['timestamp']) for seq in sequences]\n",
        "\n",
        "    # Convert seq_lengths to tensor\n",
        "    seq_lengths = torch.tensor(seq_lengths, dtype=torch.long)\n",
        "\n",
        "    # Process target (exclude 'timestamp' and 'position' as they're not in target)\n",
        "    for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_target[key] = []\n",
        "        for target in targets:\n",
        "            if target[key] is not None:\n",
        "                batch_target[key].append(target[key])\n",
        "            else:\n",
        "                batch_target[key].append(-100 if key not in ['quantity', 'price'] else 0.0)\n",
        "\n",
        "        # Convert to tensor and create mask\n",
        "        if key in ['quantity', 'price']:\n",
        "            # For continuous features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != 0.0 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.float)\n",
        "        else:\n",
        "            # For categorical features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != -100 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.long)\n",
        "\n",
        "    return batch_data, batch_target, seq_data, seq_lengths\n",
        "\n",
        "# Training and Testing Loop\n",
        "def train_model(model_class, model_params, dataset_params, training_params):\n",
        "    # Create Dataset and DataLoader\n",
        "    dataset = MaskedOrderDataset(**dataset_params)\n",
        "    dataloader = DataLoader(dataset, batch_size=training_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    # Create model\n",
        "    model = model_class(**model_params).to(training_params['device'])\n",
        "    optimizer = optim.Adam(model.parameters(), lr=training_params['learning_rate'])\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(training_params['num_epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_data, batch_target, seq_data, seq_lengths in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move data to device\n",
        "            device = training_params.get('device', 'cpu')\n",
        "            batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
        "            batch_target = {k: v.to(device) for k, v in batch_target.items()}\n",
        "            seq_data = {k: v.to(device) for k, v in seq_data.items()}\n",
        "            seq_lengths = seq_lengths.to(device)\n",
        "\n",
        "            outputs = model(batch_data, seq_data, seq_lengths)\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            # Compute loss for each feature\n",
        "            for key in ['security_id', 'buy_sell', 'add_modify_delete', 'distance']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        loss_feature = criterion_ce(outputs[key], target)\n",
        "                        loss += loss_feature\n",
        "\n",
        "            for key in ['quantity', 'price']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        output = outputs[key].squeeze()\n",
        "                        loss_feature = criterion_l1(output[mask], target[mask])\n",
        "                        loss += loss_feature\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Beam Search Generation Function\n",
        "def generate_sequences(model, past_data, security_id, num_timesteps, beam_width, num_samples, device='cpu'):\n",
        "    \"\"\"\n",
        "    Generate sequences using beam search.\n",
        "\n",
        "    Args:\n",
        "        model: Trained model.\n",
        "        past_data: Dictionary containing past sequences.\n",
        "        security_id: The security ID to generate sequences for.\n",
        "        num_timesteps: Number of timesteps to generate.\n",
        "        beam_width: Beam width.\n",
        "        num_samples: Number of samples to generate.\n",
        "        device: Device to run the computations on.\n",
        "\n",
        "    Returns:\n",
        "        generated_sequences: A list of generated sequences.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Initialize the beam with the past_data\n",
        "        # Each beam entry is a tuple (sequence, cumulative_log_prob)\n",
        "        beam = [({'timestamp': past_data['timestamp'],\n",
        "                  'position': past_data['position'],\n",
        "                  'security_id': past_data['security_id'],\n",
        "                  'buy_sell': past_data['buy_sell'],\n",
        "                  'add_modify_delete': past_data['add_modify_delete'],\n",
        "                  'quantity': past_data['quantity'],\n",
        "                  'price': past_data['price'],\n",
        "                  'distance': past_data['distance']},\n",
        "                 0.0)]  # Start with log probability 0\n",
        "\n",
        "        for t in range(num_timesteps):\n",
        "            new_beam = []\n",
        "            for seq, cum_log_prob in beam:\n",
        "                # Prepare input data\n",
        "                # Use the last max_seq_len elements\n",
        "                seq_len = len(seq['timestamp'])\n",
        "                start_idx = max(0, seq_len - model.lstm_input_dim) if hasattr(model, 'lstm_input_dim') else 0\n",
        "                seq_data = {key: torch.tensor(seq[key][start_idx:]).unsqueeze(0).to(device) for key in seq}\n",
        "                seq_lengths = torch.tensor([seq_data['timestamp'].shape[1]]).to(device)\n",
        "\n",
        "                # Create a sample with masked features (except security_id and timestamp)\n",
        "                sample = {\n",
        "                    'timestamp': torch.tensor([seq['timestamp'][-1] + 1]).to(device),\n",
        "                    'position': torch.tensor([seq['position'][-1] + 1]).to(device),\n",
        "                    'security_id': torch.tensor([security_id]).to(device),\n",
        "                    'buy_sell': torch.tensor([model.buy_sell_mask if hasattr(model, 'buy_sell_mask') else 2]).to(device),\n",
        "                    'add_modify_delete': torch.tensor([model.add_modify_delete_mask if hasattr(model, 'add_modify_delete_mask') else 3]).to(device),\n",
        "                    'quantity': torch.tensor([0.0]).to(device),\n",
        "                    'price': torch.tensor([0.0]).to(device),\n",
        "                    'distance': torch.tensor([model.distance_mask if hasattr(model, 'distance_mask') else 10]).to(device)\n",
        "                }\n",
        "\n",
        "                # Predict missing features\n",
        "                outputs = model(sample, seq_data, seq_lengths)\n",
        "\n",
        "                # For each categorical feature, get top N predictions\n",
        "                candidates = []\n",
        "\n",
        "                # Adjust topk for buy_sell\n",
        "                if 'buy_sell' in outputs:\n",
        "                    buy_sell_probs = F.softmax(outputs['buy_sell'], dim=-1)\n",
        "                    num_buy_sell_classes = buy_sell_probs.size(-1)\n",
        "                    buy_sell_topk_k = min(beam_width, num_buy_sell_classes)\n",
        "                    buy_sell_topk = torch.topk(buy_sell_probs, buy_sell_topk_k)\n",
        "                else:\n",
        "                    buy_sell_topk_k = 1\n",
        "                    buy_sell_topk = None\n",
        "\n",
        "                # Adjust topk for add_modify_delete\n",
        "                if 'add_modify_delete' in outputs:\n",
        "                    add_modify_delete_probs = F.softmax(outputs['add_modify_delete'], dim=-1)\n",
        "                    num_amd_classes = add_modify_delete_probs.size(-1)\n",
        "                    amd_topk_k = min(beam_width, num_amd_classes)\n",
        "                    amd_topk = torch.topk(add_modify_delete_probs, amd_topk_k)\n",
        "                else:\n",
        "                    amd_topk_k = 1\n",
        "                    amd_topk = None\n",
        "\n",
        "                # Adjust topk for distance\n",
        "                if 'distance' in outputs:\n",
        "                    distance_probs = F.softmax(outputs['distance'], dim=-1)\n",
        "                    num_distance_classes = distance_probs.size(-1)\n",
        "                    distance_topk_k = min(beam_width, num_distance_classes)\n",
        "                    distance_topk = torch.topk(distance_probs, distance_topk_k)\n",
        "                else:\n",
        "                    distance_topk_k = 1\n",
        "                    distance_topk = None\n",
        "\n",
        "                # For continuous features, we can use the predicted value directly\n",
        "                quantity_pred = outputs['quantity'].item() if 'quantity' in outputs else 0.0\n",
        "                price_pred = outputs['price'].item() if 'price' in outputs else 0.0\n",
        "\n",
        "                # Generate combinations of top predictions\n",
        "                for i in range(buy_sell_topk_k):\n",
        "                    for j in range(amd_topk_k):\n",
        "                        for k in range(distance_topk_k):\n",
        "                            new_seq = {key: seq[key] + [sample[key].item()] for key in seq}\n",
        "                            if buy_sell_topk is not None:\n",
        "                                new_seq['buy_sell'][-1] = buy_sell_topk.indices[0][i].item()\n",
        "                            else:\n",
        "                                new_seq['buy_sell'][-1] = seq['buy_sell'][-1]  # Use previous value\n",
        "\n",
        "                            if amd_topk is not None:\n",
        "                                new_seq['add_modify_delete'][-1] = amd_topk.indices[0][j].item()\n",
        "                            else:\n",
        "                                new_seq['add_modify_delete'][-1] = seq['add_modify_delete'][-1]  # Use previous value\n",
        "\n",
        "                            if distance_topk is not None:\n",
        "                                new_seq['distance'][-1] = distance_topk.indices[0][k].item()\n",
        "                            else:\n",
        "                                new_seq['distance'][-1] = seq['distance'][-1]  # Use previous value\n",
        "\n",
        "                            new_seq['quantity'][-1] = quantity_pred\n",
        "                            new_seq['price'][-1] = price_pred\n",
        "\n",
        "                            # Compute new cumulative log probability\n",
        "                            log_prob = cum_log_prob\n",
        "                            if buy_sell_topk is not None:\n",
        "                                log_prob += torch.log(buy_sell_topk.values[0][i] + 1e-9).item()\n",
        "                            if amd_topk is not None:\n",
        "                                log_prob += torch.log(amd_topk.values[0][j] + 1e-9).item()\n",
        "                            if distance_topk is not None:\n",
        "                                log_prob += torch.log(distance_topk.values[0][k] + 1e-9).item()\n",
        "\n",
        "                            candidates.append((new_seq, log_prob))\n",
        "\n",
        "                # Keep top beam_width candidates\n",
        "                candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "                new_beam.extend(candidates[:beam_width])\n",
        "\n",
        "            # Keep top beam_width sequences\n",
        "            new_beam.sort(key=lambda x: x[1], reverse=True)\n",
        "            beam = new_beam[:beam_width]\n",
        "\n",
        "        # After generation, sample from the beam to get the required number of samples\n",
        "        generated_sequences = [seq for seq, _ in beam[:num_samples]]\n",
        "        return generated_sequences\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Training parameters\n",
        "    training_params = {\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 0.001,\n",
        "        'num_epochs': 5,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    }\n",
        "\n",
        "    # Dataset parameters\n",
        "    dataset_params = {\n",
        "        'num_samples': 5000,\n",
        "        'mask_prob': 0.15,\n",
        "        'max_seq_len': 50\n",
        "    }\n",
        "\n",
        "    # Model parameters for OrderModel\n",
        "    model_params = {\n",
        "        'N_sec_ids': 100,\n",
        "        'N_distance_bins': 10,\n",
        "        'embedding_dim': 32,\n",
        "        'hidden_dim': 64\n",
        "    }\n",
        "\n",
        "    # Train OrderModel\n",
        "    print(\"Training OrderModel...\")\n",
        "#    model = train_model(OrderModel, model_params, dataset_params, training_params)\n",
        "\n",
        "    # Example of training another model, e.g., LSTMModel\n",
        "#    '''\n",
        "    print(\"Training LSTMModel...\")\n",
        "    model_params_lstm = {\n",
        "        'input_size': 8,  # Number of features in seq_data\n",
        "        'hidden_size': 64,\n",
        "        'num_layers': 2,\n",
        "        'output_keys': ['security_id', 'buy_sell', 'add_modify_delete', 'distance', 'quantity', 'price']\n",
        "    }\n",
        "    model = train_model(LSTMModel, model_params_lstm, dataset_params, training_params)\n",
        "#    '''\n",
        "\n",
        "    # Generate sequences using beam search\n",
        "    print(\"\\nGenerating sequences using beam search...\")\n",
        "    # Prepare past_data\n",
        "    past_data = {\n",
        "        'timestamp': [1000, 1001, 1002],\n",
        "        'position': [0, 1, 2],\n",
        "        'security_id': [5, 5, 5],\n",
        "        'buy_sell': [0, 1, 0],\n",
        "        'add_modify_delete': [0, 1, 2],\n",
        "        'quantity': [500.0, 600.0, 700.0],\n",
        "        'price': [50.0, 51.0, 52.0],\n",
        "        'distance': [3, 2, 1]\n",
        "    }\n",
        "\n",
        "    # Parameters for generation\n",
        "    security_id = 5\n",
        "    num_timesteps = 5\n",
        "    beam_width = 3\n",
        "    num_samples = 3\n",
        "\n",
        "    generated_sequences = generate_sequences(\n",
        "        model=model,\n",
        "        past_data=past_data,\n",
        "        security_id=security_id,\n",
        "        num_timesteps=num_timesteps,\n",
        "        beam_width=beam_width,\n",
        "        num_samples=num_samples,\n",
        "        device=training_params['device']\n",
        "    )\n",
        "\n",
        "    # Compute distribution of buys vs sells\n",
        "    total_buy = 0\n",
        "    total_sell = 0\n",
        "    total_actions = 0\n",
        "\n",
        "    for seq in generated_sequences:\n",
        "        buy_sell_seq = seq['buy_sell'][-num_timesteps:]  # Only consider generated timesteps\n",
        "        total_buy += buy_sell_seq.count(0)\n",
        "        total_sell += buy_sell_seq.count(1)\n",
        "        total_actions += len(buy_sell_seq)\n",
        "\n",
        "    buy_percentage = (total_buy / total_actions) * 100 if total_actions > 0 else 0\n",
        "    sell_percentage = (total_sell / total_actions) * 100 if total_actions > 0 else 0\n",
        "\n",
        "    print(f\"\\nGenerated {num_samples} sequences of {num_timesteps} timesteps each.\")\n",
        "    print(f\"Buy actions: {buy_percentage:.2f}%\")\n",
        "    print(f\"Sell actions: {sell_percentage:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "1MQcCvHeYySn",
        "outputId": "c3d234b1-4f18-454e-83a2-7b2d53c1a614"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training OrderModel...\n",
            "Training LSTMModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-f82e91cc8d66>:449: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected floating point type for target with class probabilities, got Long",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f82e91cc8d66>\u001b[0m in \u001b[0;36m<cell line: 678>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;34m'output_keys'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'security_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'buy_sell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'add_modify_delete'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'distance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quantity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     }\n\u001b[0;32m--> 715\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTMModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;31m#    '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-f82e91cc8d66>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_class, model_params, dataset_params, training_params)\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                         \u001b[0mloss_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_ce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1294\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3479\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3480\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Define the Dataset\n",
        "class MaskedOrderDataset(Dataset):\n",
        "    def __init__(self, num_samples, mask_prob=0.15, max_seq_len=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.N_sec_ids = 100  # Number of unique securities\n",
        "        self.N_distance_bins = 10  # Number of distance bins\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Generate synthetic data\n",
        "        self.timestamps = torch.randint(0, 1000, (num_samples,))\n",
        "        self.security_ids = torch.randint(0, self.N_sec_ids, (num_samples,))\n",
        "        self.buy_sell = torch.randint(0, 2, (num_samples,))  # 0: buy, 1: sell\n",
        "        self.add_modify_delete = torch.randint(0, 3, (num_samples,))  # 0: add, 1: modify, 2: delete\n",
        "        self.quantity = torch.randint(1, 1000, (num_samples,)).float()\n",
        "        self.price = torch.rand(num_samples) * 100  # Prices between 0 and 100\n",
        "        self.distance = torch.randint(0, self.N_distance_bins, (num_samples,))\n",
        "\n",
        "        # Sort the data by timestamps (ascending)\n",
        "        sorted_indices = torch.argsort(self.timestamps)\n",
        "        self.timestamps = self.timestamps[sorted_indices]\n",
        "        self.security_ids = self.security_ids[sorted_indices]\n",
        "        self.buy_sell = self.buy_sell[sorted_indices]\n",
        "        self.add_modify_delete = self.add_modify_delete[sorted_indices]\n",
        "        self.quantity = self.quantity[sorted_indices]\n",
        "        self.price = self.price[sorted_indices]\n",
        "        self.distance = self.distance[sorted_indices]\n",
        "\n",
        "        # Define mask indices\n",
        "        self.security_id_mask = self.N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = self.N_distance_bins\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence from idx to end, up to max_seq_len\n",
        "        end_idx = min(idx + self.max_seq_len, self.num_samples)\n",
        "        seq_len = end_idx - idx\n",
        "        sequence = {\n",
        "            'timestamp': self.timestamps[idx:end_idx],\n",
        "            'security_id': self.security_ids[idx:end_idx],\n",
        "            'buy_sell': self.buy_sell[idx:end_idx],\n",
        "            'add_modify_delete': self.add_modify_delete[idx:end_idx],\n",
        "            'quantity': self.quantity[idx:end_idx],\n",
        "            'price': self.price[idx:end_idx],\n",
        "            'distance': self.distance[idx:end_idx],\n",
        "            'position': torch.arange(seq_len)  # Row number\n",
        "        }\n",
        "\n",
        "        # Apply masking logic to the first element (idx)\n",
        "        sample = {key: sequence[key][0] for key in sequence}\n",
        "        masked_sample = sample.copy()\n",
        "        target = {}\n",
        "\n",
        "        # List of features to potentially mask\n",
        "        maskable_keys = ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']\n",
        "\n",
        "        # Decide how many features to mask (at least one)\n",
        "        num_features_to_mask = random.randint(1, len(maskable_keys))\n",
        "\n",
        "        # Randomly select features to mask\n",
        "        features_to_mask = random.sample(maskable_keys, num_features_to_mask)\n",
        "\n",
        "        for key in maskable_keys:\n",
        "            if key in features_to_mask:\n",
        "                # Mask the feature\n",
        "                target[key] = sample[key]\n",
        "                if key == 'security_id':\n",
        "                    masked_sample[key] = self.security_id_mask\n",
        "                elif key == 'buy_sell':\n",
        "                    masked_sample[key] = self.buy_sell_mask\n",
        "                elif key == 'add_modify_delete':\n",
        "                    masked_sample[key] = self.add_modify_delete_mask\n",
        "                elif key == 'distance':\n",
        "                    masked_sample[key] = self.distance_mask\n",
        "                elif key in ['quantity', 'price']:\n",
        "                    masked_sample[key] = 0.0  # For continuous features, use 0.0 as masked value\n",
        "            else:\n",
        "                target[key] = None  # Not masked\n",
        "\n",
        "        # Return masked_sample, target, and the sequence starting from idx\n",
        "        return masked_sample, target, sequence\n",
        "\n",
        "# Learnable Positional Encoder\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(PositionalEncoder, self).__init__()\n",
        "        self.timestamp_encoder = nn.Linear(1, embedding_dim)\n",
        "        self.position_encoder = nn.Embedding(1000, embedding_dim)  # Assume max 1000 positions\n",
        "\n",
        "    def forward(self, timestamps, positions):\n",
        "        timestamp_emb = self.timestamp_encoder(timestamps.unsqueeze(-1).float())\n",
        "        position_emb = self.position_encoder(positions)\n",
        "        return timestamp_emb + position_emb\n",
        "\n",
        "# Base Model Class\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Order Model with Positional Encoder\n",
        "class OrderModel(BaseModel):\n",
        "    def __init__(self, N_sec_ids, N_distance_bins, embedding_dim=32, hidden_dim=64):\n",
        "        super(OrderModel, self).__init__()\n",
        "\n",
        "        # Mask indices\n",
        "        self.security_id_mask = N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = N_distance_bins\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.security_id_embedding = nn.Embedding(N_sec_ids + 1, embedding_dim, padding_idx=self.security_id_mask)\n",
        "        self.buy_sell_embedding = nn.Embedding(3, embedding_dim, padding_idx=self.buy_sell_mask)  # 0,1,2(mask)\n",
        "        self.add_modify_delete_embedding = nn.Embedding(4, embedding_dim, padding_idx=self.add_modify_delete_mask)  # 0,1,2,3(mask)\n",
        "        self.distance_embedding = nn.Embedding(N_distance_bins + 1, embedding_dim, padding_idx=self.distance_mask)\n",
        "\n",
        "        # Linear layers for continuous features\n",
        "        self.quantity_linear = nn.Linear(1, embedding_dim)\n",
        "        self.price_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # Positional Encoder\n",
        "        self.positional_encoder = PositionalEncoder(embedding_dim)\n",
        "\n",
        "        # LSTM for sequences\n",
        "        self.lstm_input_dim = embedding_dim * 7  # Number of features\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Final fully connected layers\n",
        "        self.fc1 = nn.Linear(embedding_dim * 7 + hidden_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output heads\n",
        "        self.security_id_head = nn.Linear(128, N_sec_ids)\n",
        "        self.buy_sell_head = nn.Linear(128, 2)\n",
        "        self.add_modify_delete_head = nn.Linear(128, 3)\n",
        "        self.distance_head = nn.Linear(128, N_distance_bins)\n",
        "        self.quantity_head = nn.Linear(128, 1)\n",
        "        self.price_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x is a dictionary of features for the masked sample\n",
        "        # seq_data is a dictionary of sequences\n",
        "        # seq_lengths is a list of sequence lengths\n",
        "\n",
        "        batch_size = x['timestamp'].shape[0]\n",
        "\n",
        "        # Process the masked sample\n",
        "        timestamp = x['timestamp']\n",
        "        position = x['position']\n",
        "        security_id = x['security_id']\n",
        "        buy_sell = x['buy_sell']\n",
        "        add_modify_delete = x['add_modify_delete']\n",
        "        quantity = x['quantity'].unsqueeze(1)\n",
        "        price = x['price'].unsqueeze(1)\n",
        "        distance = x['distance']\n",
        "\n",
        "        # Embeddings\n",
        "        positional_emb = self.positional_encoder(timestamp, position)\n",
        "        security_id_emb = self.security_id_embedding(security_id)\n",
        "        buy_sell_emb = self.buy_sell_embedding(buy_sell)\n",
        "        add_modify_delete_emb = self.add_modify_delete_embedding(add_modify_delete)\n",
        "        quantity_emb = self.quantity_linear(quantity)\n",
        "        price_emb = self.price_linear(price)\n",
        "        distance_emb = self.distance_embedding(distance)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        sample_emb = torch.cat([positional_emb,\n",
        "                                security_id_emb,\n",
        "                                buy_sell_emb,\n",
        "                                add_modify_delete_emb,\n",
        "                                quantity_emb,\n",
        "                                price_emb,\n",
        "                                distance_emb], dim=1)  # Shape: (batch_size, embedding_dim * 7)\n",
        "\n",
        "        # Process the sequence data\n",
        "        # For each feature in seq_data, get embeddings\n",
        "\n",
        "        seq_timestamp = seq_data['timestamp']\n",
        "        seq_position = seq_data['position']\n",
        "        seq_security_id = seq_data['security_id']\n",
        "        seq_buy_sell = seq_data['buy_sell']\n",
        "        seq_add_modify_delete = seq_data['add_modify_delete']\n",
        "        seq_quantity = seq_data['quantity']\n",
        "        seq_price = seq_data['price']\n",
        "        seq_distance = seq_data['distance']\n",
        "\n",
        "        # Embeddings for sequence data\n",
        "        seq_positional_emb = self.positional_encoder(seq_timestamp, seq_position)\n",
        "        seq_security_id_emb = self.security_id_embedding(seq_security_id)\n",
        "        seq_buy_sell_emb = self.buy_sell_embedding(seq_buy_sell)\n",
        "        seq_add_modify_delete_emb = self.add_modify_delete_embedding(seq_add_modify_delete)\n",
        "        seq_quantity_emb = self.quantity_linear(seq_quantity.unsqueeze(-1))\n",
        "        seq_price_emb = self.price_linear(seq_price.unsqueeze(-1))\n",
        "        seq_distance_emb = self.distance_embedding(seq_distance)\n",
        "\n",
        "        # Concatenate sequence embeddings\n",
        "        seq_emb = torch.cat([seq_positional_emb,\n",
        "                             seq_security_id_emb,\n",
        "                             seq_buy_sell_emb,\n",
        "                             seq_add_modify_delete_emb,\n",
        "                             seq_quantity_emb,\n",
        "                             seq_price_emb,\n",
        "                             seq_distance_emb], dim=2)  # Shape: (batch_size, seq_len, embedding_dim * 7)\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = pack_padded_sequence(seq_emb, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb)\n",
        "\n",
        "        # Get the last hidden state for each sequence\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Combine the sample embedding with the sequence context\n",
        "        combined = torch.cat([sample_emb, seq_context], dim=1)  # Shape: (batch_size, embedding_dim * 7 + hidden_dim)\n",
        "\n",
        "        # Forward pass\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Outputs\n",
        "        outputs = {\n",
        "            'security_id': self.security_id_head(x),\n",
        "            'buy_sell': self.buy_sell_head(x),\n",
        "            'add_modify_delete': self.add_modify_delete_head(x),\n",
        "            'distance': self.distance_head(x),\n",
        "            'quantity': self.quantity_head(x),\n",
        "            'price': self.price_head(x)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Additional Models\n",
        "\n",
        "class MatrixRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys, num_classes_dict):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(input_size, input_size))\n",
        "        self.output_heads = nn.ModuleDict()\n",
        "        self.output_keys = output_keys\n",
        "        for key in output_keys:\n",
        "            if key in num_classes_dict:\n",
        "                num_classes = num_classes_dict[key]\n",
        "                self.output_heads[key] = nn.Linear(input_size, num_classes)\n",
        "            else:\n",
        "                self.output_heads[key] = nn.Linear(input_size, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: batch_data concatenated into a single vector\n",
        "        x_vector = torch.cat([x[key].unsqueeze(-1).float() for key in x], dim=1)\n",
        "        x_vector = x_vector.view(x_vector.size(0), -1)\n",
        "        x_transformed = x_vector @ self.A\n",
        "\n",
        "        outputs = {}\n",
        "        for key in self.output_keys:\n",
        "            outputs[key] = self.output_heads[key](x_transformed)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class LogisticRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys, num_classes_dict):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.output_heads = nn.ModuleDict()\n",
        "        self.output_keys = output_keys\n",
        "        for key in output_keys:\n",
        "            if key in num_classes_dict:\n",
        "                num_classes = num_classes_dict[key]\n",
        "                self.output_heads[key] = nn.Linear(input_size, num_classes)\n",
        "            else:\n",
        "                self.output_heads[key] = nn.Linear(input_size, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: batch_data concatenated into a single vector\n",
        "        x_vector = torch.cat([x[key].unsqueeze(-1).float() for key in x], dim=1)\n",
        "        x_vector = x_vector.view(x_vector.size(0), -1)\n",
        "        outputs = {}\n",
        "        for key in self.output_keys:\n",
        "            outputs[key] = self.output_heads[key](x_vector)\n",
        "        return outputs\n",
        "\n",
        "class CNNModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys, num_classes_dict):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.output_heads = nn.ModuleDict()\n",
        "        self.output_keys = output_keys\n",
        "        for key in output_keys:\n",
        "            if key in num_classes_dict:\n",
        "                num_classes = num_classes_dict[key]\n",
        "                self.output_heads[key] = nn.Linear(128, num_classes)\n",
        "            else:\n",
        "                self.output_heads[key] = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        seq_vector = seq_vector.permute(0, 2, 1)  # (batch_size, num_features, seq_len)\n",
        "        x = self.relu(self.conv1(seq_vector))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "\n",
        "        outputs = {}\n",
        "        for key in self.output_keys:\n",
        "            outputs[key] = self.output_heads[key](x)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_keys, num_classes_dict):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.output_heads = nn.ModuleDict()\n",
        "        self.output_keys = output_keys\n",
        "        for key in output_keys:\n",
        "            if key in num_classes_dict:\n",
        "                num_classes = num_classes_dict[key]\n",
        "                self.output_heads[key] = nn.Linear(hidden_size, num_classes)\n",
        "            else:\n",
        "                self.output_heads[key] = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        packed_seq_emb = pack_padded_sequence(seq_vector, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        h0 = torch.zeros(self.lstm.num_layers, seq_vector.size(0), self.lstm.hidden_size).to(seq_vector.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, seq_vector.size(0), self.lstm.hidden_size).to(seq_vector.device)\n",
        "\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb, (h0, c0))\n",
        "\n",
        "        # Get the last hidden state\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        outputs = {}\n",
        "        for key in self.output_keys:\n",
        "            outputs[key] = self.output_heads[key](seq_context)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class TransformerModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Transformer Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures global dependencies.\n",
        "    - Parallelizable.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Requires large datasets.\n",
        "    - Computationally intensive.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_heads, num_layers, output_keys, num_classes_dict):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.positional_encoder = PositionalEncoder(input_size)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=num_heads)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.output_heads = nn.ModuleDict()\n",
        "        self.output_keys = output_keys\n",
        "        for key in output_keys:\n",
        "            if key in num_classes_dict:\n",
        "                num_classes = num_classes_dict[key]\n",
        "                self.output_heads[key] = nn.Linear(input_size, num_classes)\n",
        "            else:\n",
        "                self.output_heads[key] = nn.Linear(input_size, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        # Add positional encoding\n",
        "        positions = torch.arange(0, seq_vector.size(1), device=seq_vector.device).unsqueeze(0).repeat(seq_vector.size(0), 1)\n",
        "        seq_vector = seq_vector + self.positional_encoder(positions, positions)\n",
        "\n",
        "        # Transformer expects input shape (seq_len, batch_size, feature_dim)\n",
        "        seq_vector = seq_vector.permute(1, 0, 2)\n",
        "        transformer_output = self.transformer_encoder(seq_vector)\n",
        "        # Take the output corresponding to the last position\n",
        "        x = transformer_output[-1, :, :]\n",
        "        outputs = {}\n",
        "        for key in self.output_keys:\n",
        "            outputs[key] = self.output_heads[key](x)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Collate function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    # batch is a list of (masked_sample, target, sequence)\n",
        "    batch_size = len(batch)\n",
        "    masked_samples = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    sequences = [item[2] for item in batch]\n",
        "\n",
        "    # Convert masked_samples to tensors\n",
        "    batch_data = {}\n",
        "    batch_target = {}\n",
        "    seq_data = {}\n",
        "    seq_lengths = []\n",
        "\n",
        "    # Process data\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_data[key] = torch.tensor([sample[key] for sample in masked_samples])\n",
        "\n",
        "    # Process sequences\n",
        "    # Sequences are variable-length\n",
        "    # For each key, we have a list of sequences\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        seq_list = [torch.tensor(seq[key]) for seq in sequences]\n",
        "        seq_padded = nn.utils.rnn.pad_sequence(seq_list, batch_first=True, padding_value=0)\n",
        "        seq_data[key] = seq_padded\n",
        "    # Record lengths\n",
        "    seq_lengths = [len(seq['timestamp']) for seq in sequences]\n",
        "\n",
        "    # Convert seq_lengths to tensor\n",
        "    seq_lengths = torch.tensor(seq_lengths, dtype=torch.long)\n",
        "\n",
        "    # Process target (exclude 'timestamp' and 'position' as they're not in target)\n",
        "    for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_target[key] = []\n",
        "        for target in targets:\n",
        "            if target[key] is not None:\n",
        "                batch_target[key].append(target[key])\n",
        "            else:\n",
        "                batch_target[key].append(-100 if key not in ['quantity', 'price'] else 0.0)\n",
        "\n",
        "        # Convert to tensor and create mask\n",
        "        if key in ['quantity', 'price']:\n",
        "            # For continuous features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != 0.0 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.float)\n",
        "        else:\n",
        "            # For categorical features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != -100 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.long)\n",
        "\n",
        "    return batch_data, batch_target, seq_data, seq_lengths\n",
        "\n",
        "# Training and Testing Loop\n",
        "def train_model(model_class, model_params, dataset_params, training_params):\n",
        "    # Create Dataset and DataLoader\n",
        "    dataset = MaskedOrderDataset(**dataset_params)\n",
        "    dataloader = DataLoader(dataset, batch_size=training_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    # Create model\n",
        "    model = model_class(**model_params).to(training_params['device'])\n",
        "    optimizer = optim.Adam(model.parameters(), lr=training_params['learning_rate'])\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(training_params['num_epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_data, batch_target, seq_data, seq_lengths in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move data to device\n",
        "            device = training_params.get('device', 'cpu')\n",
        "            batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
        "            batch_target = {k: v.to(device) for k, v in batch_target.items()}\n",
        "            seq_data = {k: v.to(device) for k, v in seq_data.items()}\n",
        "            seq_lengths = seq_lengths.to(device)\n",
        "\n",
        "            outputs = model(batch_data, seq_data, seq_lengths)\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            # Compute loss for each feature\n",
        "            for key in ['security_id', 'buy_sell', 'add_modify_delete', 'distance']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        output = outputs[key]\n",
        "                        loss_feature = criterion_ce(output, target)\n",
        "                        loss += loss_feature\n",
        "\n",
        "            for key in ['quantity', 'price']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        output = outputs[key].squeeze()\n",
        "                        loss_feature = criterion_l1(output[mask], target[mask])\n",
        "                        loss += loss_feature\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Beam Search Generation Function (unchanged)\n",
        "def generate_sequences(model, past_data, security_id, num_timesteps, beam_width, num_samples, device='cpu'):\n",
        "    # [Function body remains the same]\n",
        "    # For brevity, we'll keep the function as is\n",
        "    pass\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Training parameters\n",
        "    training_params = {\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 0.001,\n",
        "        'num_epochs': 2,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    }\n",
        "\n",
        "    # Dataset parameters\n",
        "    dataset_params = {\n",
        "        'num_samples': 5000,\n",
        "        'mask_prob': 0.15,\n",
        "        'max_seq_len': 50\n",
        "    }\n",
        "\n",
        "    # Common parameters\n",
        "    output_keys = ['security_id', 'buy_sell', 'add_modify_delete', 'distance', 'quantity', 'price']\n",
        "    num_classes_dict = {\n",
        "        'security_id': 100,\n",
        "        'buy_sell': 2,\n",
        "        'add_modify_delete': 3,\n",
        "        'distance': 10\n",
        "    }\n",
        "\n",
        "    # Example 1: Training OrderModel\n",
        "    print(\"Training OrderModel...\")\n",
        "    model_params_order = {\n",
        "        'N_sec_ids': 100,\n",
        "        'N_distance_bins': 10,\n",
        "        'embedding_dim': 32,\n",
        "        'hidden_dim': 64\n",
        "    }\n",
        "    model_order = train_model(OrderModel, model_params_order, dataset_params, training_params)\n",
        "\n",
        "    # Example 2: Training LSTMModel\n",
        "    print(\"\\nTraining LSTMModel...\")\n",
        "    model_params_lstm = {\n",
        "        'input_size': 8,  # Number of features in seq_data\n",
        "        'hidden_size': 64,\n",
        "        'num_layers': 2,\n",
        "        'output_keys': output_keys,\n",
        "        'num_classes_dict': num_classes_dict\n",
        "    }\n",
        "    model_lstm = train_model(LSTMModel, model_params_lstm, dataset_params, training_params)\n",
        "\n",
        "    # Example 3: Training CNNModel\n",
        "    print(\"\\nTraining CNNModel...\")\n",
        "    model_params_cnn = {\n",
        "        'input_size': 8,  # Number of features in seq_data\n",
        "        'output_keys': output_keys,\n",
        "        'num_classes_dict': num_classes_dict\n",
        "    }\n",
        "    model_cnn = train_model(CNNModel, model_params_cnn, dataset_params, training_params)\n",
        "\n",
        "    # Example 4: Training LogisticRegressionModel\n",
        "    print(\"\\nTraining LogisticRegressionModel...\")\n",
        "    model_params_lr = {\n",
        "        'input_size': 8,  # Number of features in batch_data\n",
        "        'output_keys': output_keys,\n",
        "        'num_classes_dict': num_classes_dict\n",
        "    }\n",
        "    model_lr = train_model(LogisticRegressionModel, model_params_lr, dataset_params, training_params)\n",
        "\n",
        "    # Example 5: Training MatrixRegressionModel\n",
        "    print(\"\\nTraining MatrixRegressionModel...\")\n",
        "    model_params_mr = {\n",
        "        'input_size': 8,  # Number of features in batch_data\n",
        "        'output_keys': output_keys,\n",
        "        'num_classes_dict': num_classes_dict\n",
        "    }\n",
        "    model_mr = train_model(MatrixRegressionModel, model_params_mr, dataset_params, training_params)\n",
        "\n",
        "    # Example of generating sequences (for brevity, we use model_order)\n",
        "    print(\"\\nGenerating sequences using beam search with OrderModel...\")\n",
        "    # Prepare past_data\n",
        "    past_data = {\n",
        "        'timestamp': [1000, 1001, 1002],\n",
        "        'position': [0, 1, 2],\n",
        "        'security_id': [5, 5, 5],\n",
        "        'buy_sell': [0, 1, 0],\n",
        "        'add_modify_delete': [0, 1, 2],\n",
        "        'quantity': [500.0, 600.0, 700.0],\n",
        "        'price': [50.0, 51.0, 52.0],\n",
        "        'distance': [3, 2, 1]\n",
        "    }\n",
        "\n",
        "    # Parameters for generation\n",
        "    security_id = 5\n",
        "    num_timesteps = 5\n",
        "    beam_width = 3\n",
        "    num_samples = 3\n",
        "\n",
        "    generated_sequences = generate_sequences(\n",
        "        model=model_order,\n",
        "        past_data=past_data,\n",
        "        security_id=security_id,\n",
        "        num_timesteps=num_timesteps,\n",
        "        beam_width=beam_width,\n",
        "        num_samples=num_samples,\n",
        "        device=training_params['device']\n",
        "    )\n",
        "\n",
        "    # Compute distribution of buys vs sells\n",
        "    # For brevity, we will not reimplement the generate_sequences function here\n",
        "    # Assume it works as in the previous code\n",
        "\n",
        "    print(\"\\nAll models have been trained and sequences generated successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F64ML3eccyHZ",
        "outputId": "cc8a99cb-d641-4ebd-d23d-f8e31faf5099"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training OrderModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-6fa0b59fd028>:471: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 381.1270192140227\n",
            "Epoch 2, Loss: 341.25743229374007\n",
            "\n",
            "Training LSTMModel...\n",
            "Epoch 1, Loss: 540.2828345815087\n",
            "Epoch 2, Loss: 528.951018315212\n",
            "\n",
            "Training CNNModel...\n",
            "Epoch 1, Loss: 326.2109530503583\n",
            "Epoch 2, Loss: 292.82250053259975\n",
            "\n",
            "Training LogisticRegressionModel...\n",
            "Epoch 1, Loss: 889.8038691623955\n",
            "Epoch 2, Loss: 599.5396227016571\n",
            "\n",
            "Training MatrixRegressionModel...\n",
            "Epoch 1, Loss: 1410.0754884367536\n",
            "Epoch 2, Loss: 593.8235143187699\n",
            "\n",
            "Generating sequences using beam search with OrderModel...\n",
            "\n",
            "All models have been trained and sequences generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Define the Dataset\n",
        "class MaskedOrderDataset(Dataset):\n",
        "    def __init__(self, num_samples, mask_prob=0.15, max_seq_len=50):\n",
        "        self.num_samples = num_samples\n",
        "        self.N_sec_ids = 100  # Number of unique securities\n",
        "        self.N_distance_bins = 10  # Number of distance bins\n",
        "        self.mask_prob = mask_prob\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Generate synthetic data\n",
        "        self.timestamps = torch.randint(0, 1000, (num_samples,))\n",
        "        self.security_ids = torch.randint(0, self.N_sec_ids, (num_samples,))\n",
        "        self.buy_sell = torch.randint(0, 2, (num_samples,))  # 0: buy, 1: sell\n",
        "        self.add_modify_delete = torch.randint(0, 3, (num_samples,))  # 0: add, 1: modify, 2: delete\n",
        "        self.quantity = torch.randint(1, 1000, (num_samples,)).float()\n",
        "        self.price = torch.rand(num_samples) * 100  # Prices between 0 and 100\n",
        "        self.distance = torch.randint(0, self.N_distance_bins, (num_samples,))\n",
        "\n",
        "        # Sort the data by timestamps (ascending)\n",
        "        sorted_indices = torch.argsort(self.timestamps)\n",
        "        self.timestamps = self.timestamps[sorted_indices]\n",
        "        self.security_ids = self.security_ids[sorted_indices]\n",
        "        self.buy_sell = self.buy_sell[sorted_indices]\n",
        "        self.add_modify_delete = self.add_modify_delete[sorted_indices]\n",
        "        self.quantity = self.quantity[sorted_indices]\n",
        "        self.price = self.price[sorted_indices]\n",
        "        self.distance = self.distance[sorted_indices]\n",
        "\n",
        "        # Define mask indices\n",
        "        self.security_id_mask = self.N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = self.N_distance_bins\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence from idx to end, up to max_seq_len\n",
        "        end_idx = min(idx + self.max_seq_len, self.num_samples)\n",
        "        seq_len = end_idx - idx\n",
        "        sequence = {\n",
        "            'timestamp': self.timestamps[idx:end_idx],\n",
        "            'security_id': self.security_ids[idx:end_idx],\n",
        "            'buy_sell': self.buy_sell[idx:end_idx],\n",
        "            'add_modify_delete': self.add_modify_delete[idx:end_idx],\n",
        "            'quantity': self.quantity[idx:end_idx],\n",
        "            'price': self.price[idx:end_idx],\n",
        "            'distance': self.distance[idx:end_idx],\n",
        "            'position': torch.arange(seq_len)  # Row number\n",
        "        }\n",
        "\n",
        "        # Apply masking logic to the first element (idx)\n",
        "        sample = {key: sequence[key][0] for key in sequence}\n",
        "        masked_sample = sample.copy()\n",
        "        target = {}\n",
        "\n",
        "        # List of features to potentially mask\n",
        "        maskable_keys = ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']\n",
        "\n",
        "        # Decide how many features to mask (at least one)\n",
        "        num_features_to_mask = random.randint(1, len(maskable_keys))\n",
        "\n",
        "        # Randomly select features to mask\n",
        "        features_to_mask = random.sample(maskable_keys, num_features_to_mask)\n",
        "\n",
        "        for key in maskable_keys:\n",
        "            if key in features_to_mask:\n",
        "                # Mask the feature\n",
        "                target[key] = sample[key]\n",
        "                if key == 'security_id':\n",
        "                    masked_sample[key] = self.security_id_mask\n",
        "                elif key == 'buy_sell':\n",
        "                    masked_sample[key] = self.buy_sell_mask\n",
        "                elif key == 'add_modify_delete':\n",
        "                    masked_sample[key] = self.add_modify_delete_mask\n",
        "                elif key == 'distance':\n",
        "                    masked_sample[key] = self.distance_mask\n",
        "                elif key in ['quantity', 'price']:\n",
        "                    masked_sample[key] = 0.0  # For continuous features, use 0.0 as masked value\n",
        "            else:\n",
        "                target[key] = None  # Not masked\n",
        "\n",
        "        # Return masked_sample, target, and the sequence starting from idx\n",
        "        return masked_sample, target, sequence\n",
        "\n",
        "# Learnable Positional Encoder\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(PositionalEncoder, self).__init__()\n",
        "        self.timestamp_encoder = nn.Linear(1, embedding_dim)\n",
        "        self.position_encoder = nn.Embedding(1000, embedding_dim)  # Assume max 1000 positions\n",
        "\n",
        "    def forward(self, timestamps, positions):\n",
        "        timestamp_emb = self.timestamp_encoder(timestamps.unsqueeze(-1).float())\n",
        "        position_emb = self.position_encoder(positions)\n",
        "        return timestamp_emb + position_emb\n",
        "\n",
        "# Base Model Class\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Order Model with Positional Encoder\n",
        "class OrderModel(BaseModel):\n",
        "    def __init__(self, N_sec_ids, N_distance_bins, embedding_dim=32, hidden_dim=64):\n",
        "        super(OrderModel, self).__init__()\n",
        "\n",
        "        # Mask indices\n",
        "        self.security_id_mask = N_sec_ids\n",
        "        self.buy_sell_mask = 2\n",
        "        self.add_modify_delete_mask = 3\n",
        "        self.distance_mask = N_distance_bins\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.security_id_embedding = nn.Embedding(N_sec_ids + 1, embedding_dim, padding_idx=self.security_id_mask)\n",
        "        self.buy_sell_embedding = nn.Embedding(3, embedding_dim, padding_idx=self.buy_sell_mask)  # 0,1,2(mask)\n",
        "        self.add_modify_delete_embedding = nn.Embedding(4, embedding_dim, padding_idx=self.add_modify_delete_mask)  # 0,1,2,3(mask)\n",
        "        self.distance_embedding = nn.Embedding(N_distance_bins + 1, embedding_dim, padding_idx=self.distance_mask)\n",
        "\n",
        "        # Linear layers for continuous features\n",
        "        self.quantity_linear = nn.Linear(1, embedding_dim)\n",
        "        self.price_linear = nn.Linear(1, embedding_dim)\n",
        "\n",
        "        # Positional Encoder\n",
        "        self.positional_encoder = PositionalEncoder(embedding_dim)\n",
        "\n",
        "        # LSTM for sequences\n",
        "        self.lstm_input_dim = embedding_dim * 7  # Number of features\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # Final fully connected layers\n",
        "        self.fc1 = nn.Linear(embedding_dim * 7 + hidden_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output heads\n",
        "        self.security_id_head = nn.Linear(128, N_sec_ids)\n",
        "        self.buy_sell_head = nn.Linear(128, 2)\n",
        "        self.add_modify_delete_head = nn.Linear(128, 3)\n",
        "        self.distance_head = nn.Linear(128, N_distance_bins)\n",
        "        self.quantity_head = nn.Linear(128, 1)\n",
        "        self.price_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x is a dictionary of features for the masked sample\n",
        "        # seq_data is a dictionary of sequences\n",
        "        # seq_lengths is a list of sequence lengths\n",
        "\n",
        "        batch_size = x['timestamp'].shape[0]\n",
        "\n",
        "        # Process the masked sample\n",
        "        timestamp = x['timestamp']\n",
        "        position = x['position']\n",
        "        security_id = x['security_id']\n",
        "        buy_sell = x['buy_sell']\n",
        "        add_modify_delete = x['add_modify_delete']\n",
        "        quantity = x['quantity'].unsqueeze(1)\n",
        "        price = x['price'].unsqueeze(1)\n",
        "        distance = x['distance']\n",
        "\n",
        "        # Embeddings\n",
        "        positional_emb = self.positional_encoder(timestamp, position)\n",
        "        security_id_emb = self.security_id_embedding(security_id)\n",
        "        buy_sell_emb = self.buy_sell_embedding(buy_sell)\n",
        "        add_modify_delete_emb = self.add_modify_delete_embedding(add_modify_delete)\n",
        "        quantity_emb = self.quantity_linear(quantity)\n",
        "        price_emb = self.price_linear(price)\n",
        "        distance_emb = self.distance_embedding(distance)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        sample_emb = torch.cat([positional_emb,\n",
        "                                security_id_emb,\n",
        "                                buy_sell_emb,\n",
        "                                add_modify_delete_emb,\n",
        "                                quantity_emb,\n",
        "                                price_emb,\n",
        "                                distance_emb], dim=1)  # Shape: (batch_size, embedding_dim * 7)\n",
        "\n",
        "        # Process the sequence data\n",
        "        # For each feature in seq_data, get embeddings\n",
        "\n",
        "        seq_timestamp = seq_data['timestamp']\n",
        "        seq_position = seq_data['position']\n",
        "        seq_security_id = seq_data['security_id']\n",
        "        seq_buy_sell = seq_data['buy_sell']\n",
        "        seq_add_modify_delete = seq_data['add_modify_delete']\n",
        "        seq_quantity = seq_data['quantity']\n",
        "        seq_price = seq_data['price']\n",
        "        seq_distance = seq_data['distance']\n",
        "\n",
        "        # Embeddings for sequence data\n",
        "        seq_positional_emb = self.positional_encoder(seq_timestamp, seq_position)\n",
        "        seq_security_id_emb = self.security_id_embedding(seq_security_id)\n",
        "        seq_buy_sell_emb = self.buy_sell_embedding(seq_buy_sell)\n",
        "        seq_add_modify_delete_emb = self.add_modify_delete_embedding(seq_add_modify_delete)\n",
        "        seq_quantity_emb = self.quantity_linear(seq_quantity.unsqueeze(-1))\n",
        "        seq_price_emb = self.price_linear(seq_price.unsqueeze(-1))\n",
        "        seq_distance_emb = self.distance_embedding(seq_distance)\n",
        "\n",
        "        # Concatenate sequence embeddings\n",
        "        seq_emb = torch.cat([seq_positional_emb,\n",
        "                             seq_security_id_emb,\n",
        "                             seq_buy_sell_emb,\n",
        "                             seq_add_modify_delete_emb,\n",
        "                             seq_quantity_emb,\n",
        "                             seq_price_emb,\n",
        "                             seq_distance_emb], dim=2)  # Shape: (batch_size, seq_len, embedding_dim * 7)\n",
        "\n",
        "        # Pack the sequences\n",
        "        packed_seq_emb = pack_padded_sequence(seq_emb, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb)\n",
        "\n",
        "        # Get the last hidden state for each sequence\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Combine the sample embedding with the sequence context\n",
        "        combined = torch.cat([sample_emb, seq_context], dim=1)  # Shape: (batch_size, embedding_dim * 7 + hidden_dim)\n",
        "\n",
        "        # Forward pass\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Outputs\n",
        "        outputs = {\n",
        "            'security_id': self.security_id_head(x),\n",
        "            'buy_sell': self.buy_sell_head(x),\n",
        "            'add_modify_delete': self.add_modify_delete_head(x),\n",
        "            'distance': self.distance_head(x),\n",
        "            'quantity': self.quantity_head(x),\n",
        "            'price': self.price_head(x)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Additional Models\n",
        "\n",
        "class MatrixRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Matrix Regression Model: Y = A * X * B\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Fast training.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing complex patterns.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys, num_classes_dict):\n",
        "        super(MatrixRegressionModel, self).__init__()\n",
        "        self.A = nn.Parameter(torch.randn(input_size, input_size))\n",
        "        self.output_heads = nn.ModuleDict()\n",
        "        self.output_keys = output_keys\n",
        "        for key in self.output_keys:\n",
        "            if key in num_classes_dict:\n",
        "                num_classes = num_classes_dict[key]\n",
        "                self.output_heads[key] = nn.Linear(input_size, num_classes)\n",
        "            else:\n",
        "                self.output_heads[key] = nn.Linear(input_size, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: batch_data concatenated into a single vector\n",
        "        x_vector = torch.cat([x[key].unsqueeze(-1).float() for key in x], dim=1)\n",
        "        x_vector = x_vector.view(x_vector.size(0), -1)\n",
        "        x_transformed = x_vector @ self.A\n",
        "\n",
        "        outputs = {}\n",
        "        for key in self.output_keys:\n",
        "            outputs[key] = self.output_heads[key](x_transformed)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class LogisticRegressionModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Logistic Regression Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Simple and interpretable.\n",
        "    - Good baseline model.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Assumes linear relationship.\n",
        "    - May underfit complex data.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys, num_classes_dict):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.output_heads = nn.ModuleDict()\n",
        "        self.output_keys = output_keys\n",
        "        for key in self.output_keys:\n",
        "            if key in num_classes_dict:\n",
        "                num_classes = num_classes_dict[key]\n",
        "                self.output_heads[key] = nn.Linear(input_size, num_classes)\n",
        "            else:\n",
        "                self.output_heads[key] = nn.Linear(input_size, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # x: batch_data concatenated into a single vector\n",
        "        x_vector = torch.cat([x[key].unsqueeze(-1).float() for key in x], dim=1)\n",
        "        x_vector = x_vector.view(x_vector.size(0), -1)\n",
        "        outputs = {}\n",
        "        for key in self.output_keys:\n",
        "            outputs[key] = self.output_heads[key](x_vector)\n",
        "        return outputs\n",
        "\n",
        "class CNNModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures local temporal patterns.\n",
        "    - Efficient computation.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Limited in capturing long-term dependencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_keys, num_classes_dict):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.output_heads = nn.ModuleDict()\n",
        "        self.output_keys = output_keys\n",
        "        for key in output_keys:\n",
        "            if key in num_classes_dict:\n",
        "                num_classes = num_classes_dict[key]\n",
        "                self.output_heads[key] = nn.Linear(128, num_classes)\n",
        "            else:\n",
        "                self.output_heads[key] = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        seq_vector = seq_vector.permute(0, 2, 1)  # (batch_size, num_features, seq_len)\n",
        "        x = self.relu(self.conv1(seq_vector))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = torch.mean(x, dim=2)  # Global average pooling\n",
        "\n",
        "        outputs = {}\n",
        "        for key in self.output_keys:\n",
        "            outputs[key] = self.output_heads[key](x)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class LSTMModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures long-term dependencies.\n",
        "    - Suitable for sequential data.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Computationally intensive.\n",
        "    - Prone to overfitting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_keys, num_classes_dict):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.output_heads = nn.ModuleDict()\n",
        "        self.output_keys = output_keys\n",
        "        for key in self.output_keys:\n",
        "            if key in num_classes_dict:\n",
        "                num_classes = num_classes_dict[key]\n",
        "                self.output_heads[key] = nn.Linear(hidden_size, num_classes)\n",
        "            else:\n",
        "                self.output_heads[key] = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        packed_seq_emb = pack_padded_sequence(seq_vector, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        h0 = torch.zeros(self.lstm.num_layers, seq_vector.size(0), self.lstm.hidden_size).to(seq_vector.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, seq_vector.size(0), self.lstm.hidden_size).to(seq_vector.device)\n",
        "\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb, (h0, c0))\n",
        "\n",
        "        # Get the last hidden state\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        outputs = {}\n",
        "        for key in self.output_keys:\n",
        "            outputs[key] = self.output_heads[key](seq_context)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class TransformerModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Transformer Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Captures global dependencies.\n",
        "    - Parallelizable.\n",
        "\n",
        "    Disadvantages:\n",
        "    - Requires large datasets.\n",
        "    - Computationally intensive.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_heads, num_layers, output_keys, num_classes_dict):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.positional_encoder = PositionalEncoder(input_size)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=num_heads)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.output_heads = nn.ModuleDict()\n",
        "        self.output_keys = output_keys\n",
        "        for key in self.output_keys:\n",
        "            if key in num_classes_dict:\n",
        "                num_classes = num_classes_dict[key]\n",
        "                self.output_heads[key] = nn.Linear(input_size, num_classes)\n",
        "            else:\n",
        "                self.output_heads[key] = nn.Linear(input_size, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        # Add positional encoding\n",
        "        positions = torch.arange(0, seq_vector.size(1), device=seq_vector.device).unsqueeze(0).repeat(seq_vector.size(0), 1)\n",
        "        seq_vector = seq_vector + self.positional_encoder(positions, positions)\n",
        "\n",
        "        # Transformer expects input shape (seq_len, batch_size, feature_dim)\n",
        "        seq_vector = seq_vector.permute(1, 0, 2)\n",
        "        transformer_output = self.transformer_encoder(seq_vector)\n",
        "        # Take the output corresponding to the last position\n",
        "        x = transformer_output[-1, :, :]\n",
        "        outputs = {}\n",
        "        for key in self.output_keys:\n",
        "            outputs[key] = self.output_heads[key](x)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class MambaModel(BaseModel):\n",
        "    \"\"\"\n",
        "    Mamba Model.\n",
        "\n",
        "    Advantages:\n",
        "    - Custom model that combines CNN and LSTM architectures.\n",
        "    - Captures both local and long-term dependencies.\n",
        "\n",
        "    Disadvantages:\n",
        "    - More complex and may require careful tuning.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_keys, num_classes_dict):\n",
        "        super(MambaModel, self).__init__()\n",
        "        # CNN part\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # LSTM part\n",
        "        self.lstm = nn.LSTM(input_size=128, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        # Output heads\n",
        "        self.output_heads = nn.ModuleDict()\n",
        "        self.output_keys = output_keys\n",
        "        for key in self.output_keys:\n",
        "            if key in num_classes_dict:\n",
        "                num_classes = num_classes_dict[key]\n",
        "                self.output_heads[key] = nn.Linear(hidden_size, num_classes)\n",
        "            else:\n",
        "                self.output_heads[key] = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x, seq_data, seq_lengths):\n",
        "        # seq_data: concatenated features\n",
        "        seq_vector = torch.cat([seq_data[key].unsqueeze(-1).float() for key in seq_data], dim=2)\n",
        "        seq_vector = seq_vector.permute(0, 2, 1)  # (batch_size, num_features, seq_len)\n",
        "\n",
        "        # CNN part\n",
        "        x = self.relu(self.conv1(seq_vector))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = x.permute(0, 2, 1)  # (batch_size, seq_len, channels)\n",
        "\n",
        "        # LSTM part\n",
        "        packed_seq_emb = pack_padded_sequence(x, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        h0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_seq_emb, (h0, c0))\n",
        "        seq_context = h_n[-1]  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        outputs = {}\n",
        "        for key in self.output_keys:\n",
        "            outputs[key] = self.output_heads[key](seq_context)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Collate function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    # batch is a list of (masked_sample, target, sequence)\n",
        "    batch_size = len(batch)\n",
        "    masked_samples = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    sequences = [item[2] for item in batch]\n",
        "\n",
        "    # Convert masked_samples to tensors\n",
        "    batch_data = {}\n",
        "    batch_target = {}\n",
        "    seq_data = {}\n",
        "    seq_lengths = []\n",
        "\n",
        "    # Process data\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_data[key] = torch.tensor([sample[key] for sample in masked_samples])\n",
        "\n",
        "    # Process sequences\n",
        "    # Sequences are variable-length\n",
        "    # For each key, we have a list of sequences\n",
        "    for key in ['timestamp', 'position', 'security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        seq_list = [torch.tensor(seq[key]) for seq in sequences]\n",
        "        seq_padded = nn.utils.rnn.pad_sequence(seq_list, batch_first=True, padding_value=0)\n",
        "        seq_data[key] = seq_padded\n",
        "    # Record lengths\n",
        "    seq_lengths = [len(seq['timestamp']) for seq in sequences]\n",
        "\n",
        "    # Convert seq_lengths to tensor\n",
        "    seq_lengths = torch.tensor(seq_lengths, dtype=torch.long)\n",
        "\n",
        "    # Process target (exclude 'timestamp' and 'position' as they're not in target)\n",
        "    for key in ['security_id', 'buy_sell', 'add_modify_delete', 'quantity', 'price', 'distance']:\n",
        "        batch_target[key] = []\n",
        "        for target in targets:\n",
        "            if target[key] is not None:\n",
        "                batch_target[key].append(target[key])\n",
        "            else:\n",
        "                batch_target[key].append(-100 if key not in ['quantity', 'price'] else 0.0)\n",
        "\n",
        "        # Convert to tensor and create mask\n",
        "        if key in ['quantity', 'price']:\n",
        "            # For continuous features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != 0.0 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.float)\n",
        "        else:\n",
        "            # For categorical features\n",
        "            batch_target[key + '_mask'] = torch.tensor([t != -100 for t in batch_target[key]], dtype=torch.bool)\n",
        "            batch_target[key] = torch.tensor(batch_target[key], dtype=torch.long)\n",
        "\n",
        "    return batch_data, batch_target, seq_data, seq_lengths\n",
        "\n",
        "# Training and Testing Loop\n",
        "def train_model(model_class, model_params, dataset_params, training_params):\n",
        "    # Create Dataset and DataLoader\n",
        "    dataset = MaskedOrderDataset(**dataset_params)\n",
        "    dataloader = DataLoader(dataset, batch_size=training_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    # Create model\n",
        "    model = model_class(**model_params).to(training_params['device'])\n",
        "    optimizer = optim.Adam(model.parameters(), lr=training_params['learning_rate'])\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(training_params['num_epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_data, batch_target, seq_data, seq_lengths in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move data to device\n",
        "            device = training_params.get('device', 'cpu')\n",
        "            batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
        "            batch_target = {k: v.to(device) for k, v in batch_target.items()}\n",
        "            seq_data = {k: v.to(device) for k, v in seq_data.items()}\n",
        "            seq_lengths = seq_lengths.to(device)\n",
        "\n",
        "            outputs = model(batch_data, seq_data, seq_lengths)\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            # Compute loss for each feature\n",
        "            for key in ['security_id', 'buy_sell', 'add_modify_delete', 'distance']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        output = outputs[key]\n",
        "                        loss_feature = criterion_ce(output, target)\n",
        "                        loss += loss_feature\n",
        "\n",
        "            for key in ['quantity', 'price']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        output = outputs[key].squeeze()\n",
        "                        loss_feature = criterion_l1(output[mask], target[mask])\n",
        "                        loss += loss_feature\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Beam Search Generation Function\n",
        "def generate_sequences(model, past_data, security_id, num_timesteps, beam_width, num_samples, device='cpu'):\n",
        "    \"\"\"\n",
        "    Generate sequences using beam search.\n",
        "\n",
        "    Args:\n",
        "        model: Trained model.\n",
        "        past_data: Dictionary containing past sequences.\n",
        "        security_id: The security ID to generate sequences for.\n",
        "        num_timesteps: Number of timesteps to generate.\n",
        "        beam_width: Beam width.\n",
        "        num_samples: Number of samples to generate.\n",
        "        device: Device to run the computations on.\n",
        "\n",
        "    Returns:\n",
        "        generated_sequences: A list of generated sequences.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Initialize the beam with the past_data\n",
        "        # Each beam entry is a tuple (sequence, cumulative_log_prob)\n",
        "        beam = [({'timestamp': past_data['timestamp'],\n",
        "                  'position': past_data['position'],\n",
        "                  'security_id': past_data['security_id'],\n",
        "                  'buy_sell': past_data['buy_sell'],\n",
        "                  'add_modify_delete': past_data['add_modify_delete'],\n",
        "                  'quantity': past_data['quantity'],\n",
        "                  'price': past_data['price'],\n",
        "                  'distance': past_data['distance']},\n",
        "                 0.0)]  # Start with log probability 0\n",
        "\n",
        "        for t in range(num_timesteps):\n",
        "            new_beam = []\n",
        "            for seq, cum_log_prob in beam:\n",
        "                # Prepare input data\n",
        "                # Use the last max_seq_len elements\n",
        "                seq_len = len(seq['timestamp'])\n",
        "                start_idx = max(0, seq_len - model.lstm_input_dim) if hasattr(model, 'lstm_input_dim') else 0\n",
        "                seq_data = {key: torch.tensor(seq[key][start_idx:]).unsqueeze(0).to(device) for key in seq}\n",
        "                seq_lengths = torch.tensor([seq_data['timestamp'].shape[1]]).to(device)\n",
        "\n",
        "                # Create a sample with masked features (except security_id and timestamp)\n",
        "                sample = {\n",
        "                    'timestamp': torch.tensor([seq['timestamp'][-1] + 1]).to(device),\n",
        "                    'position': torch.tensor([seq['position'][-1] + 1]).to(device),\n",
        "                    'security_id': torch.tensor([security_id]).to(device),\n",
        "                    'buy_sell': torch.tensor([model.buy_sell_mask if hasattr(model, 'buy_sell_mask') else 2]).to(device),\n",
        "                    'add_modify_delete': torch.tensor([model.add_modify_delete_mask if hasattr(model, 'add_modify_delete_mask') else 3]).to(device),\n",
        "                    'quantity': torch.tensor([0.0]).to(device),\n",
        "                    'price': torch.tensor([0.0]).to(device),\n",
        "                    'distance': torch.tensor([model.distance_mask if hasattr(model, 'distance_mask') else 10]).to(device)\n",
        "                }\n",
        "\n",
        "                # Predict missing features\n",
        "                outputs = model(sample, seq_data, seq_lengths)\n",
        "\n",
        "                # For each categorical feature, get top N predictions\n",
        "                candidates = []\n",
        "\n",
        "                # Adjust topk for buy_sell\n",
        "                if 'buy_sell' in outputs:\n",
        "                    buy_sell_probs = F.softmax(outputs['buy_sell'], dim=-1)\n",
        "                    num_buy_sell_classes = buy_sell_probs.size(-1)\n",
        "                    buy_sell_topk_k = min(beam_width, num_buy_sell_classes)\n",
        "                    buy_sell_topk = torch.topk(buy_sell_probs, buy_sell_topk_k)\n",
        "                else:\n",
        "                    buy_sell_topk_k = 1\n",
        "                    buy_sell_topk = None\n",
        "\n",
        "                # Adjust topk for add_modify_delete\n",
        "                if 'add_modify_delete' in outputs:\n",
        "                    add_modify_delete_probs = F.softmax(outputs['add_modify_delete'], dim=-1)\n",
        "                    num_amd_classes = add_modify_delete_probs.size(-1)\n",
        "                    amd_topk_k = min(beam_width, num_amd_classes)\n",
        "                    amd_topk = torch.topk(add_modify_delete_probs, amd_topk_k)\n",
        "                else:\n",
        "                    amd_topk_k = 1\n",
        "                    amd_topk = None\n",
        "\n",
        "                # Adjust topk for distance\n",
        "                if 'distance' in outputs:\n",
        "                    distance_probs = F.softmax(outputs['distance'], dim=-1)\n",
        "                    num_distance_classes = distance_probs.size(-1)\n",
        "                    distance_topk_k = min(beam_width, num_distance_classes)\n",
        "                    distance_topk = torch.topk(distance_probs, distance_topk_k)\n",
        "                else:\n",
        "                    distance_topk_k = 1\n",
        "                    distance_topk = None\n",
        "\n",
        "                # For continuous features, we can use the predicted value directly\n",
        "                quantity_pred = outputs['quantity'].item() if 'quantity' in outputs else 0.0\n",
        "                price_pred = outputs['price'].item() if 'price' in outputs else 0.0\n",
        "\n",
        "                # Generate combinations of top predictions\n",
        "                for i in range(buy_sell_topk_k):\n",
        "                    for j in range(amd_topk_k):\n",
        "                        for k in range(distance_topk_k):\n",
        "                            new_seq = {key: seq[key] + [sample[key].item()] for key in seq}\n",
        "                            if buy_sell_topk is not None:\n",
        "                                new_seq['buy_sell'][-1] = buy_sell_topk.indices[0][i].item()\n",
        "                            else:\n",
        "                                new_seq['buy_sell'][-1] = seq['buy_sell'][-1]  # Use previous value\n",
        "\n",
        "                            if amd_topk is not None:\n",
        "                                new_seq['add_modify_delete'][-1] = amd_topk.indices[0][j].item()\n",
        "                            else:\n",
        "                                new_seq['add_modify_delete'][-1] = seq['add_modify_delete'][-1]  # Use previous value\n",
        "\n",
        "                            if distance_topk is not None:\n",
        "                                new_seq['distance'][-1] = distance_topk.indices[0][k].item()\n",
        "                            else:\n",
        "                                new_seq['distance'][-1] = seq['distance'][-1]  # Use previous value\n",
        "\n",
        "                            new_seq['quantity'][-1] = quantity_pred\n",
        "                            new_seq['price'][-1] = price_pred\n",
        "\n",
        "                            # Compute new cumulative log probability\n",
        "                            log_prob = cum_log_prob\n",
        "                            if buy_sell_topk is not None:\n",
        "                                log_prob += torch.log(buy_sell_topk.values[0][i] + 1e-9).item()\n",
        "                            if amd_topk is not None:\n",
        "                                log_prob += torch.log(amd_topk.values[0][j] + 1e-9).item()\n",
        "                            if distance_topk is not None:\n",
        "                                log_prob += torch.log(distance_topk.values[0][k] + 1e-9).item()\n",
        "\n",
        "                            candidates.append((new_seq, log_prob))\n",
        "\n",
        "                # Keep top beam_width candidates\n",
        "                candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "                new_beam.extend(candidates[:beam_width])\n",
        "\n",
        "            # Keep top beam_width sequences\n",
        "            new_beam.sort(key=lambda x: x[1], reverse=True)\n",
        "            beam = new_beam[:beam_width]\n",
        "\n",
        "        # After generation, sample from the beam to get the required number of samples\n",
        "        generated_sequences = [seq for seq, _ in beam[:num_samples]]\n",
        "        return generated_sequences\n",
        "\n",
        "# Hyperparameter Optimization\n",
        "def hyperparameter_optimization(model_class, model_params_grid, dataset_params, training_params, output_keys, num_classes_dict):\n",
        "    from sklearn.model_selection import ParameterGrid\n",
        "    import copy\n",
        "\n",
        "    # Create Dataset and DataLoader\n",
        "    dataset = MaskedOrderDataset(**dataset_params)\n",
        "    dataloader = DataLoader(dataset, batch_size=training_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    best_model = None\n",
        "    best_loss = float('inf')\n",
        "    best_params = None\n",
        "\n",
        "    param_grid = list(ParameterGrid(model_params_grid))\n",
        "\n",
        "    for params in param_grid:\n",
        "        print(f\"Testing parameters: {params}\")\n",
        "        model_params = params.copy()\n",
        "        model_params['output_keys'] = output_keys\n",
        "        model_params['num_classes_dict'] = num_classes_dict\n",
        "\n",
        "        model = model_class(**model_params).to(training_params['device'])\n",
        "        optimizer = optim.Adam(model.parameters(), lr=training_params['learning_rate'])\n",
        "\n",
        "        # Loss functions\n",
        "        criterion_ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "        criterion_l1 = nn.L1Loss()\n",
        "\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_data, batch_target, seq_data, seq_lengths in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move data to device\n",
        "            device = training_params.get('device', 'cpu')\n",
        "            batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
        "            batch_target = {k: v.to(device) for k, v in batch_target.items()}\n",
        "            seq_data = {k: v.to(device) for k, v in seq_data.items()}\n",
        "            seq_lengths = seq_lengths.to(device)\n",
        "\n",
        "            outputs = model(batch_data, seq_data, seq_lengths)\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            # Compute loss for each feature\n",
        "            for key in ['security_id', 'buy_sell', 'add_modify_delete', 'distance']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        output = outputs[key]\n",
        "                        loss_feature = criterion_ce(output, target)\n",
        "                        loss += loss_feature\n",
        "\n",
        "            for key in ['quantity', 'price']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        output = outputs[key].squeeze()\n",
        "                        loss_feature = criterion_l1(output[mask], target[mask])\n",
        "                        loss += loss_feature\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"Average Loss: {avg_loss}\")\n",
        "\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_model = copy.deepcopy(model)\n",
        "            best_params = params\n",
        "\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "    print(f\"Best Loss: {best_loss}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Training parameters\n",
        "    training_params = {\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 0.001,\n",
        "        'num_epochs': 2,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    }\n",
        "\n",
        "    # Dataset parameters\n",
        "    dataset_params = {\n",
        "        'num_samples': 5000,\n",
        "        'mask_prob': 0.15,\n",
        "        'max_seq_len': 50\n",
        "    }\n",
        "\n",
        "    # Common parameters\n",
        "    output_keys = ['security_id', 'buy_sell', 'add_modify_delete', 'distance', 'quantity', 'price']\n",
        "    num_classes_dict = {\n",
        "        'security_id': 100,\n",
        "        'buy_sell': 2,\n",
        "        'add_modify_delete': 3,\n",
        "        'distance': 10\n",
        "    }\n",
        "\n",
        "    # Example 1: Training TransformerModel\n",
        "    print(\"Training TransformerModel...\")\n",
        "    model_params_transformer = {\n",
        "        'input_size': 8,  # Number of features in seq_data\n",
        "        'num_heads': 4,\n",
        "        'num_layers': 2,\n",
        "        'output_keys': output_keys,\n",
        "        'num_classes_dict': num_classes_dict\n",
        "    }\n",
        "    model_transformer = train_model(TransformerModel, model_params_transformer, dataset_params, training_params)\n",
        "\n",
        "    # Example 2: Training MambaModel\n",
        "    print(\"\\nTraining MambaModel...\")\n",
        "    model_params_mamba = {\n",
        "        'input_size': 8,  # Number of features in seq_data\n",
        "        'hidden_size': 64,\n",
        "        'num_layers': 2,\n",
        "        'output_keys': output_keys,\n",
        "        'num_classes_dict': num_classes_dict\n",
        "    }\n",
        "    model_mamba = train_model(MambaModel, model_params_mamba, dataset_params, training_params)\n",
        "\n",
        "    # Generate sequences using beam search with TransformerModel\n",
        "    print(\"\\nGenerating sequences using beam search with TransformerModel...\")\n",
        "    # Prepare past_data\n",
        "    past_data = {\n",
        "        'timestamp': [1000, 1001, 1002],\n",
        "        'position': [0, 1, 2],\n",
        "        'security_id': [5, 5, 5],\n",
        "        'buy_sell': [0, 1, 0],\n",
        "        'add_modify_delete': [0, 1, 2],\n",
        "        'quantity': [500.0, 600.0, 700.0],\n",
        "        'price': [50.0, 51.0, 52.0],\n",
        "        'distance': [3, 2, 1]\n",
        "    }\n",
        "\n",
        "    # Parameters for generation\n",
        "    security_id = 5\n",
        "    num_timesteps = 5\n",
        "    beam_width = 3\n",
        "    num_samples = 3\n",
        "\n",
        "    generated_sequences = generate_sequences(\n",
        "        model=model_transformer,\n",
        "        past_data=past_data,\n",
        "        security_id=security_id,\n",
        "        num_timesteps=num_timesteps,\n",
        "        beam_width=beam_width,\n",
        "        num_samples=num_samples,\n",
        "        device=training_params['device']\n",
        "    )\n",
        "\n",
        "    # Compute distribution of buys vs sells\n",
        "    total_buy = 0\n",
        "    total_sell = 0\n",
        "    total_actions = 0\n",
        "\n",
        "    for seq in generated_sequences:\n",
        "        buy_sell_seq = seq['buy_sell'][-num_timesteps:]  # Only consider generated timesteps\n",
        "        total_buy += buy_sell_seq.count(0)\n",
        "        total_sell += buy_sell_seq.count(1)\n",
        "        total_actions += len(buy_sell_seq)\n",
        "\n",
        "    buy_percentage = (total_buy / total_actions) * 100 if total_actions > 0 else 0\n",
        "    sell_percentage = (total_sell / total_actions) * 100 if total_actions > 0 else 0\n",
        "\n",
        "    print(f\"\\nGenerated {num_samples} sequences of {num_timesteps} timesteps each.\")\n",
        "    print(f\"Buy actions: {buy_percentage:.2f}%\")\n",
        "    print(f\"Sell actions: {sell_percentage:.2f}%\")\n",
        "\n",
        "    # Hyperparameter Optimization Example with MambaModel\n",
        "    print(\"\\nStarting Hyperparameter Optimization for MambaModel...\")\n",
        "    model_params_grid = {\n",
        "        'hidden_size': [32, 64],\n",
        "        'num_layers': [1, 2],\n",
        "    }\n",
        "    best_mamba_model = hyperparameter_optimization(\n",
        "        model_class=MambaModel,\n",
        "        model_params_grid=model_params_grid,\n",
        "        dataset_params=dataset_params,\n",
        "        training_params=training_params,\n",
        "        output_keys=output_keys,\n",
        "        num_classes_dict=num_classes_dict\n",
        "    )\n",
        "\n",
        "    print(\"\\nHyperparameter optimization completed.\")"
      ],
      "metadata": {
        "id": "HAPJPuRTimNL",
        "outputId": "fd185d9a-f53e-4ff6-870b-8dcc7eea20c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training TransformerModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "<ipython-input-12-79da02321f52>:526: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 559.9849175131245\n",
            "Epoch 2, Loss: 550.8923345675134\n",
            "\n",
            "Training MambaModel...\n",
            "Epoch 1, Loss: 540.1169313078474\n",
            "Epoch 2, Loss: 519.5057787075165\n",
            "\n",
            "Generating sequences using beam search with TransformerModel...\n",
            "\n",
            "Generated 3 sequences of 5 timesteps each.\n",
            "Buy actions: 0.00%\n",
            "Sell actions: 100.00%\n",
            "\n",
            "Starting Hyperparameter Optimization for MambaModel...\n",
            "Testing parameters: {'hidden_size': 32, 'num_layers': 1}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "MambaModel.__init__() missing 1 required positional argument: 'input_size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-79da02321f52>\u001b[0m in \u001b[0;36m<cell line: 838>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;34m'num_layers'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     }\n\u001b[0;32m--> 939\u001b[0;31m     best_mamba_model = hyperparameter_optimization(\n\u001b[0m\u001b[1;32m    940\u001b[0m         \u001b[0mmodel_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMambaModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0mmodel_params_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_params_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-79da02321f52>\u001b[0m in \u001b[0;36mhyperparameter_optimization\u001b[0;34m(model_class, model_params_grid, dataset_params, training_params, output_keys, num_classes_dict)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_classes_dict'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: MambaModel.__init__() missing 1 required positional argument: 'input_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperparameter_optimization(model_class, model_params_grid, dataset_params, training_params, output_keys, num_classes_dict):\n",
        "    from sklearn.model_selection import ParameterGrid\n",
        "    import copy\n",
        "\n",
        "    # Create Dataset and DataLoader\n",
        "    dataset = MaskedOrderDataset(**dataset_params)\n",
        "    dataloader = DataLoader(dataset, batch_size=training_params['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    best_model = None\n",
        "    best_loss = float('inf')\n",
        "    best_params = None\n",
        "\n",
        "    param_grid = list(ParameterGrid(model_params_grid))\n",
        "\n",
        "    for params in param_grid:\n",
        "        print(f\"Testing parameters: {params}\")\n",
        "        model_params = params.copy()\n",
        "        model_params['input_size'] = 8  # Number of features in seq_data\n",
        "        model_params['output_keys'] = output_keys\n",
        "        model_params['num_classes_dict'] = num_classes_dict\n",
        "\n",
        "        model = model_class(**model_params).to(training_params['device'])\n",
        "        optimizer = optim.Adam(model.parameters(), lr=training_params['learning_rate'])\n",
        "\n",
        "        # Loss functions\n",
        "        criterion_ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "        criterion_l1 = nn.L1Loss()\n",
        "\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch_data, batch_target, seq_data, seq_lengths in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move data to device\n",
        "            device = training_params.get('device', 'cpu')\n",
        "            batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
        "            batch_target = {k: v.to(device) for k, v in batch_target.items()}\n",
        "            seq_data = {k: v.to(device) for k, v in seq_data.items()}\n",
        "            seq_lengths = seq_lengths.to(device)\n",
        "\n",
        "            outputs = model(batch_data, seq_data, seq_lengths)\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            # Compute loss for each feature\n",
        "            for key in ['security_id', 'buy_sell', 'add_modify_delete', 'distance']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        output = outputs[key]\n",
        "                        loss_feature = criterion_ce(output, target)\n",
        "                        loss += loss_feature\n",
        "\n",
        "            for key in ['quantity', 'price']:\n",
        "                if key in outputs:\n",
        "                    target = batch_target[key]\n",
        "                    mask = batch_target[key + '_mask']\n",
        "                    if mask.any():\n",
        "                        output = outputs[key].squeeze()\n",
        "                        loss_feature = criterion_l1(output[mask], target[mask])\n",
        "                        loss += loss_feature\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"Average Loss: {avg_loss}\")\n",
        "\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_model = copy.deepcopy(model)\n",
        "            best_params = params\n",
        "\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "    print(f\"Best Loss: {best_loss}\")\n",
        "\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "j7251-QOj660"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "training_params = {\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.001,\n",
        "    'num_epochs': 2,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "}\n",
        "\n",
        "# Dataset parameters\n",
        "dataset_params = {\n",
        "    'num_samples': 5000,\n",
        "    'mask_prob': 0.15,\n",
        "    'max_seq_len': 50\n",
        "}\n",
        "\n",
        "# Common parameters\n",
        "output_keys = ['security_id', 'buy_sell', 'add_modify_delete', 'distance', 'quantity', 'price']\n",
        "num_classes_dict = {\n",
        "    'security_id': 100,\n",
        "    'buy_sell': 2,\n",
        "    'add_modify_delete': 3,\n",
        "    'distance': 10\n",
        "}"
      ],
      "metadata": {
        "id": "2YZ8yDk5ol2b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining LogisticRegressionModel...\")\n",
        "model_params_lr = {\n",
        "    'input_size': 8,  # Number of features in batch_data\n",
        "    'output_keys': output_keys,\n",
        "    'num_classes_dict': num_classes_dict\n",
        "}\n",
        "model_lr = train_model(LogisticRegressionModel, model_params_lr, dataset_params, training_params)"
      ],
      "metadata": {
        "id": "AfzAxN3TopMS",
        "outputId": "e3f152d8-9d29-4eae-e091-fb83b2fd0de9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LogisticRegressionModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-79da02321f52>:526: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1038.635112981128\n",
            "Epoch 2, Loss: 618.0137916127587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining MatrixRegressionModel...\")\n",
        "model_params_mr = {\n",
        "    'input_size': 8,  # Number of features in batch_data\n",
        "    'output_keys': output_keys,\n",
        "    'num_classes_dict': num_classes_dict\n",
        "}\n",
        "model_mr = train_model(MatrixRegressionModel, model_params_mr, dataset_params, training_params)"
      ],
      "metadata": {
        "id": "ya_fy0bqouJK",
        "outputId": "82466c5e-18da-4ce1-9b36-cfad32cf257a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training MatrixRegressionModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-79da02321f52>:526: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1354.9664022846587\n",
            "Epoch 2, Loss: 639.6293430206882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nHyperparameter Optimization for MatrixRegressionModel...\")\n",
        "model_params_grid_mr = {\n",
        "    'input_size': [8],  # Usually fixed\n",
        "}\n",
        "best_mr_model = hyperparameter_optimization(\n",
        "    model_class=MatrixRegressionModel,\n",
        "    model_params_grid=model_params_grid_mr,\n",
        "    dataset_params=dataset_params,\n",
        "    training_params=training_params,\n",
        "    output_keys=output_keys,\n",
        "    num_classes_dict=num_classes_dict\n",
        ")"
      ],
      "metadata": {
        "id": "tCGDZd0Ho1As",
        "outputId": "b7f82bc6-e022-4c26-9253-9894dcd1e93d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hyperparameter Optimization for MatrixRegressionModel...\n",
            "Testing parameters: {'input_size': 8}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-79da02321f52>:526: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss: 1549.875912806031\n",
            "Best Parameters: {'input_size': 8}\n",
            "Best Loss: 1549.875912806031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining CNNModel...\")\n",
        "model_params_cnn = {\n",
        "    'input_size': 8,  # Number of features in seq_data\n",
        "    'output_keys': output_keys,\n",
        "    'num_classes_dict': num_classes_dict\n",
        "}\n",
        "model_cnn = train_model(CNNModel, model_params_cnn, dataset_params, training_params)"
      ],
      "metadata": {
        "id": "AXKKupoXo6l_",
        "outputId": "1688cef9-2751-4af3-b90e-f318b81a0bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training CNNModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-79da02321f52>:526: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 326.69811331390576\n",
            "Epoch 2, Loss: 298.0500039264655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nHyperparameter Optimization for CNNModel...\")\n",
        "model_params_grid_cnn = {\n",
        "    'input_size': [8],  # Usually fixed\n",
        "}\n",
        "best_cnn_model = hyperparameter_optimization(\n",
        "    model_class=CNNModel,\n",
        "    model_params_grid=model_params_grid_cnn,\n",
        "    dataset_params=dataset_params,\n",
        "    training_params=training_params,\n",
        "    output_keys=output_keys,\n",
        "    num_classes_dict=num_classes_dict\n",
        ")"
      ],
      "metadata": {
        "id": "JHPWlXbgo9IQ",
        "outputId": "5e2ad57d-bf33-44e5-9136-a5d13e568b3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hyperparameter Optimization for CNNModel...\n",
            "Testing parameters: {'input_size': 8}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-79da02321f52>:526: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss: 333.3192240721101\n",
            "Best Parameters: {'input_size': 8}\n",
            "Best Loss: 333.3192240721101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining LSTMModel...\")\n",
        "model_params_lstm = {\n",
        "    'input_size': 8,  # Number of features in seq_data\n",
        "    'hidden_size': 64,\n",
        "    'num_layers': 2,\n",
        "    'output_keys': output_keys,\n",
        "    'num_classes_dict': num_classes_dict\n",
        "}\n",
        "model_lstm = train_model(LSTMModel, model_params_lstm, dataset_params, training_params)"
      ],
      "metadata": {
        "id": "g-S-rlV4pClq",
        "outputId": "97e4bafe-04f3-4f36-f4eb-bacbf816aa87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LSTMModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-79da02321f52>:526: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 541.4942780512913\n",
            "Epoch 2, Loss: 521.8279852411549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nHyperparameter Optimization for LSTMModel...\")\n",
        "model_params_grid_lstm = {\n",
        "    'hidden_size': [32, 64],\n",
        "    'num_layers': [1, 2],\n",
        "}\n",
        "best_lstm_model = hyperparameter_optimization(\n",
        "    model_class=LSTMModel,\n",
        "    model_params_grid=model_params_grid_lstm,\n",
        "    dataset_params=dataset_params,\n",
        "    training_params=training_params,\n",
        "    output_keys=output_keys,\n",
        "    num_classes_dict=num_classes_dict\n",
        ")"
      ],
      "metadata": {
        "id": "L510fkXCpF4F",
        "outputId": "4334bcc4-d59a-4a6b-b003-b14547ce59aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hyperparameter Optimization for LSTMModel...\n",
            "Testing parameters: {'hidden_size': 32, 'num_layers': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-79da02321f52>:526: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss: 556.6154732673791\n",
            "Testing parameters: {'hidden_size': 32, 'num_layers': 2}\n",
            "Average Loss: 553.4682630794064\n",
            "Testing parameters: {'hidden_size': 64, 'num_layers': 1}\n",
            "Average Loss: 549.3058979010126\n",
            "Testing parameters: {'hidden_size': 64, 'num_layers': 2}\n",
            "Average Loss: 543.2973115763087\n",
            "Best Parameters: {'hidden_size': 64, 'num_layers': 2}\n",
            "Best Loss: 543.2973115763087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining TransformerModel...\")\n",
        "model_params_transformer = {\n",
        "    'input_size': 8,  # Number of features in seq_data\n",
        "    'num_heads': 4,\n",
        "    'num_layers': 2,\n",
        "    'output_keys': output_keys,\n",
        "    'num_classes_dict': num_classes_dict\n",
        "}\n",
        "model_transformer = train_model(TransformerModel, model_params_transformer, dataset_params, training_params)"
      ],
      "metadata": {
        "id": "i0NGnqePpJdf",
        "outputId": "e0fed943-ad6b-4825-8e3d-89da98cd75c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training TransformerModel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "<ipython-input-12-79da02321f52>:526: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 557.859285196681\n",
            "Epoch 2, Loss: 550.991188195101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nHyperparameter Optimization for TransformerModel...\")\n",
        "model_params_grid_transformer = {\n",
        "    'num_heads': [2, 4],\n",
        "    'num_layers': [1, 2],\n",
        "}\n",
        "best_transformer_model = hyperparameter_optimization(\n",
        "    model_class=TransformerModel,\n",
        "    model_params_grid=model_params_grid_transformer,\n",
        "    dataset_params=dataset_params,\n",
        "    training_params=training_params,\n",
        "    output_keys=output_keys,\n",
        "    num_classes_dict=num_classes_dict\n",
        ")"
      ],
      "metadata": {
        "id": "-WIxpgRQpM_f",
        "outputId": "2931d204-03c1-4873-fb16-661f7742017d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hyperparameter Optimization for TransformerModel...\n",
            "Testing parameters: {'num_heads': 2, 'num_layers': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-79da02321f52>:526: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  seq_list = [torch.tensor(seq[key]) for seq in sequences]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss: 552.7555909369402\n",
            "Testing parameters: {'num_heads': 2, 'num_layers': 2}\n",
            "Average Loss: 558.3002187157892\n",
            "Testing parameters: {'num_heads': 4, 'num_layers': 1}\n"
          ]
        }
      ]
    }
  ]
}